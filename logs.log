2024-02-16 23:26:54,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-16 23:26:54,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-16 23:26:54,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-16 23:26:54,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-02-16 23:30:56,841:INFO:PyCaret ClassificationExperiment
2024-02-16 23:30:56,841:INFO:Logging name: clf-default-name
2024-02-16 23:30:56,841:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-16 23:30:56,841:INFO:version 3.2.0
2024-02-16 23:30:56,841:INFO:Initializing setup()
2024-02-16 23:30:56,841:INFO:self.USI: efb2
2024-02-16 23:30:56,841:INFO:self._variable_keys: {'y_test', 'fold_groups_param', 'X', 'pipeline', 'logging_param', 'idx', 'exp_id', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'gpu_param', 'memory', 'y', 'seed', 'X_test', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'data', 'X_train', 'target_param', 'html_param', 'y_train', 'fix_imbalance', 'fold_generator', '_available_plots', '_ml_usecase', 'USI'}
2024-02-16 23:30:56,841:INFO:Checking environment
2024-02-16 23:30:56,841:INFO:python_version: 3.10.2
2024-02-16 23:30:56,841:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2024-02-16 23:30:56,841:INFO:machine: AMD64
2024-02-16 23:30:56,841:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-16 23:30:56,858:INFO:Memory: svmem(total=8247582720, available=1799798784, percent=78.2, used=6447783936, free=1799798784)
2024-02-16 23:30:56,858:INFO:Physical Core: 4
2024-02-16 23:30:56,858:INFO:Logical Core: 8
2024-02-16 23:30:56,858:INFO:Checking libraries
2024-02-16 23:30:56,858:INFO:System:
2024-02-16 23:30:56,858:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2024-02-16 23:30:56,858:INFO:executable: c:\Users\happy\AppData\Local\Programs\Python\Python310\python.exe
2024-02-16 23:30:56,858:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-16 23:30:56,858:INFO:PyCaret required dependencies:
2024-02-16 23:30:56,858:INFO:                 pip: 24.0
2024-02-16 23:30:56,858:INFO:          setuptools: 58.1.0
2024-02-16 23:30:56,858:INFO:             pycaret: 3.2.0
2024-02-16 23:30:56,858:INFO:             IPython: 8.16.1
2024-02-16 23:30:56,858:INFO:          ipywidgets: 8.1.1
2024-02-16 23:30:56,858:INFO:                tqdm: 4.66.1
2024-02-16 23:30:56,858:INFO:               numpy: 1.25.2
2024-02-16 23:30:56,858:INFO:              pandas: 1.5.3
2024-02-16 23:30:56,858:INFO:              jinja2: 3.1.3
2024-02-16 23:30:56,858:INFO:               scipy: 1.10.1
2024-02-16 23:30:56,858:INFO:              joblib: 1.3.2
2024-02-16 23:30:56,858:INFO:             sklearn: 1.2.2
2024-02-16 23:30:56,858:INFO:                pyod: 1.1.2
2024-02-16 23:30:56,868:INFO:            imblearn: 0.12.0
2024-02-16 23:30:56,868:INFO:   category_encoders: 2.6.3
2024-02-16 23:30:56,868:INFO:            lightgbm: 4.3.0
2024-02-16 23:30:56,868:INFO:               numba: 0.59.0
2024-02-16 23:30:56,868:INFO:            requests: 2.31.0
2024-02-16 23:30:56,868:INFO:          matplotlib: 3.6.0
2024-02-16 23:30:56,868:INFO:          scikitplot: 0.3.7
2024-02-16 23:30:56,868:INFO:         yellowbrick: 1.5
2024-02-16 23:30:56,868:INFO:              plotly: 5.18.0
2024-02-16 23:30:56,868:INFO:    plotly-resampler: Not installed
2024-02-16 23:30:56,868:INFO:             kaleido: 0.2.1
2024-02-16 23:30:56,868:INFO:           schemdraw: 0.15
2024-02-16 23:30:56,868:INFO:         statsmodels: 0.14.1
2024-02-16 23:30:56,868:INFO:              sktime: 0.21.1
2024-02-16 23:30:56,868:INFO:               tbats: 1.1.3
2024-02-16 23:30:56,868:INFO:            pmdarima: 2.0.4
2024-02-16 23:30:56,868:INFO:              psutil: 5.9.6
2024-02-16 23:30:56,868:INFO:          markupsafe: 2.1.4
2024-02-16 23:30:56,868:INFO:             pickle5: Not installed
2024-02-16 23:30:56,872:INFO:         cloudpickle: 3.0.0
2024-02-16 23:30:56,872:INFO:         deprecation: 2.1.0
2024-02-16 23:30:56,872:INFO:              xxhash: 3.4.1
2024-02-16 23:30:56,872:INFO:           wurlitzer: Not installed
2024-02-16 23:30:56,872:INFO:PyCaret optional dependencies:
2024-02-16 23:30:56,925:INFO:                shap: Not installed
2024-02-16 23:30:56,925:INFO:           interpret: Not installed
2024-02-16 23:30:56,925:INFO:                umap: Not installed
2024-02-16 23:30:56,925:INFO:     ydata_profiling: Not installed
2024-02-16 23:30:56,925:INFO:  explainerdashboard: Not installed
2024-02-16 23:30:56,925:INFO:             autoviz: Not installed
2024-02-16 23:30:56,925:INFO:           fairlearn: Not installed
2024-02-16 23:30:56,925:INFO:          deepchecks: Not installed
2024-02-16 23:30:56,925:INFO:             xgboost: 2.0.3
2024-02-16 23:30:56,925:INFO:            catboost: 1.2.2
2024-02-16 23:30:56,925:INFO:              kmodes: Not installed
2024-02-16 23:30:56,925:INFO:             mlxtend: 0.23.1
2024-02-16 23:30:56,925:INFO:       statsforecast: Not installed
2024-02-16 23:30:56,925:INFO:        tune_sklearn: Not installed
2024-02-16 23:30:56,925:INFO:                 ray: Not installed
2024-02-16 23:30:56,925:INFO:            hyperopt: Not installed
2024-02-16 23:30:56,925:INFO:              optuna: Not installed
2024-02-16 23:30:56,925:INFO:               skopt: Not installed
2024-02-16 23:30:56,925:INFO:              mlflow: Not installed
2024-02-16 23:30:56,925:INFO:              gradio: Not installed
2024-02-16 23:30:56,925:INFO:             fastapi: Not installed
2024-02-16 23:30:56,925:INFO:             uvicorn: Not installed
2024-02-16 23:30:56,925:INFO:              m2cgen: Not installed
2024-02-16 23:30:56,925:INFO:           evidently: Not installed
2024-02-16 23:30:56,925:INFO:               fugue: Not installed
2024-02-16 23:30:56,925:INFO:           streamlit: Not installed
2024-02-16 23:30:56,925:INFO:             prophet: Not installed
2024-02-16 23:30:56,933:INFO:None
2024-02-16 23:30:56,933:INFO:Set up data.
2024-02-16 23:30:56,990:INFO:Set up folding strategy.
2024-02-16 23:30:56,990:INFO:Set up train/test split.
2024-02-16 23:30:57,021:INFO:Set up index.
2024-02-16 23:30:57,029:INFO:Assigning column types.
2024-02-16 23:42:26,551:INFO:PyCaret ClassificationExperiment
2024-02-16 23:42:26,554:INFO:Logging name: clf-default-name
2024-02-16 23:42:26,554:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-16 23:42:26,554:INFO:version 3.2.0
2024-02-16 23:42:26,554:INFO:Initializing setup()
2024-02-16 23:42:26,554:INFO:self.USI: e491
2024-02-16 23:42:26,554:INFO:self._variable_keys: {'y_test', 'fold_groups_param', 'X', 'pipeline', 'logging_param', 'idx', 'exp_id', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'gpu_param', 'memory', 'y', 'seed', 'X_test', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'data', 'X_train', 'target_param', 'html_param', 'y_train', 'fix_imbalance', 'fold_generator', '_available_plots', '_ml_usecase', 'USI'}
2024-02-16 23:42:26,554:INFO:Checking environment
2024-02-16 23:42:26,554:INFO:python_version: 3.10.2
2024-02-16 23:42:26,554:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2024-02-16 23:42:26,554:INFO:machine: AMD64
2024-02-16 23:42:26,554:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-16 23:42:26,562:INFO:Memory: svmem(total=8247582720, available=1616302080, percent=80.4, used=6631280640, free=1616302080)
2024-02-16 23:42:26,562:INFO:Physical Core: 4
2024-02-16 23:42:26,562:INFO:Logical Core: 8
2024-02-16 23:42:26,562:INFO:Checking libraries
2024-02-16 23:42:26,562:INFO:System:
2024-02-16 23:42:26,562:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2024-02-16 23:42:26,562:INFO:executable: c:\Users\happy\AppData\Local\Programs\Python\Python310\python.exe
2024-02-16 23:42:26,562:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-16 23:42:26,562:INFO:PyCaret required dependencies:
2024-02-16 23:42:26,562:INFO:                 pip: 24.0
2024-02-16 23:42:26,562:INFO:          setuptools: 58.1.0
2024-02-16 23:42:26,562:INFO:             pycaret: 3.2.0
2024-02-16 23:42:26,562:INFO:             IPython: 8.16.1
2024-02-16 23:42:26,562:INFO:          ipywidgets: 8.1.1
2024-02-16 23:42:26,562:INFO:                tqdm: 4.66.1
2024-02-16 23:42:26,562:INFO:               numpy: 1.25.2
2024-02-16 23:42:26,562:INFO:              pandas: 1.5.3
2024-02-16 23:42:26,562:INFO:              jinja2: 3.1.3
2024-02-16 23:42:26,562:INFO:               scipy: 1.10.1
2024-02-16 23:42:26,562:INFO:              joblib: 1.3.2
2024-02-16 23:42:26,562:INFO:             sklearn: 1.2.2
2024-02-16 23:42:26,562:INFO:                pyod: 1.1.2
2024-02-16 23:42:26,562:INFO:            imblearn: 0.12.0
2024-02-16 23:42:26,562:INFO:   category_encoders: 2.6.3
2024-02-16 23:42:26,562:INFO:            lightgbm: 4.3.0
2024-02-16 23:42:26,562:INFO:               numba: 0.59.0
2024-02-16 23:42:26,562:INFO:            requests: 2.31.0
2024-02-16 23:42:26,562:INFO:          matplotlib: 3.6.0
2024-02-16 23:42:26,562:INFO:          scikitplot: 0.3.7
2024-02-16 23:42:26,562:INFO:         yellowbrick: 1.5
2024-02-16 23:42:26,562:INFO:              plotly: 5.18.0
2024-02-16 23:42:26,562:INFO:    plotly-resampler: Not installed
2024-02-16 23:42:26,562:INFO:             kaleido: 0.2.1
2024-02-16 23:42:26,562:INFO:           schemdraw: 0.15
2024-02-16 23:42:26,562:INFO:         statsmodels: 0.14.1
2024-02-16 23:42:26,562:INFO:              sktime: 0.21.1
2024-02-16 23:42:26,562:INFO:               tbats: 1.1.3
2024-02-16 23:42:26,562:INFO:            pmdarima: 2.0.4
2024-02-16 23:42:26,562:INFO:              psutil: 5.9.6
2024-02-16 23:42:26,562:INFO:          markupsafe: 2.1.4
2024-02-16 23:42:26,562:INFO:             pickle5: Not installed
2024-02-16 23:42:26,562:INFO:         cloudpickle: 3.0.0
2024-02-16 23:42:26,562:INFO:         deprecation: 2.1.0
2024-02-16 23:42:26,562:INFO:              xxhash: 3.4.1
2024-02-16 23:42:26,562:INFO:           wurlitzer: Not installed
2024-02-16 23:42:26,562:INFO:PyCaret optional dependencies:
2024-02-16 23:42:26,574:INFO:                shap: Not installed
2024-02-16 23:42:26,574:INFO:           interpret: Not installed
2024-02-16 23:42:26,574:INFO:                umap: Not installed
2024-02-16 23:42:26,574:INFO:     ydata_profiling: Not installed
2024-02-16 23:42:26,574:INFO:  explainerdashboard: Not installed
2024-02-16 23:42:26,574:INFO:             autoviz: Not installed
2024-02-16 23:42:26,574:INFO:           fairlearn: Not installed
2024-02-16 23:42:26,574:INFO:          deepchecks: Not installed
2024-02-16 23:42:26,574:INFO:             xgboost: 2.0.3
2024-02-16 23:42:26,574:INFO:            catboost: 1.2.2
2024-02-16 23:42:26,574:INFO:              kmodes: Not installed
2024-02-16 23:42:26,574:INFO:             mlxtend: 0.23.1
2024-02-16 23:42:26,574:INFO:       statsforecast: Not installed
2024-02-16 23:42:26,574:INFO:        tune_sklearn: Not installed
2024-02-16 23:42:26,574:INFO:                 ray: Not installed
2024-02-16 23:42:26,574:INFO:            hyperopt: Not installed
2024-02-16 23:42:26,574:INFO:              optuna: Not installed
2024-02-16 23:42:26,574:INFO:               skopt: Not installed
2024-02-16 23:42:26,574:INFO:              mlflow: Not installed
2024-02-16 23:42:26,574:INFO:              gradio: Not installed
2024-02-16 23:42:26,574:INFO:             fastapi: Not installed
2024-02-16 23:42:26,574:INFO:             uvicorn: Not installed
2024-02-16 23:42:26,574:INFO:              m2cgen: Not installed
2024-02-16 23:42:26,574:INFO:           evidently: Not installed
2024-02-16 23:42:26,574:INFO:               fugue: Not installed
2024-02-16 23:42:26,574:INFO:           streamlit: Not installed
2024-02-16 23:42:26,574:INFO:             prophet: Not installed
2024-02-16 23:42:26,574:INFO:None
2024-02-16 23:42:26,574:INFO:Set up data.
2024-02-16 23:42:26,615:INFO:Set up folding strategy.
2024-02-16 23:42:26,615:INFO:Set up train/test split.
2024-02-16 23:42:26,658:INFO:Set up index.
2024-02-16 23:42:26,658:INFO:Assigning column types.
2024-02-16 23:43:41,398:INFO:PyCaret ClassificationExperiment
2024-02-16 23:43:41,398:INFO:Logging name: clf-default-name
2024-02-16 23:43:41,398:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-16 23:43:41,398:INFO:version 3.2.0
2024-02-16 23:43:41,398:INFO:Initializing setup()
2024-02-16 23:43:41,398:INFO:self.USI: 7a23
2024-02-16 23:43:41,398:INFO:self._variable_keys: {'y_test', 'fold_groups_param', 'X', 'pipeline', 'logging_param', 'idx', 'exp_id', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'gpu_param', 'memory', 'y', 'seed', 'X_test', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'data', 'X_train', 'target_param', 'html_param', 'y_train', 'fix_imbalance', 'fold_generator', '_available_plots', '_ml_usecase', 'USI'}
2024-02-16 23:43:41,398:INFO:Checking environment
2024-02-16 23:43:41,398:INFO:python_version: 3.10.2
2024-02-16 23:43:41,398:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2024-02-16 23:43:41,398:INFO:machine: AMD64
2024-02-16 23:43:41,398:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-16 23:43:41,398:INFO:Memory: svmem(total=8247582720, available=1452929024, percent=82.4, used=6794653696, free=1452929024)
2024-02-16 23:43:41,398:INFO:Physical Core: 4
2024-02-16 23:43:41,398:INFO:Logical Core: 8
2024-02-16 23:43:41,398:INFO:Checking libraries
2024-02-16 23:43:41,398:INFO:System:
2024-02-16 23:43:41,398:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2024-02-16 23:43:41,398:INFO:executable: c:\Users\happy\AppData\Local\Programs\Python\Python310\python.exe
2024-02-16 23:43:41,398:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-16 23:43:41,398:INFO:PyCaret required dependencies:
2024-02-16 23:43:41,398:INFO:                 pip: 24.0
2024-02-16 23:43:41,398:INFO:          setuptools: 58.1.0
2024-02-16 23:43:41,398:INFO:             pycaret: 3.2.0
2024-02-16 23:43:41,398:INFO:             IPython: 8.16.1
2024-02-16 23:43:41,398:INFO:          ipywidgets: 8.1.1
2024-02-16 23:43:41,398:INFO:                tqdm: 4.66.1
2024-02-16 23:43:41,398:INFO:               numpy: 1.25.2
2024-02-16 23:43:41,398:INFO:              pandas: 1.5.3
2024-02-16 23:43:41,407:INFO:              jinja2: 3.1.3
2024-02-16 23:43:41,407:INFO:               scipy: 1.10.1
2024-02-16 23:43:41,407:INFO:              joblib: 1.3.2
2024-02-16 23:43:41,407:INFO:             sklearn: 1.2.2
2024-02-16 23:43:41,407:INFO:                pyod: 1.1.2
2024-02-16 23:43:41,407:INFO:            imblearn: 0.12.0
2024-02-16 23:43:41,407:INFO:   category_encoders: 2.6.3
2024-02-16 23:43:41,407:INFO:            lightgbm: 4.3.0
2024-02-16 23:43:41,407:INFO:               numba: 0.59.0
2024-02-16 23:43:41,407:INFO:            requests: 2.31.0
2024-02-16 23:43:41,407:INFO:          matplotlib: 3.6.0
2024-02-16 23:43:41,407:INFO:          scikitplot: 0.3.7
2024-02-16 23:43:41,407:INFO:         yellowbrick: 1.5
2024-02-16 23:43:41,407:INFO:              plotly: 5.18.0
2024-02-16 23:43:41,407:INFO:    plotly-resampler: Not installed
2024-02-16 23:43:41,407:INFO:             kaleido: 0.2.1
2024-02-16 23:43:41,407:INFO:           schemdraw: 0.15
2024-02-16 23:43:41,407:INFO:         statsmodels: 0.14.1
2024-02-16 23:43:41,407:INFO:              sktime: 0.21.1
2024-02-16 23:43:41,407:INFO:               tbats: 1.1.3
2024-02-16 23:43:41,407:INFO:            pmdarima: 2.0.4
2024-02-16 23:43:41,407:INFO:              psutil: 5.9.6
2024-02-16 23:43:41,407:INFO:          markupsafe: 2.1.4
2024-02-16 23:43:41,407:INFO:             pickle5: Not installed
2024-02-16 23:43:41,408:INFO:         cloudpickle: 3.0.0
2024-02-16 23:43:41,408:INFO:         deprecation: 2.1.0
2024-02-16 23:43:41,408:INFO:              xxhash: 3.4.1
2024-02-16 23:43:41,408:INFO:           wurlitzer: Not installed
2024-02-16 23:43:41,408:INFO:PyCaret optional dependencies:
2024-02-16 23:43:41,408:INFO:                shap: Not installed
2024-02-16 23:43:41,408:INFO:           interpret: Not installed
2024-02-16 23:43:41,408:INFO:                umap: Not installed
2024-02-16 23:43:41,408:INFO:     ydata_profiling: Not installed
2024-02-16 23:43:41,408:INFO:  explainerdashboard: Not installed
2024-02-16 23:43:41,408:INFO:             autoviz: Not installed
2024-02-16 23:43:41,408:INFO:           fairlearn: Not installed
2024-02-16 23:43:41,408:INFO:          deepchecks: Not installed
2024-02-16 23:43:41,408:INFO:             xgboost: 2.0.3
2024-02-16 23:43:41,408:INFO:            catboost: 1.2.2
2024-02-16 23:43:41,408:INFO:              kmodes: Not installed
2024-02-16 23:43:41,408:INFO:             mlxtend: 0.23.1
2024-02-16 23:43:41,408:INFO:       statsforecast: Not installed
2024-02-16 23:43:41,408:INFO:        tune_sklearn: Not installed
2024-02-16 23:43:41,408:INFO:                 ray: Not installed
2024-02-16 23:43:41,408:INFO:            hyperopt: Not installed
2024-02-16 23:43:41,408:INFO:              optuna: Not installed
2024-02-16 23:43:41,408:INFO:               skopt: Not installed
2024-02-16 23:43:41,408:INFO:              mlflow: Not installed
2024-02-16 23:43:41,408:INFO:              gradio: Not installed
2024-02-16 23:43:41,408:INFO:             fastapi: Not installed
2024-02-16 23:43:41,408:INFO:             uvicorn: Not installed
2024-02-16 23:43:41,408:INFO:              m2cgen: Not installed
2024-02-16 23:43:41,408:INFO:           evidently: Not installed
2024-02-16 23:43:41,408:INFO:               fugue: Not installed
2024-02-16 23:43:41,408:INFO:           streamlit: Not installed
2024-02-16 23:43:41,409:INFO:             prophet: Not installed
2024-02-16 23:43:41,409:INFO:None
2024-02-16 23:43:41,409:INFO:Set up data.
2024-02-16 23:43:41,422:INFO:Set up folding strategy.
2024-02-16 23:43:41,422:INFO:Set up train/test split.
2024-02-16 23:43:41,429:INFO:Set up index.
2024-02-16 23:43:41,429:INFO:Assigning column types.
2024-02-16 23:43:41,438:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-16 23:43:41,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,515:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,515:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,557:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,578:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,578:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,578:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-16 23:43:41,614:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,631:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,645:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,680:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-16 23:43:41,712:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,712:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,712:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-16 23:43:41,778:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,779:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,845:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:41,845:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:41,864:INFO:Preparing preprocessing pipeline...
2024-02-16 23:43:41,866:INFO:Set up simple imputation.
2024-02-16 23:43:41,895:INFO:Finished creating preprocessing pipeline.
2024-02-16 23:43:41,901:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\happy\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_cat...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-02-16 23:43:41,901:INFO:Creating final display dataframe.
2024-02-16 23:43:41,985:INFO:Setup _display_container:                     Description             Value
0                    Session id              3957
1                        Target      is_converted
2                   Target type            Binary
3           Original data shape        (9700, 20)
4        Transformed data shape        (9700, 20)
5   Transformed train set shape        (6790, 20)
6    Transformed test set shape        (2910, 20)
7               Ignore features                 1
8              Numeric features                19
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              7a23
2024-02-16 23:43:42,069:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:42,069:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:42,134:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-16 23:43:42,134:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-16 23:43:42,134:INFO:setup() successfully completed in 0.74s...............
2024-02-17 00:01:54,522:INFO:Initializing compare_models()
2024-02-17 00:01:54,522:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 00:01:54,522:INFO:Checking exceptions
2024-02-17 00:01:54,536:INFO:Preparing display monitor
2024-02-17 00:01:54,615:INFO:Initializing Logistic Regression
2024-02-17 00:01:54,615:INFO:Total runtime is 0.0 minutes
2024-02-17 00:01:54,620:INFO:SubProcess create_model() called ==================================
2024-02-17 00:01:54,620:INFO:Initializing create_model()
2024-02-17 00:01:54,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:01:54,620:INFO:Checking exceptions
2024-02-17 00:01:54,620:INFO:Importing libraries
2024-02-17 00:01:54,620:INFO:Copying training dataset
2024-02-17 00:01:54,625:INFO:Defining folds
2024-02-17 00:01:54,625:INFO:Declaring metric variables
2024-02-17 00:01:54,633:INFO:Importing untrained model
2024-02-17 00:01:54,641:INFO:Logistic Regression Imported successfully
2024-02-17 00:01:54,652:INFO:Starting cross validation
2024-02-17 00:01:54,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:01,436:INFO:Calculating mean and std
2024-02-17 00:02:01,436:INFO:Creating metrics dataframe
2024-02-17 00:02:01,453:INFO:Uploading results into container
2024-02-17 00:02:01,453:INFO:Uploading model into container now
2024-02-17 00:02:01,453:INFO:_master_model_container: 1
2024-02-17 00:02:01,453:INFO:_display_container: 2
2024-02-17 00:02:01,453:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3957, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 00:02:01,453:INFO:create_model() successfully completed......................................
2024-02-17 00:02:01,587:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:01,587:INFO:Creating metrics dataframe
2024-02-17 00:02:01,603:INFO:Initializing K Neighbors Classifier
2024-02-17 00:02:01,603:INFO:Total runtime is 0.11647796233495077 minutes
2024-02-17 00:02:01,603:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:01,603:INFO:Initializing create_model()
2024-02-17 00:02:01,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:01,603:INFO:Checking exceptions
2024-02-17 00:02:01,603:INFO:Importing libraries
2024-02-17 00:02:01,603:INFO:Copying training dataset
2024-02-17 00:02:01,614:INFO:Defining folds
2024-02-17 00:02:01,614:INFO:Declaring metric variables
2024-02-17 00:02:01,624:INFO:Importing untrained model
2024-02-17 00:02:01,626:INFO:K Neighbors Classifier Imported successfully
2024-02-17 00:02:01,636:INFO:Starting cross validation
2024-02-17 00:02:01,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:01,953:INFO:Calculating mean and std
2024-02-17 00:02:01,953:INFO:Creating metrics dataframe
2024-02-17 00:02:01,959:INFO:Uploading results into container
2024-02-17 00:02:01,959:INFO:Uploading model into container now
2024-02-17 00:02:01,959:INFO:_master_model_container: 2
2024-02-17 00:02:01,959:INFO:_display_container: 2
2024-02-17 00:02:01,959:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 00:02:01,959:INFO:create_model() successfully completed......................................
2024-02-17 00:02:02,087:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:02,087:INFO:Creating metrics dataframe
2024-02-17 00:02:02,113:INFO:Initializing Naive Bayes
2024-02-17 00:02:02,113:INFO:Total runtime is 0.12497169574101766 minutes
2024-02-17 00:02:02,113:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:02,113:INFO:Initializing create_model()
2024-02-17 00:02:02,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:02,113:INFO:Checking exceptions
2024-02-17 00:02:02,113:INFO:Importing libraries
2024-02-17 00:02:02,113:INFO:Copying training dataset
2024-02-17 00:02:02,120:INFO:Defining folds
2024-02-17 00:02:02,120:INFO:Declaring metric variables
2024-02-17 00:02:02,131:INFO:Importing untrained model
2024-02-17 00:02:02,139:INFO:Naive Bayes Imported successfully
2024-02-17 00:02:02,139:INFO:Starting cross validation
2024-02-17 00:02:02,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:02,251:INFO:Calculating mean and std
2024-02-17 00:02:02,253:INFO:Creating metrics dataframe
2024-02-17 00:02:02,255:INFO:Uploading results into container
2024-02-17 00:02:02,255:INFO:Uploading model into container now
2024-02-17 00:02:02,255:INFO:_master_model_container: 3
2024-02-17 00:02:02,255:INFO:_display_container: 2
2024-02-17 00:02:02,255:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 00:02:02,255:INFO:create_model() successfully completed......................................
2024-02-17 00:02:02,361:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:02,362:INFO:Creating metrics dataframe
2024-02-17 00:02:02,387:INFO:Initializing Decision Tree Classifier
2024-02-17 00:02:02,387:INFO:Total runtime is 0.12953853209813435 minutes
2024-02-17 00:02:02,393:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:02,393:INFO:Initializing create_model()
2024-02-17 00:02:02,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:02,393:INFO:Checking exceptions
2024-02-17 00:02:02,393:INFO:Importing libraries
2024-02-17 00:02:02,393:INFO:Copying training dataset
2024-02-17 00:02:02,393:INFO:Defining folds
2024-02-17 00:02:02,393:INFO:Declaring metric variables
2024-02-17 00:02:02,403:INFO:Importing untrained model
2024-02-17 00:02:02,403:INFO:Decision Tree Classifier Imported successfully
2024-02-17 00:02:02,403:INFO:Starting cross validation
2024-02-17 00:02:02,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:02,565:INFO:Calculating mean and std
2024-02-17 00:02:02,565:INFO:Creating metrics dataframe
2024-02-17 00:02:02,565:INFO:Uploading results into container
2024-02-17 00:02:02,565:INFO:Uploading model into container now
2024-02-17 00:02:02,569:INFO:_master_model_container: 4
2024-02-17 00:02:02,570:INFO:_display_container: 2
2024-02-17 00:02:02,570:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3957, splitter='best')
2024-02-17 00:02:02,570:INFO:create_model() successfully completed......................................
2024-02-17 00:02:02,673:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:02,673:INFO:Creating metrics dataframe
2024-02-17 00:02:02,703:INFO:Initializing SVM - Linear Kernel
2024-02-17 00:02:02,703:INFO:Total runtime is 0.13480982383092244 minutes
2024-02-17 00:02:02,710:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:02,710:INFO:Initializing create_model()
2024-02-17 00:02:02,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:02,710:INFO:Checking exceptions
2024-02-17 00:02:02,710:INFO:Importing libraries
2024-02-17 00:02:02,710:INFO:Copying training dataset
2024-02-17 00:02:02,718:INFO:Defining folds
2024-02-17 00:02:02,718:INFO:Declaring metric variables
2024-02-17 00:02:02,720:INFO:Importing untrained model
2024-02-17 00:02:02,720:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 00:02:02,720:INFO:Starting cross validation
2024-02-17 00:02:02,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:02,953:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,953:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,953:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,953:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,967:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,967:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,967:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:02,967:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:03,053:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:03,062:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:02:03,085:INFO:Calculating mean and std
2024-02-17 00:02:03,088:INFO:Creating metrics dataframe
2024-02-17 00:02:03,092:INFO:Uploading results into container
2024-02-17 00:02:03,092:INFO:Uploading model into container now
2024-02-17 00:02:03,092:INFO:_master_model_container: 5
2024-02-17 00:02:03,092:INFO:_display_container: 2
2024-02-17 00:02:03,092:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3957, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 00:02:03,092:INFO:create_model() successfully completed......................................
2024-02-17 00:02:03,196:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:03,203:INFO:Creating metrics dataframe
2024-02-17 00:02:03,205:INFO:Initializing Ridge Classifier
2024-02-17 00:02:03,205:INFO:Total runtime is 0.14317992925643921 minutes
2024-02-17 00:02:03,205:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:03,205:INFO:Initializing create_model()
2024-02-17 00:02:03,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:03,205:INFO:Checking exceptions
2024-02-17 00:02:03,205:INFO:Importing libraries
2024-02-17 00:02:03,205:INFO:Copying training dataset
2024-02-17 00:02:03,220:INFO:Defining folds
2024-02-17 00:02:03,220:INFO:Declaring metric variables
2024-02-17 00:02:03,220:INFO:Importing untrained model
2024-02-17 00:02:03,229:INFO:Ridge Classifier Imported successfully
2024-02-17 00:02:03,239:INFO:Starting cross validation
2024-02-17 00:02:03,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:03,294:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,294:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,294:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,294:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,294:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,321:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,321:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:02:03,350:INFO:Calculating mean and std
2024-02-17 00:02:03,350:INFO:Creating metrics dataframe
2024-02-17 00:02:03,353:INFO:Uploading results into container
2024-02-17 00:02:03,353:INFO:Uploading model into container now
2024-02-17 00:02:03,353:INFO:_master_model_container: 6
2024-02-17 00:02:03,353:INFO:_display_container: 2
2024-02-17 00:02:03,353:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3957, solver='auto',
                tol=0.0001)
2024-02-17 00:02:03,353:INFO:create_model() successfully completed......................................
2024-02-17 00:02:03,453:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:03,453:INFO:Creating metrics dataframe
2024-02-17 00:02:03,481:INFO:Initializing Random Forest Classifier
2024-02-17 00:02:03,481:INFO:Total runtime is 0.14777817328770956 minutes
2024-02-17 00:02:03,481:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:03,481:INFO:Initializing create_model()
2024-02-17 00:02:03,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:03,481:INFO:Checking exceptions
2024-02-17 00:02:03,481:INFO:Importing libraries
2024-02-17 00:02:03,481:INFO:Copying training dataset
2024-02-17 00:02:03,481:INFO:Defining folds
2024-02-17 00:02:03,481:INFO:Declaring metric variables
2024-02-17 00:02:03,497:INFO:Importing untrained model
2024-02-17 00:02:03,503:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:02:03,512:INFO:Starting cross validation
2024-02-17 00:02:03,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:05,281:INFO:Calculating mean and std
2024-02-17 00:02:05,281:INFO:Creating metrics dataframe
2024-02-17 00:02:05,281:INFO:Uploading results into container
2024-02-17 00:02:05,281:INFO:Uploading model into container now
2024-02-17 00:02:05,281:INFO:_master_model_container: 7
2024-02-17 00:02:05,281:INFO:_display_container: 2
2024-02-17 00:02:05,281:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:02:05,281:INFO:create_model() successfully completed......................................
2024-02-17 00:02:05,414:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:05,414:INFO:Creating metrics dataframe
2024-02-17 00:02:05,440:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 00:02:05,455:INFO:Total runtime is 0.18066883087158203 minutes
2024-02-17 00:02:05,455:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:05,455:INFO:Initializing create_model()
2024-02-17 00:02:05,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:05,455:INFO:Checking exceptions
2024-02-17 00:02:05,455:INFO:Importing libraries
2024-02-17 00:02:05,455:INFO:Copying training dataset
2024-02-17 00:02:05,470:INFO:Defining folds
2024-02-17 00:02:05,470:INFO:Declaring metric variables
2024-02-17 00:02:05,474:INFO:Importing untrained model
2024-02-17 00:02:05,483:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 00:02:05,492:INFO:Starting cross validation
2024-02-17 00:02:05,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:05,630:INFO:Calculating mean and std
2024-02-17 00:02:05,630:INFO:Creating metrics dataframe
2024-02-17 00:02:05,637:INFO:Uploading results into container
2024-02-17 00:02:05,637:INFO:Uploading model into container now
2024-02-17 00:02:05,638:INFO:_master_model_container: 8
2024-02-17 00:02:05,638:INFO:_display_container: 2
2024-02-17 00:02:05,639:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 00:02:05,639:INFO:create_model() successfully completed......................................
2024-02-17 00:02:05,757:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:05,757:INFO:Creating metrics dataframe
2024-02-17 00:02:05,788:INFO:Initializing Ada Boost Classifier
2024-02-17 00:02:05,788:INFO:Total runtime is 0.18622271219889322 minutes
2024-02-17 00:02:05,788:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:05,788:INFO:Initializing create_model()
2024-02-17 00:02:05,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:05,788:INFO:Checking exceptions
2024-02-17 00:02:05,788:INFO:Importing libraries
2024-02-17 00:02:05,788:INFO:Copying training dataset
2024-02-17 00:02:05,803:INFO:Defining folds
2024-02-17 00:02:05,803:INFO:Declaring metric variables
2024-02-17 00:02:05,803:INFO:Importing untrained model
2024-02-17 00:02:05,812:INFO:Ada Boost Classifier Imported successfully
2024-02-17 00:02:05,827:INFO:Starting cross validation
2024-02-17 00:02:05,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:06,983:INFO:Calculating mean and std
2024-02-17 00:02:06,983:INFO:Creating metrics dataframe
2024-02-17 00:02:06,983:INFO:Uploading results into container
2024-02-17 00:02:06,983:INFO:Uploading model into container now
2024-02-17 00:02:06,983:INFO:_master_model_container: 9
2024-02-17 00:02:06,983:INFO:_display_container: 2
2024-02-17 00:02:06,983:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3957)
2024-02-17 00:02:06,983:INFO:create_model() successfully completed......................................
2024-02-17 00:02:07,111:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:07,111:INFO:Creating metrics dataframe
2024-02-17 00:02:07,125:INFO:Initializing Gradient Boosting Classifier
2024-02-17 00:02:07,125:INFO:Total runtime is 0.208502197265625 minutes
2024-02-17 00:02:07,139:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:07,139:INFO:Initializing create_model()
2024-02-17 00:02:07,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:07,139:INFO:Checking exceptions
2024-02-17 00:02:07,139:INFO:Importing libraries
2024-02-17 00:02:07,139:INFO:Copying training dataset
2024-02-17 00:02:07,139:INFO:Defining folds
2024-02-17 00:02:07,139:INFO:Declaring metric variables
2024-02-17 00:02:07,154:INFO:Importing untrained model
2024-02-17 00:02:07,160:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:02:07,178:INFO:Starting cross validation
2024-02-17 00:02:07,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:10,050:INFO:Calculating mean and std
2024-02-17 00:02:10,050:INFO:Creating metrics dataframe
2024-02-17 00:02:10,050:INFO:Uploading results into container
2024-02-17 00:02:10,050:INFO:Uploading model into container now
2024-02-17 00:02:10,050:INFO:_master_model_container: 10
2024-02-17 00:02:10,050:INFO:_display_container: 2
2024-02-17 00:02:10,066:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:02:10,066:INFO:create_model() successfully completed......................................
2024-02-17 00:02:10,170:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:10,170:INFO:Creating metrics dataframe
2024-02-17 00:02:10,203:INFO:Initializing Linear Discriminant Analysis
2024-02-17 00:02:10,203:INFO:Total runtime is 0.2598104198773702 minutes
2024-02-17 00:02:10,203:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:10,203:INFO:Initializing create_model()
2024-02-17 00:02:10,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:10,203:INFO:Checking exceptions
2024-02-17 00:02:10,203:INFO:Importing libraries
2024-02-17 00:02:10,211:INFO:Copying training dataset
2024-02-17 00:02:10,211:INFO:Defining folds
2024-02-17 00:02:10,211:INFO:Declaring metric variables
2024-02-17 00:02:10,219:INFO:Importing untrained model
2024-02-17 00:02:10,221:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 00:02:10,221:INFO:Starting cross validation
2024-02-17 00:02:10,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:10,349:INFO:Calculating mean and std
2024-02-17 00:02:10,349:INFO:Creating metrics dataframe
2024-02-17 00:02:10,349:INFO:Uploading results into container
2024-02-17 00:02:10,349:INFO:Uploading model into container now
2024-02-17 00:02:10,349:INFO:_master_model_container: 11
2024-02-17 00:02:10,349:INFO:_display_container: 2
2024-02-17 00:02:10,349:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 00:02:10,349:INFO:create_model() successfully completed......................................
2024-02-17 00:02:10,459:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:10,459:INFO:Creating metrics dataframe
2024-02-17 00:02:10,486:INFO:Initializing Extra Trees Classifier
2024-02-17 00:02:10,486:INFO:Total runtime is 0.2645319700241089 minutes
2024-02-17 00:02:10,486:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:10,486:INFO:Initializing create_model()
2024-02-17 00:02:10,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:10,486:INFO:Checking exceptions
2024-02-17 00:02:10,486:INFO:Importing libraries
2024-02-17 00:02:10,486:INFO:Copying training dataset
2024-02-17 00:02:10,494:INFO:Defining folds
2024-02-17 00:02:10,494:INFO:Declaring metric variables
2024-02-17 00:02:10,503:INFO:Importing untrained model
2024-02-17 00:02:10,503:INFO:Extra Trees Classifier Imported successfully
2024-02-17 00:02:10,503:INFO:Starting cross validation
2024-02-17 00:02:10,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:11,915:INFO:Calculating mean and std
2024-02-17 00:02:11,915:INFO:Creating metrics dataframe
2024-02-17 00:02:11,915:INFO:Uploading results into container
2024-02-17 00:02:11,915:INFO:Uploading model into container now
2024-02-17 00:02:11,915:INFO:_master_model_container: 12
2024-02-17 00:02:11,915:INFO:_display_container: 2
2024-02-17 00:02:11,915:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:02:11,929:INFO:create_model() successfully completed......................................
2024-02-17 00:02:12,032:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:12,032:INFO:Creating metrics dataframe
2024-02-17 00:02:12,063:INFO:Initializing Extreme Gradient Boosting
2024-02-17 00:02:12,063:INFO:Total runtime is 0.29080594380696617 minutes
2024-02-17 00:02:12,070:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:12,070:INFO:Initializing create_model()
2024-02-17 00:02:12,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:12,070:INFO:Checking exceptions
2024-02-17 00:02:12,070:INFO:Importing libraries
2024-02-17 00:02:12,070:INFO:Copying training dataset
2024-02-17 00:02:12,070:INFO:Defining folds
2024-02-17 00:02:12,070:INFO:Declaring metric variables
2024-02-17 00:02:12,079:INFO:Importing untrained model
2024-02-17 00:02:12,086:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:02:12,095:INFO:Starting cross validation
2024-02-17 00:02:12,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:12,669:INFO:Calculating mean and std
2024-02-17 00:02:12,670:INFO:Creating metrics dataframe
2024-02-17 00:02:12,670:INFO:Uploading results into container
2024-02-17 00:02:12,670:INFO:Uploading model into container now
2024-02-17 00:02:12,670:INFO:_master_model_container: 13
2024-02-17 00:02:12,670:INFO:_display_container: 2
2024-02-17 00:02:12,670:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:02:12,670:INFO:create_model() successfully completed......................................
2024-02-17 00:02:12,780:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:12,781:INFO:Creating metrics dataframe
2024-02-17 00:02:12,803:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 00:02:12,803:INFO:Total runtime is 0.30314320723215743 minutes
2024-02-17 00:02:12,811:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:12,811:INFO:Initializing create_model()
2024-02-17 00:02:12,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:12,811:INFO:Checking exceptions
2024-02-17 00:02:12,811:INFO:Importing libraries
2024-02-17 00:02:12,811:INFO:Copying training dataset
2024-02-17 00:02:12,820:INFO:Defining folds
2024-02-17 00:02:12,820:INFO:Declaring metric variables
2024-02-17 00:02:12,822:INFO:Importing untrained model
2024-02-17 00:02:12,822:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:02:12,836:INFO:Starting cross validation
2024-02-17 00:02:12,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:14,517:INFO:Calculating mean and std
2024-02-17 00:02:14,517:INFO:Creating metrics dataframe
2024-02-17 00:02:14,527:INFO:Uploading results into container
2024-02-17 00:02:14,539:INFO:Uploading model into container now
2024-02-17 00:02:14,539:INFO:_master_model_container: 14
2024-02-17 00:02:14,539:INFO:_display_container: 2
2024-02-17 00:02:14,539:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:02:14,544:INFO:create_model() successfully completed......................................
2024-02-17 00:02:14,665:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:14,665:INFO:Creating metrics dataframe
2024-02-17 00:02:14,697:INFO:Initializing CatBoost Classifier
2024-02-17 00:02:14,697:INFO:Total runtime is 0.3347075661023458 minutes
2024-02-17 00:02:14,713:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:14,713:INFO:Initializing create_model()
2024-02-17 00:02:14,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:14,713:INFO:Checking exceptions
2024-02-17 00:02:14,713:INFO:Importing libraries
2024-02-17 00:02:14,713:INFO:Copying training dataset
2024-02-17 00:02:14,720:INFO:Defining folds
2024-02-17 00:02:14,720:INFO:Declaring metric variables
2024-02-17 00:02:14,720:INFO:Importing untrained model
2024-02-17 00:02:14,731:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:02:14,748:INFO:Starting cross validation
2024-02-17 00:02:14,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:34,480:INFO:Calculating mean and std
2024-02-17 00:02:34,480:INFO:Creating metrics dataframe
2024-02-17 00:02:34,480:INFO:Uploading results into container
2024-02-17 00:02:34,480:INFO:Uploading model into container now
2024-02-17 00:02:34,480:INFO:_master_model_container: 15
2024-02-17 00:02:34,480:INFO:_display_container: 2
2024-02-17 00:02:34,480:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DA1DEAB90>
2024-02-17 00:02:34,480:INFO:create_model() successfully completed......................................
2024-02-17 00:02:34,611:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:34,611:INFO:Creating metrics dataframe
2024-02-17 00:02:34,626:INFO:Initializing Dummy Classifier
2024-02-17 00:02:34,626:INFO:Total runtime is 0.6668577194213867 minutes
2024-02-17 00:02:34,626:INFO:SubProcess create_model() called ==================================
2024-02-17 00:02:34,638:INFO:Initializing create_model()
2024-02-17 00:02:34,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC19422F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:34,638:INFO:Checking exceptions
2024-02-17 00:02:34,638:INFO:Importing libraries
2024-02-17 00:02:34,638:INFO:Copying training dataset
2024-02-17 00:02:34,642:INFO:Defining folds
2024-02-17 00:02:34,642:INFO:Declaring metric variables
2024-02-17 00:02:34,642:INFO:Importing untrained model
2024-02-17 00:02:34,654:INFO:Dummy Classifier Imported successfully
2024-02-17 00:02:34,664:INFO:Starting cross validation
2024-02-17 00:02:34,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:02:34,735:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:02:34,735:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:02:34,735:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:02:34,735:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:02:34,735:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:02:34,751:INFO:Calculating mean and std
2024-02-17 00:02:34,751:INFO:Creating metrics dataframe
2024-02-17 00:02:34,751:INFO:Uploading results into container
2024-02-17 00:02:34,751:INFO:Uploading model into container now
2024-02-17 00:02:34,751:INFO:_master_model_container: 16
2024-02-17 00:02:34,751:INFO:_display_container: 2
2024-02-17 00:02:34,751:INFO:DummyClassifier(constant=None, random_state=3957, strategy='prior')
2024-02-17 00:02:34,751:INFO:create_model() successfully completed......................................
2024-02-17 00:02:34,854:INFO:SubProcess create_model() end ==================================
2024-02-17 00:02:34,854:INFO:Creating metrics dataframe
2024-02-17 00:02:34,901:INFO:Initializing create_model()
2024-02-17 00:02:34,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DA1DEAB90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:02:34,901:INFO:Checking exceptions
2024-02-17 00:02:34,904:INFO:Importing libraries
2024-02-17 00:02:34,904:INFO:Copying training dataset
2024-02-17 00:02:34,909:INFO:Defining folds
2024-02-17 00:02:34,909:INFO:Declaring metric variables
2024-02-17 00:02:34,909:INFO:Importing untrained model
2024-02-17 00:02:34,909:INFO:Declaring custom model
2024-02-17 00:02:34,909:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:02:34,909:INFO:Cross validation set to False
2024-02-17 00:02:34,909:INFO:Fitting Model
2024-02-17 00:02:38,402:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFA90>
2024-02-17 00:02:38,402:INFO:create_model() successfully completed......................................
2024-02-17 00:02:38,584:INFO:_master_model_container: 16
2024-02-17 00:02:38,584:INFO:_display_container: 2
2024-02-17 00:02:38,584:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFA90>
2024-02-17 00:02:38,584:INFO:compare_models() successfully completed......................................
2024-02-17 00:03:07,296:INFO:Initializing tune_model()
2024-02-17 00:03:07,296:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC15BFA90>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:03:07,296:INFO:Checking exceptions
2024-02-17 00:03:07,313:INFO:Copying training dataset
2024-02-17 00:03:07,313:INFO:Checking base model
2024-02-17 00:03:07,313:INFO:Base model : CatBoost Classifier
2024-02-17 00:03:07,323:INFO:Declaring metric variables
2024-02-17 00:03:07,323:INFO:Defining Hyperparameters
2024-02-17 00:03:07,454:INFO:Tuning with n_jobs=-1
2024-02-17 00:03:07,454:INFO:Initializing RandomizedSearchCV
2024-02-17 00:04:13,005:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2303, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2230, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6105, in _catboost._check_train_params
  File "_catboost.pyx", line 6124, in _catboost._check_train_params
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-02-17 00:04:13,045:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84742268 0.80574374        nan 0.90029455 0.8353461  0.90795287
 0.92076583 0.82268041 0.86023564 0.88468336]
  warnings.warn(

2024-02-17 00:04:13,045:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2024-02-17 00:04:13,045:INFO:Hyperparameter search completed
2024-02-17 00:04:13,045:INFO:SubProcess create_model() called ==================================
2024-02-17 00:04:13,045:INFO:Initializing create_model()
2024-02-17 00:04:13,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DA1DEA8C0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE0DC910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 250, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 8})
2024-02-17 00:04:13,045:INFO:Checking exceptions
2024-02-17 00:04:13,045:INFO:Importing libraries
2024-02-17 00:04:13,045:INFO:Copying training dataset
2024-02-17 00:04:13,069:INFO:Defining folds
2024-02-17 00:04:13,069:INFO:Declaring metric variables
2024-02-17 00:04:13,079:INFO:Importing untrained model
2024-02-17 00:04:13,079:INFO:Declaring custom model
2024-02-17 00:04:13,085:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:04:13,095:INFO:Starting cross validation
2024-02-17 00:04:13,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:04:21,627:INFO:Calculating mean and std
2024-02-17 00:04:21,627:INFO:Creating metrics dataframe
2024-02-17 00:04:21,636:INFO:Finalizing model
2024-02-17 00:04:23,838:INFO:Uploading results into container
2024-02-17 00:04:23,840:INFO:Uploading model into container now
2024-02-17 00:04:23,840:INFO:_master_model_container: 17
2024-02-17 00:04:23,840:INFO:_display_container: 3
2024-02-17 00:04:23,840:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBE811210>
2024-02-17 00:04:23,840:INFO:create_model() successfully completed......................................
2024-02-17 00:04:23,965:INFO:SubProcess create_model() end ==================================
2024-02-17 00:04:23,965:INFO:choose_better activated
2024-02-17 00:04:23,965:INFO:SubProcess create_model() called ==================================
2024-02-17 00:04:23,965:INFO:Initializing create_model()
2024-02-17 00:04:23,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC15BFA90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:04:23,973:INFO:Checking exceptions
2024-02-17 00:04:23,973:INFO:Importing libraries
2024-02-17 00:04:23,973:INFO:Copying training dataset
2024-02-17 00:04:23,981:INFO:Defining folds
2024-02-17 00:04:23,981:INFO:Declaring metric variables
2024-02-17 00:04:23,981:INFO:Importing untrained model
2024-02-17 00:04:23,981:INFO:Declaring custom model
2024-02-17 00:04:23,981:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:04:23,981:INFO:Starting cross validation
2024-02-17 00:04:23,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:04:41,232:INFO:Calculating mean and std
2024-02-17 00:04:41,232:INFO:Creating metrics dataframe
2024-02-17 00:04:41,232:INFO:Finalizing model
2024-02-17 00:04:44,611:INFO:Uploading results into container
2024-02-17 00:04:44,611:INFO:Uploading model into container now
2024-02-17 00:04:44,611:INFO:_master_model_container: 18
2024-02-17 00:04:44,611:INFO:_display_container: 4
2024-02-17 00:04:44,611:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBEB32C50>
2024-02-17 00:04:44,611:INFO:create_model() successfully completed......................................
2024-02-17 00:04:44,721:INFO:SubProcess create_model() end ==================================
2024-02-17 00:04:44,721:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBEB32C50> result for Accuracy is 0.9227
2024-02-17 00:04:44,721:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBE811210> result for Accuracy is 0.9208
2024-02-17 00:04:44,721:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBEB32C50> is best model
2024-02-17 00:04:44,721:INFO:choose_better completed
2024-02-17 00:04:44,721:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:04:44,729:INFO:_master_model_container: 18
2024-02-17 00:04:44,729:INFO:_display_container: 3
2024-02-17 00:04:44,729:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBEB32C50>
2024-02-17 00:04:44,729:INFO:tune_model() successfully completed......................................
2024-02-17 00:16:10,794:INFO:Initializing compare_models()
2024-02-17 00:16:10,794:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 00:16:10,794:INFO:Checking exceptions
2024-02-17 00:16:10,800:INFO:Preparing display monitor
2024-02-17 00:16:10,826:INFO:Initializing Logistic Regression
2024-02-17 00:16:10,826:INFO:Total runtime is 0.0 minutes
2024-02-17 00:16:10,826:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:10,826:INFO:Initializing create_model()
2024-02-17 00:16:10,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:10,826:INFO:Checking exceptions
2024-02-17 00:16:10,826:INFO:Importing libraries
2024-02-17 00:16:10,826:INFO:Copying training dataset
2024-02-17 00:16:10,836:INFO:Defining folds
2024-02-17 00:16:10,836:INFO:Declaring metric variables
2024-02-17 00:16:10,844:INFO:Importing untrained model
2024-02-17 00:16:10,847:INFO:Logistic Regression Imported successfully
2024-02-17 00:16:10,852:INFO:Starting cross validation
2024-02-17 00:16:10,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:15,113:INFO:Calculating mean and std
2024-02-17 00:16:15,113:INFO:Creating metrics dataframe
2024-02-17 00:16:15,120:INFO:Uploading results into container
2024-02-17 00:16:15,120:INFO:Uploading model into container now
2024-02-17 00:16:15,120:INFO:_master_model_container: 19
2024-02-17 00:16:15,120:INFO:_display_container: 4
2024-02-17 00:16:15,120:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3957, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 00:16:15,120:INFO:create_model() successfully completed......................................
2024-02-17 00:16:15,237:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:15,237:INFO:Creating metrics dataframe
2024-02-17 00:16:15,253:INFO:Initializing K Neighbors Classifier
2024-02-17 00:16:15,253:INFO:Total runtime is 0.07379175821940104 minutes
2024-02-17 00:16:15,253:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:15,253:INFO:Initializing create_model()
2024-02-17 00:16:15,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:15,253:INFO:Checking exceptions
2024-02-17 00:16:15,253:INFO:Importing libraries
2024-02-17 00:16:15,253:INFO:Copying training dataset
2024-02-17 00:16:15,253:INFO:Defining folds
2024-02-17 00:16:15,265:INFO:Declaring metric variables
2024-02-17 00:16:15,276:INFO:Importing untrained model
2024-02-17 00:16:15,276:INFO:K Neighbors Classifier Imported successfully
2024-02-17 00:16:15,290:INFO:Starting cross validation
2024-02-17 00:16:15,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:15,596:INFO:Calculating mean and std
2024-02-17 00:16:15,596:INFO:Creating metrics dataframe
2024-02-17 00:16:15,596:INFO:Uploading results into container
2024-02-17 00:16:15,596:INFO:Uploading model into container now
2024-02-17 00:16:15,603:INFO:_master_model_container: 20
2024-02-17 00:16:15,603:INFO:_display_container: 4
2024-02-17 00:16:15,603:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 00:16:15,603:INFO:create_model() successfully completed......................................
2024-02-17 00:16:15,716:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:15,716:INFO:Creating metrics dataframe
2024-02-17 00:16:15,722:INFO:Initializing Naive Bayes
2024-02-17 00:16:15,722:INFO:Total runtime is 0.08161027828852335 minutes
2024-02-17 00:16:15,722:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:15,722:INFO:Initializing create_model()
2024-02-17 00:16:15,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:15,722:INFO:Checking exceptions
2024-02-17 00:16:15,722:INFO:Importing libraries
2024-02-17 00:16:15,722:INFO:Copying training dataset
2024-02-17 00:16:15,731:INFO:Defining folds
2024-02-17 00:16:15,731:INFO:Declaring metric variables
2024-02-17 00:16:15,739:INFO:Importing untrained model
2024-02-17 00:16:15,739:INFO:Naive Bayes Imported successfully
2024-02-17 00:16:15,747:INFO:Starting cross validation
2024-02-17 00:16:15,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:15,849:INFO:Calculating mean and std
2024-02-17 00:16:15,849:INFO:Creating metrics dataframe
2024-02-17 00:16:15,853:INFO:Uploading results into container
2024-02-17 00:16:15,853:INFO:Uploading model into container now
2024-02-17 00:16:15,853:INFO:_master_model_container: 21
2024-02-17 00:16:15,853:INFO:_display_container: 4
2024-02-17 00:16:15,853:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 00:16:15,853:INFO:create_model() successfully completed......................................
2024-02-17 00:16:15,967:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:15,967:INFO:Creating metrics dataframe
2024-02-17 00:16:15,975:INFO:Initializing Decision Tree Classifier
2024-02-17 00:16:15,975:INFO:Total runtime is 0.08582158088684082 minutes
2024-02-17 00:16:15,975:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:15,982:INFO:Initializing create_model()
2024-02-17 00:16:15,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:15,982:INFO:Checking exceptions
2024-02-17 00:16:15,982:INFO:Importing libraries
2024-02-17 00:16:15,982:INFO:Copying training dataset
2024-02-17 00:16:15,989:INFO:Defining folds
2024-02-17 00:16:15,989:INFO:Declaring metric variables
2024-02-17 00:16:15,992:INFO:Importing untrained model
2024-02-17 00:16:15,992:INFO:Decision Tree Classifier Imported successfully
2024-02-17 00:16:16,004:INFO:Starting cross validation
2024-02-17 00:16:16,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:16,150:INFO:Calculating mean and std
2024-02-17 00:16:16,150:INFO:Creating metrics dataframe
2024-02-17 00:16:16,153:INFO:Uploading results into container
2024-02-17 00:16:16,153:INFO:Uploading model into container now
2024-02-17 00:16:16,153:INFO:_master_model_container: 22
2024-02-17 00:16:16,153:INFO:_display_container: 4
2024-02-17 00:16:16,153:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3957, splitter='best')
2024-02-17 00:16:16,153:INFO:create_model() successfully completed......................................
2024-02-17 00:16:16,274:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:16,274:INFO:Creating metrics dataframe
2024-02-17 00:16:16,282:INFO:Initializing SVM - Linear Kernel
2024-02-17 00:16:16,282:INFO:Total runtime is 0.09093650976816813 minutes
2024-02-17 00:16:16,289:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:16,289:INFO:Initializing create_model()
2024-02-17 00:16:16,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:16,289:INFO:Checking exceptions
2024-02-17 00:16:16,289:INFO:Importing libraries
2024-02-17 00:16:16,289:INFO:Copying training dataset
2024-02-17 00:16:16,293:INFO:Defining folds
2024-02-17 00:16:16,297:INFO:Declaring metric variables
2024-02-17 00:16:16,302:INFO:Importing untrained model
2024-02-17 00:16:16,303:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 00:16:16,318:INFO:Starting cross validation
2024-02-17 00:16:16,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:16,477:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,477:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,503:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,506:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,506:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,509:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,525:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,539:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,570:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,586:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 00:16:16,614:INFO:Calculating mean and std
2024-02-17 00:16:16,614:INFO:Creating metrics dataframe
2024-02-17 00:16:16,621:INFO:Uploading results into container
2024-02-17 00:16:16,621:INFO:Uploading model into container now
2024-02-17 00:16:16,621:INFO:_master_model_container: 23
2024-02-17 00:16:16,621:INFO:_display_container: 4
2024-02-17 00:16:16,621:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3957, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 00:16:16,621:INFO:create_model() successfully completed......................................
2024-02-17 00:16:16,733:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:16,733:INFO:Creating metrics dataframe
2024-02-17 00:16:16,733:INFO:Initializing Ridge Classifier
2024-02-17 00:16:16,733:INFO:Total runtime is 0.09844443003336588 minutes
2024-02-17 00:16:16,748:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:16,748:INFO:Initializing create_model()
2024-02-17 00:16:16,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:16,748:INFO:Checking exceptions
2024-02-17 00:16:16,748:INFO:Importing libraries
2024-02-17 00:16:16,748:INFO:Copying training dataset
2024-02-17 00:16:16,755:INFO:Defining folds
2024-02-17 00:16:16,755:INFO:Declaring metric variables
2024-02-17 00:16:16,755:INFO:Importing untrained model
2024-02-17 00:16:16,763:INFO:Ridge Classifier Imported successfully
2024-02-17 00:16:16,774:INFO:Starting cross validation
2024-02-17 00:16:16,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:16,810:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,810:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,820:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,820:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,820:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,829:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,831:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,844:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,850:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,852:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 00:16:16,874:INFO:Calculating mean and std
2024-02-17 00:16:16,874:INFO:Creating metrics dataframe
2024-02-17 00:16:16,877:INFO:Uploading results into container
2024-02-17 00:16:16,877:INFO:Uploading model into container now
2024-02-17 00:16:16,877:INFO:_master_model_container: 24
2024-02-17 00:16:16,877:INFO:_display_container: 4
2024-02-17 00:16:16,877:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3957, solver='auto',
                tol=0.0001)
2024-02-17 00:16:16,880:INFO:create_model() successfully completed......................................
2024-02-17 00:16:16,986:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:16,986:INFO:Creating metrics dataframe
2024-02-17 00:16:16,991:INFO:Initializing Random Forest Classifier
2024-02-17 00:16:16,991:INFO:Total runtime is 0.1027444044748942 minutes
2024-02-17 00:16:17,000:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:17,000:INFO:Initializing create_model()
2024-02-17 00:16:17,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:17,000:INFO:Checking exceptions
2024-02-17 00:16:17,000:INFO:Importing libraries
2024-02-17 00:16:17,000:INFO:Copying training dataset
2024-02-17 00:16:17,007:INFO:Defining folds
2024-02-17 00:16:17,007:INFO:Declaring metric variables
2024-02-17 00:16:17,012:INFO:Importing untrained model
2024-02-17 00:16:17,015:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:16:17,022:INFO:Starting cross validation
2024-02-17 00:16:17,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:18,845:INFO:Calculating mean and std
2024-02-17 00:16:18,847:INFO:Creating metrics dataframe
2024-02-17 00:16:18,847:INFO:Uploading results into container
2024-02-17 00:16:18,847:INFO:Uploading model into container now
2024-02-17 00:16:18,847:INFO:_master_model_container: 25
2024-02-17 00:16:18,847:INFO:_display_container: 4
2024-02-17 00:16:18,847:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:16:18,847:INFO:create_model() successfully completed......................................
2024-02-17 00:16:18,965:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:18,965:INFO:Creating metrics dataframe
2024-02-17 00:16:18,981:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 00:16:18,981:INFO:Total runtime is 0.1359204133351644 minutes
2024-02-17 00:16:18,986:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:18,986:INFO:Initializing create_model()
2024-02-17 00:16:18,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:18,986:INFO:Checking exceptions
2024-02-17 00:16:18,986:INFO:Importing libraries
2024-02-17 00:16:18,986:INFO:Copying training dataset
2024-02-17 00:16:18,986:INFO:Defining folds
2024-02-17 00:16:18,986:INFO:Declaring metric variables
2024-02-17 00:16:18,999:INFO:Importing untrained model
2024-02-17 00:16:19,005:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 00:16:19,011:INFO:Starting cross validation
2024-02-17 00:16:19,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:19,116:INFO:Calculating mean and std
2024-02-17 00:16:19,116:INFO:Creating metrics dataframe
2024-02-17 00:16:19,121:INFO:Uploading results into container
2024-02-17 00:16:19,121:INFO:Uploading model into container now
2024-02-17 00:16:19,121:INFO:_master_model_container: 26
2024-02-17 00:16:19,121:INFO:_display_container: 4
2024-02-17 00:16:19,121:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 00:16:19,121:INFO:create_model() successfully completed......................................
2024-02-17 00:16:19,232:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:19,232:INFO:Creating metrics dataframe
2024-02-17 00:16:19,237:INFO:Initializing Ada Boost Classifier
2024-02-17 00:16:19,237:INFO:Total runtime is 0.1401783585548401 minutes
2024-02-17 00:16:19,237:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:19,237:INFO:Initializing create_model()
2024-02-17 00:16:19,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:19,237:INFO:Checking exceptions
2024-02-17 00:16:19,237:INFO:Importing libraries
2024-02-17 00:16:19,237:INFO:Copying training dataset
2024-02-17 00:16:19,248:INFO:Defining folds
2024-02-17 00:16:19,248:INFO:Declaring metric variables
2024-02-17 00:16:19,258:INFO:Importing untrained model
2024-02-17 00:16:19,258:INFO:Ada Boost Classifier Imported successfully
2024-02-17 00:16:19,270:INFO:Starting cross validation
2024-02-17 00:16:19,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:20,103:INFO:Calculating mean and std
2024-02-17 00:16:20,105:INFO:Creating metrics dataframe
2024-02-17 00:16:20,109:INFO:Uploading results into container
2024-02-17 00:16:20,109:INFO:Uploading model into container now
2024-02-17 00:16:20,112:INFO:_master_model_container: 27
2024-02-17 00:16:20,112:INFO:_display_container: 4
2024-02-17 00:16:20,113:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3957)
2024-02-17 00:16:20,113:INFO:create_model() successfully completed......................................
2024-02-17 00:16:20,221:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:20,221:INFO:Creating metrics dataframe
2024-02-17 00:16:20,231:INFO:Initializing Gradient Boosting Classifier
2024-02-17 00:16:20,231:INFO:Total runtime is 0.15674941539764406 minutes
2024-02-17 00:16:20,236:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:20,236:INFO:Initializing create_model()
2024-02-17 00:16:20,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:20,236:INFO:Checking exceptions
2024-02-17 00:16:20,236:INFO:Importing libraries
2024-02-17 00:16:20,236:INFO:Copying training dataset
2024-02-17 00:16:20,236:INFO:Defining folds
2024-02-17 00:16:20,236:INFO:Declaring metric variables
2024-02-17 00:16:20,246:INFO:Importing untrained model
2024-02-17 00:16:20,251:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:16:20,259:INFO:Starting cross validation
2024-02-17 00:16:20,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:22,668:INFO:Calculating mean and std
2024-02-17 00:16:22,670:INFO:Creating metrics dataframe
2024-02-17 00:16:22,670:INFO:Uploading results into container
2024-02-17 00:16:22,670:INFO:Uploading model into container now
2024-02-17 00:16:22,670:INFO:_master_model_container: 28
2024-02-17 00:16:22,670:INFO:_display_container: 4
2024-02-17 00:16:22,675:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:16:22,675:INFO:create_model() successfully completed......................................
2024-02-17 00:16:22,782:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:22,782:INFO:Creating metrics dataframe
2024-02-17 00:16:22,787:INFO:Initializing Linear Discriminant Analysis
2024-02-17 00:16:22,787:INFO:Total runtime is 0.19935097297032675 minutes
2024-02-17 00:16:22,798:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:22,798:INFO:Initializing create_model()
2024-02-17 00:16:22,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:22,798:INFO:Checking exceptions
2024-02-17 00:16:22,798:INFO:Importing libraries
2024-02-17 00:16:22,798:INFO:Copying training dataset
2024-02-17 00:16:22,803:INFO:Defining folds
2024-02-17 00:16:22,803:INFO:Declaring metric variables
2024-02-17 00:16:22,810:INFO:Importing untrained model
2024-02-17 00:16:22,812:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 00:16:22,820:INFO:Starting cross validation
2024-02-17 00:16:22,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:22,934:INFO:Calculating mean and std
2024-02-17 00:16:22,934:INFO:Creating metrics dataframe
2024-02-17 00:16:22,934:INFO:Uploading results into container
2024-02-17 00:16:22,934:INFO:Uploading model into container now
2024-02-17 00:16:22,934:INFO:_master_model_container: 29
2024-02-17 00:16:22,934:INFO:_display_container: 4
2024-02-17 00:16:22,934:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 00:16:22,934:INFO:create_model() successfully completed......................................
2024-02-17 00:16:23,049:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:23,049:INFO:Creating metrics dataframe
2024-02-17 00:16:23,061:INFO:Initializing Extra Trees Classifier
2024-02-17 00:16:23,061:INFO:Total runtime is 0.20392726262410482 minutes
2024-02-17 00:16:23,068:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:23,068:INFO:Initializing create_model()
2024-02-17 00:16:23,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:23,068:INFO:Checking exceptions
2024-02-17 00:16:23,068:INFO:Importing libraries
2024-02-17 00:16:23,068:INFO:Copying training dataset
2024-02-17 00:16:23,072:INFO:Defining folds
2024-02-17 00:16:23,072:INFO:Declaring metric variables
2024-02-17 00:16:23,081:INFO:Importing untrained model
2024-02-17 00:16:23,085:INFO:Extra Trees Classifier Imported successfully
2024-02-17 00:16:23,089:INFO:Starting cross validation
2024-02-17 00:16:23,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:24,605:INFO:Calculating mean and std
2024-02-17 00:16:24,605:INFO:Creating metrics dataframe
2024-02-17 00:16:24,609:INFO:Uploading results into container
2024-02-17 00:16:24,609:INFO:Uploading model into container now
2024-02-17 00:16:24,609:INFO:_master_model_container: 30
2024-02-17 00:16:24,609:INFO:_display_container: 4
2024-02-17 00:16:24,609:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:16:24,609:INFO:create_model() successfully completed......................................
2024-02-17 00:16:24,756:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:24,756:INFO:Creating metrics dataframe
2024-02-17 00:16:24,770:INFO:Initializing Extreme Gradient Boosting
2024-02-17 00:16:24,770:INFO:Total runtime is 0.23240498304367066 minutes
2024-02-17 00:16:24,770:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:24,770:INFO:Initializing create_model()
2024-02-17 00:16:24,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:24,770:INFO:Checking exceptions
2024-02-17 00:16:24,770:INFO:Importing libraries
2024-02-17 00:16:24,770:INFO:Copying training dataset
2024-02-17 00:16:24,781:INFO:Defining folds
2024-02-17 00:16:24,781:INFO:Declaring metric variables
2024-02-17 00:16:24,787:INFO:Importing untrained model
2024-02-17 00:16:24,787:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:16:24,797:INFO:Starting cross validation
2024-02-17 00:16:24,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:25,402:INFO:Calculating mean and std
2024-02-17 00:16:25,403:INFO:Creating metrics dataframe
2024-02-17 00:16:25,406:INFO:Uploading results into container
2024-02-17 00:16:25,408:INFO:Uploading model into container now
2024-02-17 00:16:25,408:INFO:_master_model_container: 31
2024-02-17 00:16:25,408:INFO:_display_container: 4
2024-02-17 00:16:25,411:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:16:25,411:INFO:create_model() successfully completed......................................
2024-02-17 00:16:25,520:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:25,520:INFO:Creating metrics dataframe
2024-02-17 00:16:25,537:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 00:16:25,537:INFO:Total runtime is 0.24519007603327433 minutes
2024-02-17 00:16:25,545:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:25,545:INFO:Initializing create_model()
2024-02-17 00:16:25,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:25,545:INFO:Checking exceptions
2024-02-17 00:16:25,545:INFO:Importing libraries
2024-02-17 00:16:25,545:INFO:Copying training dataset
2024-02-17 00:16:25,554:INFO:Defining folds
2024-02-17 00:16:25,554:INFO:Declaring metric variables
2024-02-17 00:16:25,556:INFO:Importing untrained model
2024-02-17 00:16:25,556:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:16:25,573:INFO:Starting cross validation
2024-02-17 00:16:25,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:26,836:INFO:Calculating mean and std
2024-02-17 00:16:26,838:INFO:Creating metrics dataframe
2024-02-17 00:16:26,841:INFO:Uploading results into container
2024-02-17 00:16:26,841:INFO:Uploading model into container now
2024-02-17 00:16:26,841:INFO:_master_model_container: 32
2024-02-17 00:16:26,841:INFO:_display_container: 4
2024-02-17 00:16:26,841:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:16:26,841:INFO:create_model() successfully completed......................................
2024-02-17 00:16:26,963:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:26,963:INFO:Creating metrics dataframe
2024-02-17 00:16:26,979:INFO:Initializing CatBoost Classifier
2024-02-17 00:16:26,979:INFO:Total runtime is 0.26922105153401693 minutes
2024-02-17 00:16:26,979:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:26,979:INFO:Initializing create_model()
2024-02-17 00:16:26,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:26,979:INFO:Checking exceptions
2024-02-17 00:16:26,979:INFO:Importing libraries
2024-02-17 00:16:26,979:INFO:Copying training dataset
2024-02-17 00:16:26,987:INFO:Defining folds
2024-02-17 00:16:26,987:INFO:Declaring metric variables
2024-02-17 00:16:26,995:INFO:Importing untrained model
2024-02-17 00:16:26,997:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:16:27,003:INFO:Starting cross validation
2024-02-17 00:16:27,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:45,503:INFO:Calculating mean and std
2024-02-17 00:16:45,504:INFO:Creating metrics dataframe
2024-02-17 00:16:45,504:INFO:Uploading results into container
2024-02-17 00:16:45,504:INFO:Uploading model into container now
2024-02-17 00:16:45,504:INFO:_master_model_container: 33
2024-02-17 00:16:45,504:INFO:_display_container: 4
2024-02-17 00:16:45,504:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC18B8FD0>
2024-02-17 00:16:45,504:INFO:create_model() successfully completed......................................
2024-02-17 00:16:45,608:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:45,608:INFO:Creating metrics dataframe
2024-02-17 00:16:45,622:INFO:Initializing Dummy Classifier
2024-02-17 00:16:45,622:INFO:Total runtime is 0.5799279332160949 minutes
2024-02-17 00:16:45,622:INFO:SubProcess create_model() called ==================================
2024-02-17 00:16:45,622:INFO:Initializing create_model()
2024-02-17 00:16:45,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1724FA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:45,622:INFO:Checking exceptions
2024-02-17 00:16:45,622:INFO:Importing libraries
2024-02-17 00:16:45,622:INFO:Copying training dataset
2024-02-17 00:16:45,632:INFO:Defining folds
2024-02-17 00:16:45,632:INFO:Declaring metric variables
2024-02-17 00:16:45,638:INFO:Importing untrained model
2024-02-17 00:16:45,643:INFO:Dummy Classifier Imported successfully
2024-02-17 00:16:45,649:INFO:Starting cross validation
2024-02-17 00:16:45,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:16:45,697:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:16:45,709:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:16:45,709:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:16:45,721:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:16:45,721:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:16:45,739:INFO:Calculating mean and std
2024-02-17 00:16:45,739:INFO:Creating metrics dataframe
2024-02-17 00:16:45,739:INFO:Uploading results into container
2024-02-17 00:16:45,739:INFO:Uploading model into container now
2024-02-17 00:16:45,739:INFO:_master_model_container: 34
2024-02-17 00:16:45,739:INFO:_display_container: 4
2024-02-17 00:16:45,739:INFO:DummyClassifier(constant=None, random_state=3957, strategy='prior')
2024-02-17 00:16:45,739:INFO:create_model() successfully completed......................................
2024-02-17 00:16:45,848:INFO:SubProcess create_model() end ==================================
2024-02-17 00:16:45,848:INFO:Creating metrics dataframe
2024-02-17 00:16:45,871:INFO:Initializing create_model()
2024-02-17 00:16:45,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC18B8FD0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:45,871:INFO:Checking exceptions
2024-02-17 00:16:45,873:INFO:Importing libraries
2024-02-17 00:16:45,873:INFO:Copying training dataset
2024-02-17 00:16:45,873:INFO:Defining folds
2024-02-17 00:16:45,873:INFO:Declaring metric variables
2024-02-17 00:16:45,873:INFO:Importing untrained model
2024-02-17 00:16:45,873:INFO:Declaring custom model
2024-02-17 00:16:45,873:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:16:45,873:INFO:Cross validation set to False
2024-02-17 00:16:45,873:INFO:Fitting Model
2024-02-17 00:16:49,111:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1870670>
2024-02-17 00:16:49,111:INFO:create_model() successfully completed......................................
2024-02-17 00:16:49,227:INFO:Initializing create_model()
2024-02-17 00:16:49,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:49,227:INFO:Checking exceptions
2024-02-17 00:16:49,229:INFO:Importing libraries
2024-02-17 00:16:49,229:INFO:Copying training dataset
2024-02-17 00:16:49,229:INFO:Defining folds
2024-02-17 00:16:49,229:INFO:Declaring metric variables
2024-02-17 00:16:49,229:INFO:Importing untrained model
2024-02-17 00:16:49,229:INFO:Declaring custom model
2024-02-17 00:16:49,229:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:16:49,229:INFO:Cross validation set to False
2024-02-17 00:16:49,229:INFO:Fitting Model
2024-02-17 00:16:49,388:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:16:49,388:INFO:create_model() successfully completed......................................
2024-02-17 00:16:49,517:INFO:Initializing create_model()
2024-02-17 00:16:49,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:49,517:INFO:Checking exceptions
2024-02-17 00:16:49,521:INFO:Importing libraries
2024-02-17 00:16:49,521:INFO:Copying training dataset
2024-02-17 00:16:49,523:INFO:Defining folds
2024-02-17 00:16:49,523:INFO:Declaring metric variables
2024-02-17 00:16:49,523:INFO:Importing untrained model
2024-02-17 00:16:49,523:INFO:Declaring custom model
2024-02-17 00:16:49,523:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:16:49,523:INFO:Cross validation set to False
2024-02-17 00:16:49,523:INFO:Fitting Model
2024-02-17 00:16:49,572:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:16:49,588:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.
2024-02-17 00:16:49,588:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:16:49,588:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:16:49,588:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:16:49,588:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:16:49,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:16:49,671:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:16:49,671:INFO:create_model() successfully completed......................................
2024-02-17 00:16:49,797:INFO:Initializing create_model()
2024-02-17 00:16:49,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:49,804:INFO:Checking exceptions
2024-02-17 00:16:49,805:INFO:Importing libraries
2024-02-17 00:16:49,805:INFO:Copying training dataset
2024-02-17 00:16:49,805:INFO:Defining folds
2024-02-17 00:16:49,805:INFO:Declaring metric variables
2024-02-17 00:16:49,805:INFO:Importing untrained model
2024-02-17 00:16:49,805:INFO:Declaring custom model
2024-02-17 00:16:49,813:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:16:49,813:INFO:Cross validation set to False
2024-02-17 00:16:49,813:INFO:Fitting Model
2024-02-17 00:16:50,132:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:16:50,132:INFO:create_model() successfully completed......................................
2024-02-17 00:16:50,245:INFO:Initializing create_model()
2024-02-17 00:16:50,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:16:50,245:INFO:Checking exceptions
2024-02-17 00:16:50,246:INFO:Importing libraries
2024-02-17 00:16:50,246:INFO:Copying training dataset
2024-02-17 00:16:50,246:INFO:Defining folds
2024-02-17 00:16:50,246:INFO:Declaring metric variables
2024-02-17 00:16:50,246:INFO:Importing untrained model
2024-02-17 00:16:50,246:INFO:Declaring custom model
2024-02-17 00:16:50,246:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:16:50,246:INFO:Cross validation set to False
2024-02-17 00:16:50,246:INFO:Fitting Model
2024-02-17 00:16:51,255:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:16:51,255:INFO:create_model() successfully completed......................................
2024-02-17 00:16:51,421:INFO:_master_model_container: 34
2024-02-17 00:16:51,421:INFO:_display_container: 4
2024-02-17 00:16:51,422:INFO:[<catboost.core.CatBoostClassifier object at 0x0000028DC1870670>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-02-17 00:16:51,422:INFO:compare_models() successfully completed......................................
2024-02-17 00:21:44,078:INFO:Initializing tune_model()
2024-02-17 00:21:44,079:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1870670>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:21:44,079:INFO:Checking exceptions
2024-02-17 00:21:44,154:INFO:Copying training dataset
2024-02-17 00:21:44,176:INFO:Checking base model
2024-02-17 00:21:44,176:INFO:Base model : CatBoost Classifier
2024-02-17 00:21:44,195:INFO:Declaring metric variables
2024-02-17 00:21:44,211:INFO:Defining Hyperparameters
2024-02-17 00:21:44,491:INFO:Tuning with n_jobs=-1
2024-02-17 00:21:44,491:INFO:Initializing RandomizedSearchCV
2024-02-17 00:22:51,055:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2303, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2230, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6105, in _catboost._check_train_params
  File "_catboost.pyx", line 6124, in _catboost._check_train_params
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-02-17 00:22:51,057:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84742268 0.80574374        nan 0.90029455 0.8353461  0.90795287
 0.92076583 0.82268041 0.86023564 0.88468336]
  warnings.warn(

2024-02-17 00:22:51,057:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2024-02-17 00:22:51,057:INFO:Hyperparameter search completed
2024-02-17 00:22:51,057:INFO:SubProcess create_model() called ==================================
2024-02-17 00:22:51,057:INFO:Initializing create_model()
2024-02-17 00:22:51,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DBEE6C5E0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE8907F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 250, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 8})
2024-02-17 00:22:51,057:INFO:Checking exceptions
2024-02-17 00:22:51,057:INFO:Importing libraries
2024-02-17 00:22:51,060:INFO:Copying training dataset
2024-02-17 00:22:51,065:INFO:Defining folds
2024-02-17 00:22:51,065:INFO:Declaring metric variables
2024-02-17 00:22:51,065:INFO:Importing untrained model
2024-02-17 00:22:51,065:INFO:Declaring custom model
2024-02-17 00:22:51,076:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:22:51,076:INFO:Starting cross validation
2024-02-17 00:22:51,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:22:59,206:INFO:Calculating mean and std
2024-02-17 00:22:59,207:INFO:Creating metrics dataframe
2024-02-17 00:22:59,214:INFO:Finalizing model
2024-02-17 00:23:00,732:INFO:Uploading results into container
2024-02-17 00:23:00,733:INFO:Uploading model into container now
2024-02-17 00:23:00,733:INFO:_master_model_container: 35
2024-02-17 00:23:00,733:INFO:_display_container: 5
2024-02-17 00:23:00,733:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1596D70>
2024-02-17 00:23:00,733:INFO:create_model() successfully completed......................................
2024-02-17 00:23:00,878:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:00,878:INFO:choose_better activated
2024-02-17 00:23:00,878:INFO:SubProcess create_model() called ==================================
2024-02-17 00:23:00,878:INFO:Initializing create_model()
2024-02-17 00:23:00,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1870670>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:23:00,878:INFO:Checking exceptions
2024-02-17 00:23:00,885:INFO:Importing libraries
2024-02-17 00:23:00,885:INFO:Copying training dataset
2024-02-17 00:23:00,894:INFO:Defining folds
2024-02-17 00:23:00,894:INFO:Declaring metric variables
2024-02-17 00:23:00,894:INFO:Importing untrained model
2024-02-17 00:23:00,894:INFO:Declaring custom model
2024-02-17 00:23:00,894:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:23:00,894:INFO:Starting cross validation
2024-02-17 00:23:00,894:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:23:19,120:INFO:Calculating mean and std
2024-02-17 00:23:19,120:INFO:Creating metrics dataframe
2024-02-17 00:23:19,126:INFO:Finalizing model
2024-02-17 00:23:23,409:INFO:Uploading results into container
2024-02-17 00:23:23,409:INFO:Uploading model into container now
2024-02-17 00:23:23,409:INFO:_master_model_container: 36
2024-02-17 00:23:23,409:INFO:_display_container: 6
2024-02-17 00:23:23,409:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873070>
2024-02-17 00:23:23,409:INFO:create_model() successfully completed......................................
2024-02-17 00:23:23,519:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:23,525:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873070> result for Accuracy is 0.9227
2024-02-17 00:23:23,525:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1596D70> result for Accuracy is 0.9208
2024-02-17 00:23:23,526:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873070> is best model
2024-02-17 00:23:23,526:INFO:choose_better completed
2024-02-17 00:23:23,526:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:23:23,544:INFO:_master_model_container: 36
2024-02-17 00:23:23,544:INFO:_display_container: 5
2024-02-17 00:23:23,544:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873070>
2024-02-17 00:23:23,544:INFO:tune_model() successfully completed......................................
2024-02-17 00:23:23,659:INFO:Initializing tune_model()
2024-02-17 00:23:23,659:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:23:23,659:INFO:Checking exceptions
2024-02-17 00:23:23,675:INFO:Copying training dataset
2024-02-17 00:23:23,680:INFO:Checking base model
2024-02-17 00:23:23,680:INFO:Base model : Extreme Gradient Boosting
2024-02-17 00:23:23,680:INFO:Declaring metric variables
2024-02-17 00:23:23,689:INFO:Defining Hyperparameters
2024-02-17 00:23:23,817:INFO:Tuning with n_jobs=-1
2024-02-17 00:23:23,817:INFO:Initializing RandomizedSearchCV
2024-02-17 00:23:32,291:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 13.4, 'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__colsample_bytree': 0.7}
2024-02-17 00:23:32,291:INFO:Hyperparameter search completed
2024-02-17 00:23:32,291:INFO:SubProcess create_model() called ==================================
2024-02-17 00:23:32,291:INFO:Initializing create_model()
2024-02-17 00:23:32,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBED98880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 13.4, 'reg_lambda': 0.005, 'reg_alpha': 0.005, 'n_estimators': 150, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.15, 'colsample_bytree': 0.7})
2024-02-17 00:23:32,291:INFO:Checking exceptions
2024-02-17 00:23:32,291:INFO:Importing libraries
2024-02-17 00:23:32,297:INFO:Copying training dataset
2024-02-17 00:23:32,298:INFO:Defining folds
2024-02-17 00:23:32,298:INFO:Declaring metric variables
2024-02-17 00:23:32,298:INFO:Importing untrained model
2024-02-17 00:23:32,298:INFO:Declaring custom model
2024-02-17 00:23:32,312:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:23:32,313:INFO:Starting cross validation
2024-02-17 00:23:32,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:23:33,451:INFO:Calculating mean and std
2024-02-17 00:23:33,452:INFO:Creating metrics dataframe
2024-02-17 00:23:33,452:INFO:Finalizing model
2024-02-17 00:23:33,738:INFO:Uploading results into container
2024-02-17 00:23:33,739:INFO:Uploading model into container now
2024-02-17 00:23:33,739:INFO:_master_model_container: 37
2024-02-17 00:23:33,739:INFO:_display_container: 6
2024-02-17 00:23:33,739:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:23:33,742:INFO:create_model() successfully completed......................................
2024-02-17 00:23:33,865:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:33,865:INFO:choose_better activated
2024-02-17 00:23:33,865:INFO:SubProcess create_model() called ==================================
2024-02-17 00:23:33,873:INFO:Initializing create_model()
2024-02-17 00:23:33,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:23:33,873:INFO:Checking exceptions
2024-02-17 00:23:33,873:INFO:Importing libraries
2024-02-17 00:23:33,873:INFO:Copying training dataset
2024-02-17 00:23:33,873:INFO:Defining folds
2024-02-17 00:23:33,873:INFO:Declaring metric variables
2024-02-17 00:23:33,873:INFO:Importing untrained model
2024-02-17 00:23:33,873:INFO:Declaring custom model
2024-02-17 00:23:33,873:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:23:33,873:INFO:Starting cross validation
2024-02-17 00:23:33,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:23:34,417:INFO:Calculating mean and std
2024-02-17 00:23:34,417:INFO:Creating metrics dataframe
2024-02-17 00:23:34,417:INFO:Finalizing model
2024-02-17 00:23:34,593:INFO:Uploading results into container
2024-02-17 00:23:34,593:INFO:Uploading model into container now
2024-02-17 00:23:34,593:INFO:_master_model_container: 38
2024-02-17 00:23:34,593:INFO:_display_container: 7
2024-02-17 00:23:34,593:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:23:34,593:INFO:create_model() successfully completed......................................
2024-02-17 00:23:34,750:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:34,750:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9212
2024-02-17 00:23:34,750:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9103
2024-02-17 00:23:34,750:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-02-17 00:23:34,750:INFO:choose_better completed
2024-02-17 00:23:34,750:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:23:34,766:INFO:_master_model_container: 38
2024-02-17 00:23:34,766:INFO:_display_container: 6
2024-02-17 00:23:34,775:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:23:34,775:INFO:tune_model() successfully completed......................................
2024-02-17 00:23:34,906:INFO:Initializing tune_model()
2024-02-17 00:23:34,906:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:23:34,906:INFO:Checking exceptions
2024-02-17 00:23:34,922:INFO:Copying training dataset
2024-02-17 00:23:34,938:INFO:Checking base model
2024-02-17 00:23:34,938:INFO:Base model : Light Gradient Boosting Machine
2024-02-17 00:23:34,945:INFO:Declaring metric variables
2024-02-17 00:23:34,952:INFO:Defining Hyperparameters
2024-02-17 00:23:35,081:INFO:Tuning with n_jobs=-1
2024-02-17 00:23:35,081:INFO:Initializing RandomizedSearchCV
2024-02-17 00:23:51,444:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2024-02-17 00:23:51,446:INFO:Hyperparameter search completed
2024-02-17 00:23:51,446:INFO:SubProcess create_model() called ==================================
2024-02-17 00:23:51,446:INFO:Initializing create_model()
2024-02-17 00:23:51,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBEE6C5B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.15, 'num_leaves': 8, 'n_estimators': 150, 'min_split_gain': 0.1, 'min_child_samples': 41, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2024-02-17 00:23:51,446:INFO:Checking exceptions
2024-02-17 00:23:51,446:INFO:Importing libraries
2024-02-17 00:23:51,450:INFO:Copying training dataset
2024-02-17 00:23:51,460:INFO:Defining folds
2024-02-17 00:23:51,460:INFO:Declaring metric variables
2024-02-17 00:23:51,463:INFO:Importing untrained model
2024-02-17 00:23:51,463:INFO:Declaring custom model
2024-02-17 00:23:51,474:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:23:51,483:INFO:Starting cross validation
2024-02-17 00:23:51,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:23:52,609:INFO:Calculating mean and std
2024-02-17 00:23:52,611:INFO:Creating metrics dataframe
2024-02-17 00:23:52,616:INFO:Finalizing model
2024-02-17 00:23:52,629:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:23:52,629:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:23:52,629:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:23:52,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:23:52,652:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:23:52,652:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:23:52,652:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:23:52,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.
2024-02-17 00:23:52,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 00:23:52,652:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:23:52,652:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:23:52,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:23:52,763:INFO:Uploading results into container
2024-02-17 00:23:52,763:INFO:Uploading model into container now
2024-02-17 00:23:52,763:INFO:_master_model_container: 39
2024-02-17 00:23:52,763:INFO:_display_container: 7
2024-02-17 00:23:52,763:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:23:52,763:INFO:create_model() successfully completed......................................
2024-02-17 00:23:52,916:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:52,916:INFO:choose_better activated
2024-02-17 00:23:52,916:INFO:SubProcess create_model() called ==================================
2024-02-17 00:23:52,916:INFO:Initializing create_model()
2024-02-17 00:23:52,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:23:52,916:INFO:Checking exceptions
2024-02-17 00:23:52,929:INFO:Importing libraries
2024-02-17 00:23:52,929:INFO:Copying training dataset
2024-02-17 00:23:52,929:INFO:Defining folds
2024-02-17 00:23:52,929:INFO:Declaring metric variables
2024-02-17 00:23:52,929:INFO:Importing untrained model
2024-02-17 00:23:52,929:INFO:Declaring custom model
2024-02-17 00:23:52,929:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:23:52,929:INFO:Starting cross validation
2024-02-17 00:23:52,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:23:54,875:INFO:Calculating mean and std
2024-02-17 00:23:54,878:INFO:Creating metrics dataframe
2024-02-17 00:23:54,878:INFO:Finalizing model
2024-02-17 00:23:54,910:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:23:54,910:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2024-02-17 00:23:54,910:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:23:54,910:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:23:54,910:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:23:54,924:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:23:54,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:23:55,094:INFO:Uploading results into container
2024-02-17 00:23:55,094:INFO:Uploading model into container now
2024-02-17 00:23:55,094:INFO:_master_model_container: 40
2024-02-17 00:23:55,094:INFO:_display_container: 8
2024-02-17 00:23:55,094:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:23:55,094:INFO:create_model() successfully completed......................................
2024-02-17 00:23:55,244:INFO:SubProcess create_model() end ==================================
2024-02-17 00:23:55,244:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9205
2024-02-17 00:23:55,244:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2024-02-17 00:23:55,244:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-17 00:23:55,244:INFO:choose_better completed
2024-02-17 00:23:55,244:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:23:55,262:INFO:_master_model_container: 40
2024-02-17 00:23:55,262:INFO:_display_container: 7
2024-02-17 00:23:55,262:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:23:55,262:INFO:tune_model() successfully completed......................................
2024-02-17 00:23:55,400:INFO:Initializing tune_model()
2024-02-17 00:23:55,400:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:23:55,400:INFO:Checking exceptions
2024-02-17 00:23:55,421:INFO:Copying training dataset
2024-02-17 00:23:55,427:INFO:Checking base model
2024-02-17 00:23:55,427:INFO:Base model : Random Forest Classifier
2024-02-17 00:23:55,432:INFO:Declaring metric variables
2024-02-17 00:23:55,444:INFO:Defining Hyperparameters
2024-02-17 00:23:55,604:INFO:Tuning with n_jobs=-1
2024-02-17 00:23:55,604:INFO:Initializing RandomizedSearchCV
2024-02-17 00:24:27,745:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2024-02-17 00:24:27,753:INFO:Hyperparameter search completed
2024-02-17 00:24:27,753:INFO:SubProcess create_model() called ==================================
2024-02-17 00:24:27,753:INFO:Initializing create_model()
2024-02-17 00:24:27,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1594250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0005, 'max_features': 'log2', 'max_depth': 5, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2024-02-17 00:24:27,753:INFO:Checking exceptions
2024-02-17 00:24:27,753:INFO:Importing libraries
2024-02-17 00:24:27,753:INFO:Copying training dataset
2024-02-17 00:24:27,777:INFO:Defining folds
2024-02-17 00:24:27,777:INFO:Declaring metric variables
2024-02-17 00:24:27,793:INFO:Importing untrained model
2024-02-17 00:24:27,793:INFO:Declaring custom model
2024-02-17 00:24:27,809:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:24:27,841:INFO:Starting cross validation
2024-02-17 00:24:27,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:24:31,378:INFO:Calculating mean and std
2024-02-17 00:24:31,378:INFO:Creating metrics dataframe
2024-02-17 00:24:31,403:INFO:Finalizing model
2024-02-17 00:24:32,145:INFO:Uploading results into container
2024-02-17 00:24:32,153:INFO:Uploading model into container now
2024-02-17 00:24:32,153:INFO:_master_model_container: 41
2024-02-17 00:24:32,153:INFO:_display_container: 8
2024-02-17 00:24:32,153:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:24:32,153:INFO:create_model() successfully completed......................................
2024-02-17 00:24:32,412:INFO:SubProcess create_model() end ==================================
2024-02-17 00:24:32,412:INFO:choose_better activated
2024-02-17 00:24:32,426:INFO:SubProcess create_model() called ==================================
2024-02-17 00:24:32,428:INFO:Initializing create_model()
2024-02-17 00:24:32,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:24:32,428:INFO:Checking exceptions
2024-02-17 00:24:32,436:INFO:Importing libraries
2024-02-17 00:24:32,436:INFO:Copying training dataset
2024-02-17 00:24:32,452:INFO:Defining folds
2024-02-17 00:24:32,452:INFO:Declaring metric variables
2024-02-17 00:24:32,452:INFO:Importing untrained model
2024-02-17 00:24:32,452:INFO:Declaring custom model
2024-02-17 00:24:32,460:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:24:32,460:INFO:Starting cross validation
2024-02-17 00:24:32,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:24:37,983:INFO:Calculating mean and std
2024-02-17 00:24:37,983:INFO:Creating metrics dataframe
2024-02-17 00:24:37,983:INFO:Finalizing model
2024-02-17 00:24:39,065:INFO:Uploading results into container
2024-02-17 00:24:39,065:INFO:Uploading model into container now
2024-02-17 00:24:39,065:INFO:_master_model_container: 42
2024-02-17 00:24:39,065:INFO:_display_container: 9
2024-02-17 00:24:39,065:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:24:39,065:INFO:create_model() successfully completed......................................
2024-02-17 00:24:39,285:INFO:SubProcess create_model() end ==================================
2024-02-17 00:24:39,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.9162
2024-02-17 00:24:39,291:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.8414
2024-02-17 00:24:39,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) is best model
2024-02-17 00:24:39,291:INFO:choose_better completed
2024-02-17 00:24:39,291:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:24:39,332:INFO:_master_model_container: 42
2024-02-17 00:24:39,336:INFO:_display_container: 8
2024-02-17 00:24:39,336:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:24:39,336:INFO:tune_model() successfully completed......................................
2024-02-17 00:24:39,600:INFO:Initializing tune_model()
2024-02-17 00:24:39,600:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:24:39,600:INFO:Checking exceptions
2024-02-17 00:24:39,664:INFO:Copying training dataset
2024-02-17 00:24:39,680:INFO:Checking base model
2024-02-17 00:24:39,680:INFO:Base model : Gradient Boosting Classifier
2024-02-17 00:24:39,688:INFO:Declaring metric variables
2024-02-17 00:24:39,696:INFO:Defining Hyperparameters
2024-02-17 00:24:39,978:INFO:Tuning with n_jobs=-1
2024-02-17 00:24:39,978:INFO:Initializing RandomizedSearchCV
2024-02-17 00:26:16,718:INFO:best_params: {'actual_estimator__subsample': 0.6, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__learning_rate': 0.2}
2024-02-17 00:26:16,724:INFO:Hyperparameter search completed
2024-02-17 00:26:16,726:INFO:SubProcess create_model() called ==================================
2024-02-17 00:26:16,726:INFO:Initializing create_model()
2024-02-17 00:26:16,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBED98880>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.6, 'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 9, 'learning_rate': 0.2})
2024-02-17 00:26:16,731:INFO:Checking exceptions
2024-02-17 00:26:16,731:INFO:Importing libraries
2024-02-17 00:26:16,731:INFO:Copying training dataset
2024-02-17 00:26:16,751:INFO:Defining folds
2024-02-17 00:26:16,751:INFO:Declaring metric variables
2024-02-17 00:26:16,757:INFO:Importing untrained model
2024-02-17 00:26:16,757:INFO:Declaring custom model
2024-02-17 00:26:16,776:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:26:16,801:INFO:Starting cross validation
2024-02-17 00:26:16,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:27:00,698:INFO:Calculating mean and std
2024-02-17 00:27:00,698:INFO:Creating metrics dataframe
2024-02-17 00:27:00,723:INFO:Finalizing model
2024-02-17 00:27:20,321:INFO:Uploading results into container
2024-02-17 00:27:20,321:INFO:Uploading model into container now
2024-02-17 00:27:20,326:INFO:_master_model_container: 43
2024-02-17 00:27:20,326:INFO:_display_container: 9
2024-02-17 00:27:20,326:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=3957, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:27:20,326:INFO:create_model() successfully completed......................................
2024-02-17 00:27:20,580:INFO:SubProcess create_model() end ==================================
2024-02-17 00:27:20,580:INFO:choose_better activated
2024-02-17 00:27:20,596:INFO:SubProcess create_model() called ==================================
2024-02-17 00:27:20,596:INFO:Initializing create_model()
2024-02-17 00:27:20,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:27:20,596:INFO:Checking exceptions
2024-02-17 00:27:20,606:INFO:Importing libraries
2024-02-17 00:27:20,606:INFO:Copying training dataset
2024-02-17 00:27:20,611:INFO:Defining folds
2024-02-17 00:27:20,611:INFO:Declaring metric variables
2024-02-17 00:27:20,611:INFO:Importing untrained model
2024-02-17 00:27:20,611:INFO:Declaring custom model
2024-02-17 00:27:20,627:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:27:20,627:INFO:Starting cross validation
2024-02-17 00:27:20,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:27:28,644:INFO:Calculating mean and std
2024-02-17 00:27:28,644:INFO:Creating metrics dataframe
2024-02-17 00:27:28,650:INFO:Finalizing model
2024-02-17 00:27:32,294:INFO:Uploading results into container
2024-02-17 00:27:32,294:INFO:Uploading model into container now
2024-02-17 00:27:32,294:INFO:_master_model_container: 44
2024-02-17 00:27:32,294:INFO:_display_container: 10
2024-02-17 00:27:32,294:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:27:32,294:INFO:create_model() successfully completed......................................
2024-02-17 00:27:32,566:INFO:SubProcess create_model() end ==================================
2024-02-17 00:27:32,566:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8999
2024-02-17 00:27:32,566:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=3957, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.9258
2024-02-17 00:27:32,566:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=3957, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-02-17 00:27:32,566:INFO:choose_better completed
2024-02-17 00:27:32,595:INFO:_master_model_container: 44
2024-02-17 00:27:32,595:INFO:_display_container: 9
2024-02-17 00:27:32,609:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=3957, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:27:32,609:INFO:tune_model() successfully completed......................................
2024-02-17 00:30:32,269:INFO:Initializing blend_models()
2024-02-17 00:30:32,269:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x0000028DC1873070>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.2, loss='log_loss', max_depth=9,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=250, n_iter_no_change=None,
                           random_state=3957, subsample=0.6, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-17 00:30:32,269:INFO:Checking exceptions
2024-02-17 00:30:32,336:INFO:Importing libraries
2024-02-17 00:30:32,336:INFO:Copying training dataset
2024-02-17 00:30:32,351:INFO:Getting model names
2024-02-17 00:30:32,367:INFO:SubProcess create_model() called ==================================
2024-02-17 00:30:32,400:INFO:Initializing create_model()
2024-02-17 00:30:32,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1873070>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                         max_depth=9,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=250,
                                                         n_iter_no_change=None,
                                                         random_state=3957,
                                                         subsample=0.6,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE810F70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:30:32,400:INFO:Checking exceptions
2024-02-17 00:30:32,400:INFO:Importing libraries
2024-02-17 00:30:32,408:INFO:Copying training dataset
2024-02-17 00:30:32,434:INFO:Defining folds
2024-02-17 00:30:32,434:INFO:Declaring metric variables
2024-02-17 00:30:32,444:INFO:Importing untrained model
2024-02-17 00:30:32,451:INFO:Declaring custom model
2024-02-17 00:30:32,476:INFO:Voting Classifier Imported successfully
2024-02-17 00:30:32,507:INFO:Starting cross validation
2024-02-17 00:30:32,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:31:07,203:INFO:Calculating mean and std
2024-02-17 00:31:07,203:INFO:Creating metrics dataframe
2024-02-17 00:31:07,213:INFO:Finalizing model
2024-02-17 00:31:14,065:INFO:Uploading results into container
2024-02-17 00:31:14,067:INFO:Uploading model into container now
2024-02-17 00:31:14,067:INFO:_master_model_container: 45
2024-02-17 00:31:14,067:INFO:_display_container: 10
2024-02-17 00:31:14,072:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC18B00A0>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                         max_depth=9,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=250,
                                                         n_iter_no_change=None,
                                                         random_state=3957,
                                                         subsample=0.6,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:31:14,072:INFO:create_model() successfully completed......................................
2024-02-17 00:31:14,201:INFO:SubProcess create_model() end ==================================
2024-02-17 00:31:14,208:INFO:_master_model_container: 45
2024-02-17 00:31:14,208:INFO:_display_container: 10
2024-02-17 00:31:14,222:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC18B00A0>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                         max_depth=9,
                                                         max_features=1.0,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=250,
                                                         n_iter_no_change=None,
                                                         random_state=3957,
                                                         subsample=0.6,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:31:14,222:INFO:blend_models() successfully completed......................................
2024-02-17 00:34:02,938:INFO:Initializing compare_models()
2024-02-17 00:34:02,938:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 00:34:02,938:INFO:Checking exceptions
2024-02-17 00:34:02,945:INFO:Preparing display monitor
2024-02-17 00:34:02,969:INFO:Initializing Logistic Regression
2024-02-17 00:34:02,969:INFO:Total runtime is 0.0 minutes
2024-02-17 00:34:02,973:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:02,973:INFO:Initializing create_model()
2024-02-17 00:34:02,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:02,973:INFO:Checking exceptions
2024-02-17 00:34:02,973:INFO:Importing libraries
2024-02-17 00:34:02,973:INFO:Copying training dataset
2024-02-17 00:34:02,978:INFO:Defining folds
2024-02-17 00:34:02,978:INFO:Declaring metric variables
2024-02-17 00:34:02,986:INFO:Importing untrained model
2024-02-17 00:34:02,994:INFO:Logistic Regression Imported successfully
2024-02-17 00:34:02,999:INFO:Starting cross validation
2024-02-17 00:34:02,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:03,957:INFO:Calculating mean and std
2024-02-17 00:34:03,957:INFO:Creating metrics dataframe
2024-02-17 00:34:03,962:INFO:Uploading results into container
2024-02-17 00:34:03,962:INFO:Uploading model into container now
2024-02-17 00:34:03,962:INFO:_master_model_container: 46
2024-02-17 00:34:03,964:INFO:_display_container: 11
2024-02-17 00:34:03,964:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3957, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 00:34:03,964:INFO:create_model() successfully completed......................................
2024-02-17 00:34:04,078:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:04,079:INFO:Creating metrics dataframe
2024-02-17 00:34:04,079:INFO:Initializing K Neighbors Classifier
2024-02-17 00:34:04,079:INFO:Total runtime is 0.018487008412679036 minutes
2024-02-17 00:34:04,079:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:04,079:INFO:Initializing create_model()
2024-02-17 00:34:04,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:04,079:INFO:Checking exceptions
2024-02-17 00:34:04,079:INFO:Importing libraries
2024-02-17 00:34:04,079:INFO:Copying training dataset
2024-02-17 00:34:04,096:INFO:Defining folds
2024-02-17 00:34:04,096:INFO:Declaring metric variables
2024-02-17 00:34:04,100:INFO:Importing untrained model
2024-02-17 00:34:04,100:INFO:K Neighbors Classifier Imported successfully
2024-02-17 00:34:04,111:INFO:Starting cross validation
2024-02-17 00:34:04,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:04,328:INFO:Calculating mean and std
2024-02-17 00:34:04,329:INFO:Creating metrics dataframe
2024-02-17 00:34:04,329:INFO:Uploading results into container
2024-02-17 00:34:04,329:INFO:Uploading model into container now
2024-02-17 00:34:04,329:INFO:_master_model_container: 47
2024-02-17 00:34:04,329:INFO:_display_container: 11
2024-02-17 00:34:04,329:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 00:34:04,337:INFO:create_model() successfully completed......................................
2024-02-17 00:34:04,462:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:04,462:INFO:Creating metrics dataframe
2024-02-17 00:34:04,466:INFO:Initializing Naive Bayes
2024-02-17 00:34:04,466:INFO:Total runtime is 0.02494887908299764 minutes
2024-02-17 00:34:04,478:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:04,478:INFO:Initializing create_model()
2024-02-17 00:34:04,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:04,478:INFO:Checking exceptions
2024-02-17 00:34:04,478:INFO:Importing libraries
2024-02-17 00:34:04,478:INFO:Copying training dataset
2024-02-17 00:34:04,482:INFO:Defining folds
2024-02-17 00:34:04,482:INFO:Declaring metric variables
2024-02-17 00:34:04,482:INFO:Importing untrained model
2024-02-17 00:34:04,493:INFO:Naive Bayes Imported successfully
2024-02-17 00:34:04,500:INFO:Starting cross validation
2024-02-17 00:34:04,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:04,589:INFO:Calculating mean and std
2024-02-17 00:34:04,589:INFO:Creating metrics dataframe
2024-02-17 00:34:04,589:INFO:Uploading results into container
2024-02-17 00:34:04,589:INFO:Uploading model into container now
2024-02-17 00:34:04,589:INFO:_master_model_container: 48
2024-02-17 00:34:04,589:INFO:_display_container: 11
2024-02-17 00:34:04,589:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 00:34:04,589:INFO:create_model() successfully completed......................................
2024-02-17 00:34:04,704:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:04,704:INFO:Creating metrics dataframe
2024-02-17 00:34:04,714:INFO:Initializing Decision Tree Classifier
2024-02-17 00:34:04,714:INFO:Total runtime is 0.029079516728719078 minutes
2024-02-17 00:34:04,714:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:04,714:INFO:Initializing create_model()
2024-02-17 00:34:04,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:04,714:INFO:Checking exceptions
2024-02-17 00:34:04,714:INFO:Importing libraries
2024-02-17 00:34:04,714:INFO:Copying training dataset
2024-02-17 00:34:04,726:INFO:Defining folds
2024-02-17 00:34:04,726:INFO:Declaring metric variables
2024-02-17 00:34:04,728:INFO:Importing untrained model
2024-02-17 00:34:04,732:INFO:Decision Tree Classifier Imported successfully
2024-02-17 00:34:04,745:INFO:Starting cross validation
2024-02-17 00:34:04,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:04,891:INFO:Calculating mean and std
2024-02-17 00:34:04,891:INFO:Creating metrics dataframe
2024-02-17 00:34:04,891:INFO:Uploading results into container
2024-02-17 00:34:04,900:INFO:Uploading model into container now
2024-02-17 00:34:04,900:INFO:_master_model_container: 49
2024-02-17 00:34:04,900:INFO:_display_container: 11
2024-02-17 00:34:04,900:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3957, splitter='best')
2024-02-17 00:34:04,900:INFO:create_model() successfully completed......................................
2024-02-17 00:34:05,010:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:05,010:INFO:Creating metrics dataframe
2024-02-17 00:34:05,028:INFO:Initializing SVM - Linear Kernel
2024-02-17 00:34:05,028:INFO:Total runtime is 0.034312276045481364 minutes
2024-02-17 00:34:05,030:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:05,030:INFO:Initializing create_model()
2024-02-17 00:34:05,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:05,030:INFO:Checking exceptions
2024-02-17 00:34:05,030:INFO:Importing libraries
2024-02-17 00:34:05,030:INFO:Copying training dataset
2024-02-17 00:34:05,030:INFO:Defining folds
2024-02-17 00:34:05,030:INFO:Declaring metric variables
2024-02-17 00:34:05,043:INFO:Importing untrained model
2024-02-17 00:34:05,047:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 00:34:05,052:INFO:Starting cross validation
2024-02-17 00:34:05,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:05,200:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,217:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,217:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,221:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,238:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,251:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,262:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,265:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,314:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,339:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,350:INFO:Calculating mean and std
2024-02-17 00:34:05,350:INFO:Creating metrics dataframe
2024-02-17 00:34:05,350:INFO:Uploading results into container
2024-02-17 00:34:05,350:INFO:Uploading model into container now
2024-02-17 00:34:05,350:INFO:_master_model_container: 50
2024-02-17 00:34:05,350:INFO:_display_container: 11
2024-02-17 00:34:05,350:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3957, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 00:34:05,350:INFO:create_model() successfully completed......................................
2024-02-17 00:34:05,469:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:05,469:INFO:Creating metrics dataframe
2024-02-17 00:34:05,478:INFO:Initializing Ridge Classifier
2024-02-17 00:34:05,478:INFO:Total runtime is 0.041814943154652916 minutes
2024-02-17 00:34:05,482:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:05,482:INFO:Initializing create_model()
2024-02-17 00:34:05,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:05,482:INFO:Checking exceptions
2024-02-17 00:34:05,482:INFO:Importing libraries
2024-02-17 00:34:05,482:INFO:Copying training dataset
2024-02-17 00:34:05,482:INFO:Defining folds
2024-02-17 00:34:05,482:INFO:Declaring metric variables
2024-02-17 00:34:05,482:INFO:Importing untrained model
2024-02-17 00:34:05,495:INFO:Ridge Classifier Imported successfully
2024-02-17 00:34:05,501:INFO:Starting cross validation
2024-02-17 00:34:05,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:05,553:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,553:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,553:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,553:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,557:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,557:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,567:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,574:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,589:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,595:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:34:05,619:INFO:Calculating mean and std
2024-02-17 00:34:05,619:INFO:Creating metrics dataframe
2024-02-17 00:34:05,619:INFO:Uploading results into container
2024-02-17 00:34:05,619:INFO:Uploading model into container now
2024-02-17 00:34:05,619:INFO:_master_model_container: 51
2024-02-17 00:34:05,619:INFO:_display_container: 11
2024-02-17 00:34:05,619:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3957, solver='auto',
                tol=0.0001)
2024-02-17 00:34:05,619:INFO:create_model() successfully completed......................................
2024-02-17 00:34:05,731:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:05,731:INFO:Creating metrics dataframe
2024-02-17 00:34:05,749:INFO:Initializing Random Forest Classifier
2024-02-17 00:34:05,749:INFO:Total runtime is 0.046332041422526046 minutes
2024-02-17 00:34:05,749:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:05,749:INFO:Initializing create_model()
2024-02-17 00:34:05,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:05,749:INFO:Checking exceptions
2024-02-17 00:34:05,749:INFO:Importing libraries
2024-02-17 00:34:05,749:INFO:Copying training dataset
2024-02-17 00:34:05,757:INFO:Defining folds
2024-02-17 00:34:05,757:INFO:Declaring metric variables
2024-02-17 00:34:05,757:INFO:Importing untrained model
2024-02-17 00:34:05,768:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:34:05,784:INFO:Starting cross validation
2024-02-17 00:34:05,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:07,960:INFO:Calculating mean and std
2024-02-17 00:34:07,960:INFO:Creating metrics dataframe
2024-02-17 00:34:07,960:INFO:Uploading results into container
2024-02-17 00:34:07,960:INFO:Uploading model into container now
2024-02-17 00:34:07,960:INFO:_master_model_container: 52
2024-02-17 00:34:07,960:INFO:_display_container: 11
2024-02-17 00:34:07,960:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:34:07,960:INFO:create_model() successfully completed......................................
2024-02-17 00:34:08,089:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:08,089:INFO:Creating metrics dataframe
2024-02-17 00:34:08,102:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 00:34:08,102:INFO:Total runtime is 0.08555041948954265 minutes
2024-02-17 00:34:08,105:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:08,105:INFO:Initializing create_model()
2024-02-17 00:34:08,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:08,105:INFO:Checking exceptions
2024-02-17 00:34:08,105:INFO:Importing libraries
2024-02-17 00:34:08,105:INFO:Copying training dataset
2024-02-17 00:34:08,116:INFO:Defining folds
2024-02-17 00:34:08,116:INFO:Declaring metric variables
2024-02-17 00:34:08,116:INFO:Importing untrained model
2024-02-17 00:34:08,129:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 00:34:08,140:INFO:Starting cross validation
2024-02-17 00:34:08,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:08,290:INFO:Calculating mean and std
2024-02-17 00:34:08,290:INFO:Creating metrics dataframe
2024-02-17 00:34:08,295:INFO:Uploading results into container
2024-02-17 00:34:08,296:INFO:Uploading model into container now
2024-02-17 00:34:08,296:INFO:_master_model_container: 53
2024-02-17 00:34:08,296:INFO:_display_container: 11
2024-02-17 00:34:08,296:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 00:34:08,296:INFO:create_model() successfully completed......................................
2024-02-17 00:34:08,413:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:08,413:INFO:Creating metrics dataframe
2024-02-17 00:34:08,449:INFO:Initializing Ada Boost Classifier
2024-02-17 00:34:08,449:INFO:Total runtime is 0.09132720232009887 minutes
2024-02-17 00:34:08,449:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:08,449:INFO:Initializing create_model()
2024-02-17 00:34:08,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:08,449:INFO:Checking exceptions
2024-02-17 00:34:08,449:INFO:Importing libraries
2024-02-17 00:34:08,449:INFO:Copying training dataset
2024-02-17 00:34:08,465:INFO:Defining folds
2024-02-17 00:34:08,465:INFO:Declaring metric variables
2024-02-17 00:34:08,465:INFO:Importing untrained model
2024-02-17 00:34:08,478:INFO:Ada Boost Classifier Imported successfully
2024-02-17 00:34:08,490:INFO:Starting cross validation
2024-02-17 00:34:08,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:09,662:INFO:Calculating mean and std
2024-02-17 00:34:09,662:INFO:Creating metrics dataframe
2024-02-17 00:34:09,662:INFO:Uploading results into container
2024-02-17 00:34:09,662:INFO:Uploading model into container now
2024-02-17 00:34:09,662:INFO:_master_model_container: 54
2024-02-17 00:34:09,662:INFO:_display_container: 11
2024-02-17 00:34:09,662:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3957)
2024-02-17 00:34:09,662:INFO:create_model() successfully completed......................................
2024-02-17 00:34:09,788:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:09,788:INFO:Creating metrics dataframe
2024-02-17 00:34:09,812:INFO:Initializing Gradient Boosting Classifier
2024-02-17 00:34:09,812:INFO:Total runtime is 0.11403967142105102 minutes
2024-02-17 00:34:09,813:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:09,813:INFO:Initializing create_model()
2024-02-17 00:34:09,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:09,813:INFO:Checking exceptions
2024-02-17 00:34:09,813:INFO:Importing libraries
2024-02-17 00:34:09,813:INFO:Copying training dataset
2024-02-17 00:34:09,813:INFO:Defining folds
2024-02-17 00:34:09,813:INFO:Declaring metric variables
2024-02-17 00:34:09,832:INFO:Importing untrained model
2024-02-17 00:34:09,835:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:34:09,845:INFO:Starting cross validation
2024-02-17 00:34:09,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:12,338:INFO:Calculating mean and std
2024-02-17 00:34:12,338:INFO:Creating metrics dataframe
2024-02-17 00:34:12,338:INFO:Uploading results into container
2024-02-17 00:34:12,338:INFO:Uploading model into container now
2024-02-17 00:34:12,338:INFO:_master_model_container: 55
2024-02-17 00:34:12,338:INFO:_display_container: 11
2024-02-17 00:34:12,338:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:34:12,338:INFO:create_model() successfully completed......................................
2024-02-17 00:34:12,443:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:12,443:INFO:Creating metrics dataframe
2024-02-17 00:34:12,464:INFO:Initializing Linear Discriminant Analysis
2024-02-17 00:34:12,464:INFO:Total runtime is 0.15823858578999836 minutes
2024-02-17 00:34:12,465:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:12,465:INFO:Initializing create_model()
2024-02-17 00:34:12,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:12,465:INFO:Checking exceptions
2024-02-17 00:34:12,465:INFO:Importing libraries
2024-02-17 00:34:12,465:INFO:Copying training dataset
2024-02-17 00:34:12,465:INFO:Defining folds
2024-02-17 00:34:12,465:INFO:Declaring metric variables
2024-02-17 00:34:12,465:INFO:Importing untrained model
2024-02-17 00:34:12,479:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 00:34:12,487:INFO:Starting cross validation
2024-02-17 00:34:12,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:12,591:INFO:Calculating mean and std
2024-02-17 00:34:12,592:INFO:Creating metrics dataframe
2024-02-17 00:34:12,596:INFO:Uploading results into container
2024-02-17 00:34:12,596:INFO:Uploading model into container now
2024-02-17 00:34:12,597:INFO:_master_model_container: 56
2024-02-17 00:34:12,597:INFO:_display_container: 11
2024-02-17 00:34:12,597:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 00:34:12,597:INFO:create_model() successfully completed......................................
2024-02-17 00:34:12,703:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:12,703:INFO:Creating metrics dataframe
2024-02-17 00:34:12,716:INFO:Initializing Extra Trees Classifier
2024-02-17 00:34:12,716:INFO:Total runtime is 0.16243582566579182 minutes
2024-02-17 00:34:12,716:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:12,716:INFO:Initializing create_model()
2024-02-17 00:34:12,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:12,716:INFO:Checking exceptions
2024-02-17 00:34:12,716:INFO:Importing libraries
2024-02-17 00:34:12,716:INFO:Copying training dataset
2024-02-17 00:34:12,729:INFO:Defining folds
2024-02-17 00:34:12,729:INFO:Declaring metric variables
2024-02-17 00:34:12,734:INFO:Importing untrained model
2024-02-17 00:34:12,736:INFO:Extra Trees Classifier Imported successfully
2024-02-17 00:34:12,745:INFO:Starting cross validation
2024-02-17 00:34:12,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:14,191:INFO:Calculating mean and std
2024-02-17 00:34:14,191:INFO:Creating metrics dataframe
2024-02-17 00:34:14,195:INFO:Uploading results into container
2024-02-17 00:34:14,199:INFO:Uploading model into container now
2024-02-17 00:34:14,199:INFO:_master_model_container: 57
2024-02-17 00:34:14,199:INFO:_display_container: 11
2024-02-17 00:34:14,199:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:34:14,199:INFO:create_model() successfully completed......................................
2024-02-17 00:34:14,313:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:14,313:INFO:Creating metrics dataframe
2024-02-17 00:34:14,325:INFO:Initializing Extreme Gradient Boosting
2024-02-17 00:34:14,325:INFO:Total runtime is 0.1892533540725708 minutes
2024-02-17 00:34:14,325:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:14,325:INFO:Initializing create_model()
2024-02-17 00:34:14,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:14,325:INFO:Checking exceptions
2024-02-17 00:34:14,325:INFO:Importing libraries
2024-02-17 00:34:14,325:INFO:Copying training dataset
2024-02-17 00:34:14,325:INFO:Defining folds
2024-02-17 00:34:14,325:INFO:Declaring metric variables
2024-02-17 00:34:14,340:INFO:Importing untrained model
2024-02-17 00:34:14,347:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:34:14,352:INFO:Starting cross validation
2024-02-17 00:34:14,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:14,845:INFO:Calculating mean and std
2024-02-17 00:34:14,846:INFO:Creating metrics dataframe
2024-02-17 00:34:14,846:INFO:Uploading results into container
2024-02-17 00:34:14,846:INFO:Uploading model into container now
2024-02-17 00:34:14,846:INFO:_master_model_container: 58
2024-02-17 00:34:14,846:INFO:_display_container: 11
2024-02-17 00:34:14,846:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:34:14,846:INFO:create_model() successfully completed......................................
2024-02-17 00:34:14,963:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:14,963:INFO:Creating metrics dataframe
2024-02-17 00:34:14,980:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 00:34:14,980:INFO:Total runtime is 0.2001773993174235 minutes
2024-02-17 00:34:14,982:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:14,982:INFO:Initializing create_model()
2024-02-17 00:34:14,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:14,982:INFO:Checking exceptions
2024-02-17 00:34:14,982:INFO:Importing libraries
2024-02-17 00:34:14,982:INFO:Copying training dataset
2024-02-17 00:34:14,989:INFO:Defining folds
2024-02-17 00:34:14,989:INFO:Declaring metric variables
2024-02-17 00:34:14,989:INFO:Importing untrained model
2024-02-17 00:34:14,998:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:34:15,001:INFO:Starting cross validation
2024-02-17 00:34:15,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:16,287:INFO:Calculating mean and std
2024-02-17 00:34:16,287:INFO:Creating metrics dataframe
2024-02-17 00:34:16,294:INFO:Uploading results into container
2024-02-17 00:34:16,294:INFO:Uploading model into container now
2024-02-17 00:34:16,295:INFO:_master_model_container: 59
2024-02-17 00:34:16,295:INFO:_display_container: 11
2024-02-17 00:34:16,295:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:34:16,295:INFO:create_model() successfully completed......................................
2024-02-17 00:34:16,415:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:16,415:INFO:Creating metrics dataframe
2024-02-17 00:34:16,433:INFO:Initializing CatBoost Classifier
2024-02-17 00:34:16,433:INFO:Total runtime is 0.22439242204030355 minutes
2024-02-17 00:34:16,437:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:16,437:INFO:Initializing create_model()
2024-02-17 00:34:16,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:16,437:INFO:Checking exceptions
2024-02-17 00:34:16,437:INFO:Importing libraries
2024-02-17 00:34:16,437:INFO:Copying training dataset
2024-02-17 00:34:16,448:INFO:Defining folds
2024-02-17 00:34:16,448:INFO:Declaring metric variables
2024-02-17 00:34:16,448:INFO:Importing untrained model
2024-02-17 00:34:16,448:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:34:16,462:INFO:Starting cross validation
2024-02-17 00:34:16,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:34,095:INFO:Calculating mean and std
2024-02-17 00:34:34,095:INFO:Creating metrics dataframe
2024-02-17 00:34:34,100:INFO:Uploading results into container
2024-02-17 00:34:34,102:INFO:Uploading model into container now
2024-02-17 00:34:34,102:INFO:_master_model_container: 60
2024-02-17 00:34:34,102:INFO:_display_container: 11
2024-02-17 00:34:34,102:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC18B33D0>
2024-02-17 00:34:34,102:INFO:create_model() successfully completed......................................
2024-02-17 00:34:34,206:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:34,206:INFO:Creating metrics dataframe
2024-02-17 00:34:34,230:INFO:Initializing Dummy Classifier
2024-02-17 00:34:34,233:INFO:Total runtime is 0.5210619489351909 minutes
2024-02-17 00:34:34,233:INFO:SubProcess create_model() called ==================================
2024-02-17 00:34:34,233:INFO:Initializing create_model()
2024-02-17 00:34:34,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE866C80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:34,233:INFO:Checking exceptions
2024-02-17 00:34:34,233:INFO:Importing libraries
2024-02-17 00:34:34,233:INFO:Copying training dataset
2024-02-17 00:34:34,233:INFO:Defining folds
2024-02-17 00:34:34,233:INFO:Declaring metric variables
2024-02-17 00:34:34,246:INFO:Importing untrained model
2024-02-17 00:34:34,250:INFO:Dummy Classifier Imported successfully
2024-02-17 00:34:34,250:INFO:Starting cross validation
2024-02-17 00:34:34,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:34:34,310:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:34:34,310:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:34:34,310:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:34:34,310:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:34:34,310:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:34:34,342:INFO:Calculating mean and std
2024-02-17 00:34:34,342:INFO:Creating metrics dataframe
2024-02-17 00:34:34,342:INFO:Uploading results into container
2024-02-17 00:34:34,342:INFO:Uploading model into container now
2024-02-17 00:34:34,342:INFO:_master_model_container: 61
2024-02-17 00:34:34,342:INFO:_display_container: 11
2024-02-17 00:34:34,342:INFO:DummyClassifier(constant=None, random_state=3957, strategy='prior')
2024-02-17 00:34:34,342:INFO:create_model() successfully completed......................................
2024-02-17 00:34:34,459:INFO:SubProcess create_model() end ==================================
2024-02-17 00:34:34,459:INFO:Creating metrics dataframe
2024-02-17 00:34:34,490:INFO:Initializing create_model()
2024-02-17 00:34:34,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC18B33D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:34,490:INFO:Checking exceptions
2024-02-17 00:34:34,490:INFO:Importing libraries
2024-02-17 00:34:34,490:INFO:Copying training dataset
2024-02-17 00:34:34,499:INFO:Defining folds
2024-02-17 00:34:34,499:INFO:Declaring metric variables
2024-02-17 00:34:34,499:INFO:Importing untrained model
2024-02-17 00:34:34,499:INFO:Declaring custom model
2024-02-17 00:34:34,499:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:34:34,499:INFO:Cross validation set to False
2024-02-17 00:34:34,499:INFO:Fitting Model
2024-02-17 00:34:37,822:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC18B2110>
2024-02-17 00:34:37,822:INFO:create_model() successfully completed......................................
2024-02-17 00:34:37,957:INFO:Initializing create_model()
2024-02-17 00:34:37,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:37,957:INFO:Checking exceptions
2024-02-17 00:34:37,958:INFO:Importing libraries
2024-02-17 00:34:37,958:INFO:Copying training dataset
2024-02-17 00:34:37,958:INFO:Defining folds
2024-02-17 00:34:37,958:INFO:Declaring metric variables
2024-02-17 00:34:37,958:INFO:Importing untrained model
2024-02-17 00:34:37,958:INFO:Declaring custom model
2024-02-17 00:34:37,966:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:34:37,966:INFO:Cross validation set to False
2024-02-17 00:34:37,966:INFO:Fitting Model
2024-02-17 00:34:38,069:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:34:38,069:INFO:create_model() successfully completed......................................
2024-02-17 00:34:38,203:INFO:Initializing create_model()
2024-02-17 00:34:38,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:38,206:INFO:Checking exceptions
2024-02-17 00:34:38,208:INFO:Importing libraries
2024-02-17 00:34:38,208:INFO:Copying training dataset
2024-02-17 00:34:38,208:INFO:Defining folds
2024-02-17 00:34:38,208:INFO:Declaring metric variables
2024-02-17 00:34:38,208:INFO:Importing untrained model
2024-02-17 00:34:38,208:INFO:Declaring custom model
2024-02-17 00:34:38,208:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:34:38,213:INFO:Cross validation set to False
2024-02-17 00:34:38,213:INFO:Fitting Model
2024-02-17 00:34:38,229:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:34:38,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.
2024-02-17 00:34:38,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 00:34:38,230:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:34:38,230:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:34:38,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:34:38,293:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:34:38,293:INFO:create_model() successfully completed......................................
2024-02-17 00:34:38,437:INFO:Initializing create_model()
2024-02-17 00:34:38,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:34:38,437:INFO:Checking exceptions
2024-02-17 00:34:38,443:INFO:Importing libraries
2024-02-17 00:34:38,443:INFO:Copying training dataset
2024-02-17 00:34:38,443:INFO:Defining folds
2024-02-17 00:34:38,443:INFO:Declaring metric variables
2024-02-17 00:34:38,443:INFO:Importing untrained model
2024-02-17 00:34:38,443:INFO:Declaring custom model
2024-02-17 00:34:38,449:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:34:38,449:INFO:Cross validation set to False
2024-02-17 00:34:38,449:INFO:Fitting Model
2024-02-17 00:34:38,763:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:34:38,763:INFO:create_model() successfully completed......................................
2024-02-17 00:34:38,898:INFO:_master_model_container: 61
2024-02-17 00:34:38,898:INFO:_display_container: 11
2024-02-17 00:34:38,906:INFO:[<catboost.core.CatBoostClassifier object at 0x0000028DC18B2110>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)]
2024-02-17 00:34:38,906:INFO:compare_models() successfully completed......................................
2024-02-17 00:35:02,606:INFO:Initializing tune_model()
2024-02-17 00:35:02,606:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC18B2110>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:35:02,606:INFO:Checking exceptions
2024-02-17 00:35:02,632:INFO:Copying training dataset
2024-02-17 00:35:02,632:INFO:Checking base model
2024-02-17 00:35:02,632:INFO:Base model : CatBoost Classifier
2024-02-17 00:35:02,639:INFO:Declaring metric variables
2024-02-17 00:35:02,639:INFO:Defining Hyperparameters
2024-02-17 00:35:02,775:INFO:Tuning with n_jobs=-1
2024-02-17 00:35:02,775:INFO:Initializing RandomizedSearchCV
2024-02-17 00:36:08,416:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2303, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2230, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6105, in _catboost._check_train_params
  File "_catboost.pyx", line 6124, in _catboost._check_train_params
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-02-17 00:36:08,416:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84742268 0.80574374        nan 0.90029455 0.8353461  0.90795287
 0.92076583 0.82268041 0.86023564 0.88468336]
  warnings.warn(

2024-02-17 00:36:08,416:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2024-02-17 00:36:08,416:INFO:Hyperparameter search completed
2024-02-17 00:36:08,416:INFO:SubProcess create_model() called ==================================
2024-02-17 00:36:08,421:INFO:Initializing create_model()
2024-02-17 00:36:08,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1BC4C70>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE890280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 250, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 8})
2024-02-17 00:36:08,421:INFO:Checking exceptions
2024-02-17 00:36:08,421:INFO:Importing libraries
2024-02-17 00:36:08,421:INFO:Copying training dataset
2024-02-17 00:36:08,429:INFO:Defining folds
2024-02-17 00:36:08,429:INFO:Declaring metric variables
2024-02-17 00:36:08,437:INFO:Importing untrained model
2024-02-17 00:36:08,437:INFO:Declaring custom model
2024-02-17 00:36:08,438:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:36:08,453:INFO:Starting cross validation
2024-02-17 00:36:08,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:36:16,744:INFO:Calculating mean and std
2024-02-17 00:36:16,744:INFO:Creating metrics dataframe
2024-02-17 00:36:16,758:INFO:Finalizing model
2024-02-17 00:36:18,267:INFO:Uploading results into container
2024-02-17 00:36:18,269:INFO:Uploading model into container now
2024-02-17 00:36:18,269:INFO:_master_model_container: 62
2024-02-17 00:36:18,271:INFO:_display_container: 12
2024-02-17 00:36:18,271:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1ADDE10>
2024-02-17 00:36:18,271:INFO:create_model() successfully completed......................................
2024-02-17 00:36:18,388:INFO:SubProcess create_model() end ==================================
2024-02-17 00:36:18,388:INFO:choose_better activated
2024-02-17 00:36:18,403:INFO:SubProcess create_model() called ==================================
2024-02-17 00:36:18,403:INFO:Initializing create_model()
2024-02-17 00:36:18,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC18B2110>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:36:18,403:INFO:Checking exceptions
2024-02-17 00:36:18,407:INFO:Importing libraries
2024-02-17 00:36:18,407:INFO:Copying training dataset
2024-02-17 00:36:18,407:INFO:Defining folds
2024-02-17 00:36:18,407:INFO:Declaring metric variables
2024-02-17 00:36:18,407:INFO:Importing untrained model
2024-02-17 00:36:18,407:INFO:Declaring custom model
2024-02-17 00:36:18,407:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:36:18,407:INFO:Starting cross validation
2024-02-17 00:36:18,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:36:36,350:INFO:Calculating mean and std
2024-02-17 00:36:36,350:INFO:Creating metrics dataframe
2024-02-17 00:36:36,353:INFO:Finalizing model
2024-02-17 00:36:40,537:INFO:Uploading results into container
2024-02-17 00:36:40,537:INFO:Uploading model into container now
2024-02-17 00:36:40,537:INFO:_master_model_container: 63
2024-02-17 00:36:40,537:INFO:_display_container: 13
2024-02-17 00:36:40,537:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B4CD30>
2024-02-17 00:36:40,537:INFO:create_model() successfully completed......................................
2024-02-17 00:36:40,670:INFO:SubProcess create_model() end ==================================
2024-02-17 00:36:40,670:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B4CD30> result for Accuracy is 0.9227
2024-02-17 00:36:40,670:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1ADDE10> result for Accuracy is 0.9208
2024-02-17 00:36:40,670:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B4CD30> is best model
2024-02-17 00:36:40,670:INFO:choose_better completed
2024-02-17 00:36:40,670:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:36:40,686:INFO:_master_model_container: 63
2024-02-17 00:36:40,686:INFO:_display_container: 12
2024-02-17 00:36:40,687:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B4CD30>
2024-02-17 00:36:40,687:INFO:tune_model() successfully completed......................................
2024-02-17 00:36:40,804:INFO:Initializing tune_model()
2024-02-17 00:36:40,804:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:36:40,804:INFO:Checking exceptions
2024-02-17 00:36:40,841:INFO:Copying training dataset
2024-02-17 00:36:40,853:INFO:Checking base model
2024-02-17 00:36:40,853:INFO:Base model : Extreme Gradient Boosting
2024-02-17 00:36:40,861:INFO:Declaring metric variables
2024-02-17 00:36:40,869:INFO:Defining Hyperparameters
2024-02-17 00:36:41,006:INFO:Tuning with n_jobs=-1
2024-02-17 00:36:41,006:INFO:Initializing RandomizedSearchCV
2024-02-17 00:36:49,564:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 13.4, 'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__colsample_bytree': 0.7}
2024-02-17 00:36:49,564:INFO:Hyperparameter search completed
2024-02-17 00:36:49,564:INFO:SubProcess create_model() called ==================================
2024-02-17 00:36:49,564:INFO:Initializing create_model()
2024-02-17 00:36:49,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE8C0D30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 13.4, 'reg_lambda': 0.005, 'reg_alpha': 0.005, 'n_estimators': 150, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.15, 'colsample_bytree': 0.7})
2024-02-17 00:36:49,570:INFO:Checking exceptions
2024-02-17 00:36:49,570:INFO:Importing libraries
2024-02-17 00:36:49,570:INFO:Copying training dataset
2024-02-17 00:36:49,579:INFO:Defining folds
2024-02-17 00:36:49,579:INFO:Declaring metric variables
2024-02-17 00:36:49,579:INFO:Importing untrained model
2024-02-17 00:36:49,579:INFO:Declaring custom model
2024-02-17 00:36:49,591:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:36:49,603:INFO:Starting cross validation
2024-02-17 00:36:49,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:36:51,031:INFO:Calculating mean and std
2024-02-17 00:36:51,031:INFO:Creating metrics dataframe
2024-02-17 00:36:51,038:INFO:Finalizing model
2024-02-17 00:36:51,299:INFO:Uploading results into container
2024-02-17 00:36:51,299:INFO:Uploading model into container now
2024-02-17 00:36:51,299:INFO:_master_model_container: 64
2024-02-17 00:36:51,299:INFO:_display_container: 13
2024-02-17 00:36:51,299:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:36:51,299:INFO:create_model() successfully completed......................................
2024-02-17 00:36:51,418:INFO:SubProcess create_model() end ==================================
2024-02-17 00:36:51,418:INFO:choose_better activated
2024-02-17 00:36:51,434:INFO:SubProcess create_model() called ==================================
2024-02-17 00:36:51,434:INFO:Initializing create_model()
2024-02-17 00:36:51,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:36:51,434:INFO:Checking exceptions
2024-02-17 00:36:51,434:INFO:Importing libraries
2024-02-17 00:36:51,434:INFO:Copying training dataset
2024-02-17 00:36:51,434:INFO:Defining folds
2024-02-17 00:36:51,434:INFO:Declaring metric variables
2024-02-17 00:36:51,434:INFO:Importing untrained model
2024-02-17 00:36:51,434:INFO:Declaring custom model
2024-02-17 00:36:51,434:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:36:51,434:INFO:Starting cross validation
2024-02-17 00:36:51,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:36:51,946:INFO:Calculating mean and std
2024-02-17 00:36:51,946:INFO:Creating metrics dataframe
2024-02-17 00:36:51,946:INFO:Finalizing model
2024-02-17 00:36:52,037:INFO:Uploading results into container
2024-02-17 00:36:52,050:INFO:Uploading model into container now
2024-02-17 00:36:52,050:INFO:_master_model_container: 65
2024-02-17 00:36:52,050:INFO:_display_container: 14
2024-02-17 00:36:52,050:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:36:52,050:INFO:create_model() successfully completed......................................
2024-02-17 00:36:52,171:INFO:SubProcess create_model() end ==================================
2024-02-17 00:36:52,171:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9212
2024-02-17 00:36:52,171:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9103
2024-02-17 00:36:52,171:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-02-17 00:36:52,171:INFO:choose_better completed
2024-02-17 00:36:52,171:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:36:52,190:INFO:_master_model_container: 65
2024-02-17 00:36:52,190:INFO:_display_container: 13
2024-02-17 00:36:52,190:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:36:52,190:INFO:tune_model() successfully completed......................................
2024-02-17 00:36:52,315:INFO:Initializing tune_model()
2024-02-17 00:36:52,315:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:36:52,315:INFO:Checking exceptions
2024-02-17 00:36:52,331:INFO:Copying training dataset
2024-02-17 00:36:52,331:INFO:Checking base model
2024-02-17 00:36:52,331:INFO:Base model : Light Gradient Boosting Machine
2024-02-17 00:36:52,337:INFO:Declaring metric variables
2024-02-17 00:36:52,337:INFO:Defining Hyperparameters
2024-02-17 00:36:52,458:INFO:Tuning with n_jobs=-1
2024-02-17 00:36:52,458:INFO:Initializing RandomizedSearchCV
2024-02-17 00:37:08,771:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2024-02-17 00:37:08,771:INFO:Hyperparameter search completed
2024-02-17 00:37:08,771:INFO:SubProcess create_model() called ==================================
2024-02-17 00:37:08,771:INFO:Initializing create_model()
2024-02-17 00:37:08,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE890280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.15, 'num_leaves': 8, 'n_estimators': 150, 'min_split_gain': 0.1, 'min_child_samples': 41, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2024-02-17 00:37:08,771:INFO:Checking exceptions
2024-02-17 00:37:08,771:INFO:Importing libraries
2024-02-17 00:37:08,771:INFO:Copying training dataset
2024-02-17 00:37:08,778:INFO:Defining folds
2024-02-17 00:37:08,778:INFO:Declaring metric variables
2024-02-17 00:37:08,786:INFO:Importing untrained model
2024-02-17 00:37:08,786:INFO:Declaring custom model
2024-02-17 00:37:08,791:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:37:08,791:INFO:Starting cross validation
2024-02-17 00:37:08,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:37:09,535:INFO:Calculating mean and std
2024-02-17 00:37:09,535:INFO:Creating metrics dataframe
2024-02-17 00:37:09,542:INFO:Finalizing model
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:37:09,557:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:37:09,557:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:37:09,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000736 seconds.
2024-02-17 00:37:09,557:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 00:37:09,557:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:37:09,557:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:37:09,557:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:37:09,678:INFO:Uploading results into container
2024-02-17 00:37:09,679:INFO:Uploading model into container now
2024-02-17 00:37:09,679:INFO:_master_model_container: 66
2024-02-17 00:37:09,680:INFO:_display_container: 14
2024-02-17 00:37:09,680:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:37:09,680:INFO:create_model() successfully completed......................................
2024-02-17 00:37:09,805:INFO:SubProcess create_model() end ==================================
2024-02-17 00:37:09,805:INFO:choose_better activated
2024-02-17 00:37:09,805:INFO:SubProcess create_model() called ==================================
2024-02-17 00:37:09,816:INFO:Initializing create_model()
2024-02-17 00:37:09,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:37:09,816:INFO:Checking exceptions
2024-02-17 00:37:09,816:INFO:Importing libraries
2024-02-17 00:37:09,816:INFO:Copying training dataset
2024-02-17 00:37:09,816:INFO:Defining folds
2024-02-17 00:37:09,816:INFO:Declaring metric variables
2024-02-17 00:37:09,816:INFO:Importing untrained model
2024-02-17 00:37:09,816:INFO:Declaring custom model
2024-02-17 00:37:09,816:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:37:09,816:INFO:Starting cross validation
2024-02-17 00:37:09,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:37:11,049:INFO:Calculating mean and std
2024-02-17 00:37:11,049:INFO:Creating metrics dataframe
2024-02-17 00:37:11,049:INFO:Finalizing model
2024-02-17 00:37:11,065:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:37:11,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.
2024-02-17 00:37:11,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:37:11,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:37:11,065:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:37:11,065:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:37:11,065:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:37:11,186:INFO:Uploading results into container
2024-02-17 00:37:11,186:INFO:Uploading model into container now
2024-02-17 00:37:11,186:INFO:_master_model_container: 67
2024-02-17 00:37:11,186:INFO:_display_container: 15
2024-02-17 00:37:11,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:37:11,186:INFO:create_model() successfully completed......................................
2024-02-17 00:37:11,322:INFO:SubProcess create_model() end ==================================
2024-02-17 00:37:11,322:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9205
2024-02-17 00:37:11,322:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2024-02-17 00:37:11,322:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-17 00:37:11,322:INFO:choose_better completed
2024-02-17 00:37:11,322:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:37:11,343:INFO:_master_model_container: 67
2024-02-17 00:37:11,343:INFO:_display_container: 14
2024-02-17 00:37:11,346:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:37:11,346:INFO:tune_model() successfully completed......................................
2024-02-17 00:37:11,468:INFO:Initializing tune_model()
2024-02-17 00:37:11,468:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:37:11,468:INFO:Checking exceptions
2024-02-17 00:37:11,483:INFO:Copying training dataset
2024-02-17 00:37:11,483:INFO:Checking base model
2024-02-17 00:37:11,483:INFO:Base model : Random Forest Classifier
2024-02-17 00:37:11,483:INFO:Declaring metric variables
2024-02-17 00:37:11,498:INFO:Defining Hyperparameters
2024-02-17 00:37:11,616:INFO:Tuning with n_jobs=-1
2024-02-17 00:37:11,616:INFO:Initializing RandomizedSearchCV
2024-02-17 00:37:23,901:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2024-02-17 00:37:23,901:INFO:Hyperparameter search completed
2024-02-17 00:37:23,901:INFO:SubProcess create_model() called ==================================
2024-02-17 00:37:23,901:INFO:Initializing create_model()
2024-02-17 00:37:23,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9ED5D270>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0005, 'max_features': 'log2', 'max_depth': 5, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2024-02-17 00:37:23,901:INFO:Checking exceptions
2024-02-17 00:37:23,901:INFO:Importing libraries
2024-02-17 00:37:23,905:INFO:Copying training dataset
2024-02-17 00:37:23,909:INFO:Defining folds
2024-02-17 00:37:23,909:INFO:Declaring metric variables
2024-02-17 00:37:23,909:INFO:Importing untrained model
2024-02-17 00:37:23,916:INFO:Declaring custom model
2024-02-17 00:37:23,916:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:37:23,931:INFO:Starting cross validation
2024-02-17 00:37:23,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:37:25,503:INFO:Calculating mean and std
2024-02-17 00:37:25,506:INFO:Creating metrics dataframe
2024-02-17 00:37:25,506:INFO:Finalizing model
2024-02-17 00:37:25,828:INFO:Uploading results into container
2024-02-17 00:37:25,830:INFO:Uploading model into container now
2024-02-17 00:37:25,830:INFO:_master_model_container: 68
2024-02-17 00:37:25,830:INFO:_display_container: 15
2024-02-17 00:37:25,830:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:37:25,830:INFO:create_model() successfully completed......................................
2024-02-17 00:37:25,969:INFO:SubProcess create_model() end ==================================
2024-02-17 00:37:25,969:INFO:choose_better activated
2024-02-17 00:37:25,973:INFO:SubProcess create_model() called ==================================
2024-02-17 00:37:25,973:INFO:Initializing create_model()
2024-02-17 00:37:25,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:37:25,973:INFO:Checking exceptions
2024-02-17 00:37:25,973:INFO:Importing libraries
2024-02-17 00:37:25,973:INFO:Copying training dataset
2024-02-17 00:37:25,985:INFO:Defining folds
2024-02-17 00:37:25,985:INFO:Declaring metric variables
2024-02-17 00:37:25,985:INFO:Importing untrained model
2024-02-17 00:37:25,985:INFO:Declaring custom model
2024-02-17 00:37:25,985:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:37:25,985:INFO:Starting cross validation
2024-02-17 00:37:25,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:37:28,440:INFO:Calculating mean and std
2024-02-17 00:37:28,440:INFO:Creating metrics dataframe
2024-02-17 00:37:28,440:INFO:Finalizing model
2024-02-17 00:37:28,739:INFO:Uploading results into container
2024-02-17 00:37:28,739:INFO:Uploading model into container now
2024-02-17 00:37:28,739:INFO:_master_model_container: 69
2024-02-17 00:37:28,739:INFO:_display_container: 16
2024-02-17 00:37:28,739:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:37:28,739:INFO:create_model() successfully completed......................................
2024-02-17 00:37:28,856:INFO:SubProcess create_model() end ==================================
2024-02-17 00:37:28,856:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.9162
2024-02-17 00:37:28,856:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.8414
2024-02-17 00:37:28,856:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) is best model
2024-02-17 00:37:28,856:INFO:choose_better completed
2024-02-17 00:37:28,856:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:37:28,872:INFO:_master_model_container: 69
2024-02-17 00:37:28,873:INFO:_display_container: 15
2024-02-17 00:37:28,874:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:37:28,874:INFO:tune_model() successfully completed......................................
2024-02-17 00:38:42,163:INFO:Initializing compare_models()
2024-02-17 00:38:42,163:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 00:38:42,163:INFO:Checking exceptions
2024-02-17 00:38:42,167:INFO:Preparing display monitor
2024-02-17 00:38:42,193:INFO:Initializing Logistic Regression
2024-02-17 00:38:42,193:INFO:Total runtime is 0.0 minutes
2024-02-17 00:38:42,201:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:42,201:INFO:Initializing create_model()
2024-02-17 00:38:42,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:42,201:INFO:Checking exceptions
2024-02-17 00:38:42,201:INFO:Importing libraries
2024-02-17 00:38:42,201:INFO:Copying training dataset
2024-02-17 00:38:42,210:INFO:Defining folds
2024-02-17 00:38:42,210:INFO:Declaring metric variables
2024-02-17 00:38:42,210:INFO:Importing untrained model
2024-02-17 00:38:42,218:INFO:Logistic Regression Imported successfully
2024-02-17 00:38:42,226:INFO:Starting cross validation
2024-02-17 00:38:42,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:43,126:INFO:Calculating mean and std
2024-02-17 00:38:43,126:INFO:Creating metrics dataframe
2024-02-17 00:38:43,130:INFO:Uploading results into container
2024-02-17 00:38:43,130:INFO:Uploading model into container now
2024-02-17 00:38:43,130:INFO:_master_model_container: 70
2024-02-17 00:38:43,130:INFO:_display_container: 16
2024-02-17 00:38:43,130:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3957, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 00:38:43,130:INFO:create_model() successfully completed......................................
2024-02-17 00:38:43,268:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:43,268:INFO:Creating metrics dataframe
2024-02-17 00:38:43,271:INFO:Initializing K Neighbors Classifier
2024-02-17 00:38:43,271:INFO:Total runtime is 0.017977972825368244 minutes
2024-02-17 00:38:43,279:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:43,279:INFO:Initializing create_model()
2024-02-17 00:38:43,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:43,279:INFO:Checking exceptions
2024-02-17 00:38:43,279:INFO:Importing libraries
2024-02-17 00:38:43,279:INFO:Copying training dataset
2024-02-17 00:38:43,288:INFO:Defining folds
2024-02-17 00:38:43,288:INFO:Declaring metric variables
2024-02-17 00:38:43,288:INFO:Importing untrained model
2024-02-17 00:38:43,296:INFO:K Neighbors Classifier Imported successfully
2024-02-17 00:38:43,304:INFO:Starting cross validation
2024-02-17 00:38:43,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:43,503:INFO:Calculating mean and std
2024-02-17 00:38:43,503:INFO:Creating metrics dataframe
2024-02-17 00:38:43,503:INFO:Uploading results into container
2024-02-17 00:38:43,510:INFO:Uploading model into container now
2024-02-17 00:38:43,510:INFO:_master_model_container: 71
2024-02-17 00:38:43,510:INFO:_display_container: 16
2024-02-17 00:38:43,510:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 00:38:43,510:INFO:create_model() successfully completed......................................
2024-02-17 00:38:43,614:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:43,614:INFO:Creating metrics dataframe
2024-02-17 00:38:43,627:INFO:Initializing Naive Bayes
2024-02-17 00:38:43,627:INFO:Total runtime is 0.023903143405914304 minutes
2024-02-17 00:38:43,627:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:43,627:INFO:Initializing create_model()
2024-02-17 00:38:43,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:43,627:INFO:Checking exceptions
2024-02-17 00:38:43,627:INFO:Importing libraries
2024-02-17 00:38:43,627:INFO:Copying training dataset
2024-02-17 00:38:43,639:INFO:Defining folds
2024-02-17 00:38:43,639:INFO:Declaring metric variables
2024-02-17 00:38:43,643:INFO:Importing untrained model
2024-02-17 00:38:43,646:INFO:Naive Bayes Imported successfully
2024-02-17 00:38:43,652:INFO:Starting cross validation
2024-02-17 00:38:43,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:43,740:INFO:Calculating mean and std
2024-02-17 00:38:43,740:INFO:Creating metrics dataframe
2024-02-17 00:38:43,744:INFO:Uploading results into container
2024-02-17 00:38:43,744:INFO:Uploading model into container now
2024-02-17 00:38:43,744:INFO:_master_model_container: 72
2024-02-17 00:38:43,744:INFO:_display_container: 16
2024-02-17 00:38:43,744:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 00:38:43,744:INFO:create_model() successfully completed......................................
2024-02-17 00:38:43,844:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:43,844:INFO:Creating metrics dataframe
2024-02-17 00:38:43,862:INFO:Initializing Decision Tree Classifier
2024-02-17 00:38:43,863:INFO:Total runtime is 0.02784008979797363 minutes
2024-02-17 00:38:43,863:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:43,863:INFO:Initializing create_model()
2024-02-17 00:38:43,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:43,863:INFO:Checking exceptions
2024-02-17 00:38:43,863:INFO:Importing libraries
2024-02-17 00:38:43,863:INFO:Copying training dataset
2024-02-17 00:38:43,869:INFO:Defining folds
2024-02-17 00:38:43,869:INFO:Declaring metric variables
2024-02-17 00:38:43,877:INFO:Importing untrained model
2024-02-17 00:38:43,882:INFO:Decision Tree Classifier Imported successfully
2024-02-17 00:38:43,893:INFO:Starting cross validation
2024-02-17 00:38:43,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:44,143:INFO:Calculating mean and std
2024-02-17 00:38:44,143:INFO:Creating metrics dataframe
2024-02-17 00:38:44,147:INFO:Uploading results into container
2024-02-17 00:38:44,147:INFO:Uploading model into container now
2024-02-17 00:38:44,147:INFO:_master_model_container: 73
2024-02-17 00:38:44,147:INFO:_display_container: 16
2024-02-17 00:38:44,147:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3957, splitter='best')
2024-02-17 00:38:44,147:INFO:create_model() successfully completed......................................
2024-02-17 00:38:44,260:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:44,260:INFO:Creating metrics dataframe
2024-02-17 00:38:44,279:INFO:Initializing SVM - Linear Kernel
2024-02-17 00:38:44,279:INFO:Total runtime is 0.034768807888031 minutes
2024-02-17 00:38:44,279:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:44,279:INFO:Initializing create_model()
2024-02-17 00:38:44,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:44,279:INFO:Checking exceptions
2024-02-17 00:38:44,279:INFO:Importing libraries
2024-02-17 00:38:44,279:INFO:Copying training dataset
2024-02-17 00:38:44,279:INFO:Defining folds
2024-02-17 00:38:44,279:INFO:Declaring metric variables
2024-02-17 00:38:44,294:INFO:Importing untrained model
2024-02-17 00:38:44,301:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 00:38:44,301:INFO:Starting cross validation
2024-02-17 00:38:44,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:44,470:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,476:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,476:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,481:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,486:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,497:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,508:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,516:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,584:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,599:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,621:INFO:Calculating mean and std
2024-02-17 00:38:44,621:INFO:Creating metrics dataframe
2024-02-17 00:38:44,628:INFO:Uploading results into container
2024-02-17 00:38:44,629:INFO:Uploading model into container now
2024-02-17 00:38:44,629:INFO:_master_model_container: 74
2024-02-17 00:38:44,629:INFO:_display_container: 16
2024-02-17 00:38:44,629:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3957, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 00:38:44,629:INFO:create_model() successfully completed......................................
2024-02-17 00:38:44,744:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:44,744:INFO:Creating metrics dataframe
2024-02-17 00:38:44,751:INFO:Initializing Ridge Classifier
2024-02-17 00:38:44,751:INFO:Total runtime is 0.042631189028422035 minutes
2024-02-17 00:38:44,760:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:44,762:INFO:Initializing create_model()
2024-02-17 00:38:44,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:44,762:INFO:Checking exceptions
2024-02-17 00:38:44,762:INFO:Importing libraries
2024-02-17 00:38:44,762:INFO:Copying training dataset
2024-02-17 00:38:44,768:INFO:Defining folds
2024-02-17 00:38:44,768:INFO:Declaring metric variables
2024-02-17 00:38:44,770:INFO:Importing untrained model
2024-02-17 00:38:44,772:INFO:Ridge Classifier Imported successfully
2024-02-17 00:38:44,782:INFO:Starting cross validation
2024-02-17 00:38:44,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:44,827:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,827:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,827:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,840:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,843:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,843:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,843:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,849:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,861:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:38:44,873:INFO:Calculating mean and std
2024-02-17 00:38:44,873:INFO:Creating metrics dataframe
2024-02-17 00:38:44,876:INFO:Uploading results into container
2024-02-17 00:38:44,876:INFO:Uploading model into container now
2024-02-17 00:38:44,876:INFO:_master_model_container: 75
2024-02-17 00:38:44,876:INFO:_display_container: 16
2024-02-17 00:38:44,876:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3957, solver='auto',
                tol=0.0001)
2024-02-17 00:38:44,876:INFO:create_model() successfully completed......................................
2024-02-17 00:38:44,981:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:44,981:INFO:Creating metrics dataframe
2024-02-17 00:38:44,996:INFO:Initializing Random Forest Classifier
2024-02-17 00:38:44,996:INFO:Total runtime is 0.04672536849975586 minutes
2024-02-17 00:38:44,996:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:44,996:INFO:Initializing create_model()
2024-02-17 00:38:44,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:44,996:INFO:Checking exceptions
2024-02-17 00:38:44,996:INFO:Importing libraries
2024-02-17 00:38:44,996:INFO:Copying training dataset
2024-02-17 00:38:45,011:INFO:Defining folds
2024-02-17 00:38:45,011:INFO:Declaring metric variables
2024-02-17 00:38:45,014:INFO:Importing untrained model
2024-02-17 00:38:45,014:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:38:45,026:INFO:Starting cross validation
2024-02-17 00:38:45,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:46,677:INFO:Calculating mean and std
2024-02-17 00:38:46,678:INFO:Creating metrics dataframe
2024-02-17 00:38:46,679:INFO:Uploading results into container
2024-02-17 00:38:46,679:INFO:Uploading model into container now
2024-02-17 00:38:46,679:INFO:_master_model_container: 76
2024-02-17 00:38:46,679:INFO:_display_container: 16
2024-02-17 00:38:46,679:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:38:46,679:INFO:create_model() successfully completed......................................
2024-02-17 00:38:46,794:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:46,794:INFO:Creating metrics dataframe
2024-02-17 00:38:46,794:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 00:38:46,794:INFO:Total runtime is 0.07668073574701945 minutes
2024-02-17 00:38:46,805:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:46,805:INFO:Initializing create_model()
2024-02-17 00:38:46,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:46,805:INFO:Checking exceptions
2024-02-17 00:38:46,805:INFO:Importing libraries
2024-02-17 00:38:46,805:INFO:Copying training dataset
2024-02-17 00:38:46,808:INFO:Defining folds
2024-02-17 00:38:46,808:INFO:Declaring metric variables
2024-02-17 00:38:46,808:INFO:Importing untrained model
2024-02-17 00:38:46,821:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 00:38:46,830:INFO:Starting cross validation
2024-02-17 00:38:46,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:46,923:INFO:Calculating mean and std
2024-02-17 00:38:46,923:INFO:Creating metrics dataframe
2024-02-17 00:38:46,923:INFO:Uploading results into container
2024-02-17 00:38:46,923:INFO:Uploading model into container now
2024-02-17 00:38:46,923:INFO:_master_model_container: 77
2024-02-17 00:38:46,923:INFO:_display_container: 16
2024-02-17 00:38:46,923:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 00:38:46,923:INFO:create_model() successfully completed......................................
2024-02-17 00:38:47,024:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:47,024:INFO:Creating metrics dataframe
2024-02-17 00:38:47,040:INFO:Initializing Ada Boost Classifier
2024-02-17 00:38:47,040:INFO:Total runtime is 0.08078121741612752 minutes
2024-02-17 00:38:47,040:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:47,040:INFO:Initializing create_model()
2024-02-17 00:38:47,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:47,040:INFO:Checking exceptions
2024-02-17 00:38:47,040:INFO:Importing libraries
2024-02-17 00:38:47,040:INFO:Copying training dataset
2024-02-17 00:38:47,055:INFO:Defining folds
2024-02-17 00:38:47,055:INFO:Declaring metric variables
2024-02-17 00:38:47,055:INFO:Importing untrained model
2024-02-17 00:38:47,066:INFO:Ada Boost Classifier Imported successfully
2024-02-17 00:38:47,081:INFO:Starting cross validation
2024-02-17 00:38:47,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:47,860:INFO:Calculating mean and std
2024-02-17 00:38:47,860:INFO:Creating metrics dataframe
2024-02-17 00:38:47,860:INFO:Uploading results into container
2024-02-17 00:38:47,860:INFO:Uploading model into container now
2024-02-17 00:38:47,860:INFO:_master_model_container: 78
2024-02-17 00:38:47,860:INFO:_display_container: 16
2024-02-17 00:38:47,860:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3957)
2024-02-17 00:38:47,860:INFO:create_model() successfully completed......................................
2024-02-17 00:38:47,972:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:47,972:INFO:Creating metrics dataframe
2024-02-17 00:38:47,974:INFO:Initializing Gradient Boosting Classifier
2024-02-17 00:38:47,974:INFO:Total runtime is 0.09636147022247314 minutes
2024-02-17 00:38:47,987:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:47,987:INFO:Initializing create_model()
2024-02-17 00:38:47,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:47,987:INFO:Checking exceptions
2024-02-17 00:38:47,987:INFO:Importing libraries
2024-02-17 00:38:47,987:INFO:Copying training dataset
2024-02-17 00:38:47,997:INFO:Defining folds
2024-02-17 00:38:47,997:INFO:Declaring metric variables
2024-02-17 00:38:47,997:INFO:Importing untrained model
2024-02-17 00:38:47,997:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:38:48,014:INFO:Starting cross validation
2024-02-17 00:38:48,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:50,240:INFO:Calculating mean and std
2024-02-17 00:38:50,240:INFO:Creating metrics dataframe
2024-02-17 00:38:50,245:INFO:Uploading results into container
2024-02-17 00:38:50,245:INFO:Uploading model into container now
2024-02-17 00:38:50,245:INFO:_master_model_container: 79
2024-02-17 00:38:50,245:INFO:_display_container: 16
2024-02-17 00:38:50,245:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:38:50,245:INFO:create_model() successfully completed......................................
2024-02-17 00:38:50,351:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:50,351:INFO:Creating metrics dataframe
2024-02-17 00:38:50,377:INFO:Initializing Linear Discriminant Analysis
2024-02-17 00:38:50,377:INFO:Total runtime is 0.13640617529551188 minutes
2024-02-17 00:38:50,377:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:50,377:INFO:Initializing create_model()
2024-02-17 00:38:50,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:50,377:INFO:Checking exceptions
2024-02-17 00:38:50,377:INFO:Importing libraries
2024-02-17 00:38:50,377:INFO:Copying training dataset
2024-02-17 00:38:50,384:INFO:Defining folds
2024-02-17 00:38:50,384:INFO:Declaring metric variables
2024-02-17 00:38:50,384:INFO:Importing untrained model
2024-02-17 00:38:50,393:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 00:38:50,404:INFO:Starting cross validation
2024-02-17 00:38:50,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:50,490:INFO:Calculating mean and std
2024-02-17 00:38:50,490:INFO:Creating metrics dataframe
2024-02-17 00:38:50,494:INFO:Uploading results into container
2024-02-17 00:38:50,495:INFO:Uploading model into container now
2024-02-17 00:38:50,495:INFO:_master_model_container: 80
2024-02-17 00:38:50,495:INFO:_display_container: 16
2024-02-17 00:38:50,495:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 00:38:50,495:INFO:create_model() successfully completed......................................
2024-02-17 00:38:50,596:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:50,596:INFO:Creating metrics dataframe
2024-02-17 00:38:50,623:INFO:Initializing Extra Trees Classifier
2024-02-17 00:38:50,623:INFO:Total runtime is 0.1405022382736206 minutes
2024-02-17 00:38:50,627:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:50,627:INFO:Initializing create_model()
2024-02-17 00:38:50,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:50,627:INFO:Checking exceptions
2024-02-17 00:38:50,627:INFO:Importing libraries
2024-02-17 00:38:50,627:INFO:Copying training dataset
2024-02-17 00:38:50,629:INFO:Defining folds
2024-02-17 00:38:50,629:INFO:Declaring metric variables
2024-02-17 00:38:50,638:INFO:Importing untrained model
2024-02-17 00:38:50,638:INFO:Extra Trees Classifier Imported successfully
2024-02-17 00:38:50,650:INFO:Starting cross validation
2024-02-17 00:38:50,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:52,061:INFO:Calculating mean and std
2024-02-17 00:38:52,061:INFO:Creating metrics dataframe
2024-02-17 00:38:52,061:INFO:Uploading results into container
2024-02-17 00:38:52,061:INFO:Uploading model into container now
2024-02-17 00:38:52,061:INFO:_master_model_container: 81
2024-02-17 00:38:52,061:INFO:_display_container: 16
2024-02-17 00:38:52,061:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:38:52,061:INFO:create_model() successfully completed......................................
2024-02-17 00:38:52,179:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:52,179:INFO:Creating metrics dataframe
2024-02-17 00:38:52,199:INFO:Initializing Extreme Gradient Boosting
2024-02-17 00:38:52,199:INFO:Total runtime is 0.16677636305491128 minutes
2024-02-17 00:38:52,199:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:52,199:INFO:Initializing create_model()
2024-02-17 00:38:52,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:52,199:INFO:Checking exceptions
2024-02-17 00:38:52,199:INFO:Importing libraries
2024-02-17 00:38:52,199:INFO:Copying training dataset
2024-02-17 00:38:52,210:INFO:Defining folds
2024-02-17 00:38:52,210:INFO:Declaring metric variables
2024-02-17 00:38:52,218:INFO:Importing untrained model
2024-02-17 00:38:52,218:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:38:52,230:INFO:Starting cross validation
2024-02-17 00:38:52,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:52,738:INFO:Calculating mean and std
2024-02-17 00:38:52,738:INFO:Creating metrics dataframe
2024-02-17 00:38:52,745:INFO:Uploading results into container
2024-02-17 00:38:52,745:INFO:Uploading model into container now
2024-02-17 00:38:52,745:INFO:_master_model_container: 82
2024-02-17 00:38:52,745:INFO:_display_container: 16
2024-02-17 00:38:52,745:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:38:52,745:INFO:create_model() successfully completed......................................
2024-02-17 00:38:52,844:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:52,844:INFO:Creating metrics dataframe
2024-02-17 00:38:52,861:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 00:38:52,861:INFO:Total runtime is 0.1777989665667216 minutes
2024-02-17 00:38:52,861:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:52,861:INFO:Initializing create_model()
2024-02-17 00:38:52,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:52,861:INFO:Checking exceptions
2024-02-17 00:38:52,861:INFO:Importing libraries
2024-02-17 00:38:52,861:INFO:Copying training dataset
2024-02-17 00:38:52,873:INFO:Defining folds
2024-02-17 00:38:52,873:INFO:Declaring metric variables
2024-02-17 00:38:52,877:INFO:Importing untrained model
2024-02-17 00:38:52,885:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:38:52,893:INFO:Starting cross validation
2024-02-17 00:38:52,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:38:54,123:INFO:Calculating mean and std
2024-02-17 00:38:54,123:INFO:Creating metrics dataframe
2024-02-17 00:38:54,130:INFO:Uploading results into container
2024-02-17 00:38:54,130:INFO:Uploading model into container now
2024-02-17 00:38:54,130:INFO:_master_model_container: 83
2024-02-17 00:38:54,130:INFO:_display_container: 16
2024-02-17 00:38:54,130:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:38:54,130:INFO:create_model() successfully completed......................................
2024-02-17 00:38:54,244:INFO:SubProcess create_model() end ==================================
2024-02-17 00:38:54,244:INFO:Creating metrics dataframe
2024-02-17 00:38:54,281:INFO:Initializing CatBoost Classifier
2024-02-17 00:38:54,281:INFO:Total runtime is 0.20147114992141724 minutes
2024-02-17 00:38:54,281:INFO:SubProcess create_model() called ==================================
2024-02-17 00:38:54,281:INFO:Initializing create_model()
2024-02-17 00:38:54,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:38:54,281:INFO:Checking exceptions
2024-02-17 00:38:54,281:INFO:Importing libraries
2024-02-17 00:38:54,281:INFO:Copying training dataset
2024-02-17 00:38:54,294:INFO:Defining folds
2024-02-17 00:38:54,294:INFO:Declaring metric variables
2024-02-17 00:38:54,304:INFO:Importing untrained model
2024-02-17 00:38:54,310:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:38:54,318:INFO:Starting cross validation
2024-02-17 00:38:54,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:39:12,258:INFO:Calculating mean and std
2024-02-17 00:39:12,258:INFO:Creating metrics dataframe
2024-02-17 00:39:12,262:INFO:Uploading results into container
2024-02-17 00:39:12,262:INFO:Uploading model into container now
2024-02-17 00:39:12,262:INFO:_master_model_container: 84
2024-02-17 00:39:12,262:INFO:_display_container: 16
2024-02-17 00:39:12,262:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1A22F20>
2024-02-17 00:39:12,262:INFO:create_model() successfully completed......................................
2024-02-17 00:39:12,378:INFO:SubProcess create_model() end ==================================
2024-02-17 00:39:12,378:INFO:Creating metrics dataframe
2024-02-17 00:39:12,383:INFO:Initializing Dummy Classifier
2024-02-17 00:39:12,383:INFO:Total runtime is 0.5031650145848592 minutes
2024-02-17 00:39:12,392:INFO:SubProcess create_model() called ==================================
2024-02-17 00:39:12,392:INFO:Initializing create_model()
2024-02-17 00:39:12,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18706D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:39:12,392:INFO:Checking exceptions
2024-02-17 00:39:12,392:INFO:Importing libraries
2024-02-17 00:39:12,392:INFO:Copying training dataset
2024-02-17 00:39:12,397:INFO:Defining folds
2024-02-17 00:39:12,397:INFO:Declaring metric variables
2024-02-17 00:39:12,404:INFO:Importing untrained model
2024-02-17 00:39:12,404:INFO:Dummy Classifier Imported successfully
2024-02-17 00:39:12,412:INFO:Starting cross validation
2024-02-17 00:39:12,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:39:12,480:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:39:12,480:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:39:12,480:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:39:12,483:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:39:12,483:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:39:12,507:INFO:Calculating mean and std
2024-02-17 00:39:12,507:INFO:Creating metrics dataframe
2024-02-17 00:39:12,511:INFO:Uploading results into container
2024-02-17 00:39:12,511:INFO:Uploading model into container now
2024-02-17 00:39:12,511:INFO:_master_model_container: 85
2024-02-17 00:39:12,511:INFO:_display_container: 16
2024-02-17 00:39:12,511:INFO:DummyClassifier(constant=None, random_state=3957, strategy='prior')
2024-02-17 00:39:12,511:INFO:create_model() successfully completed......................................
2024-02-17 00:39:12,614:INFO:SubProcess create_model() end ==================================
2024-02-17 00:39:12,614:INFO:Creating metrics dataframe
2024-02-17 00:39:12,650:INFO:Initializing create_model()
2024-02-17 00:39:12,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1A22F20>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:39:12,650:INFO:Checking exceptions
2024-02-17 00:39:12,650:INFO:Importing libraries
2024-02-17 00:39:12,650:INFO:Copying training dataset
2024-02-17 00:39:12,650:INFO:Defining folds
2024-02-17 00:39:12,650:INFO:Declaring metric variables
2024-02-17 00:39:12,650:INFO:Importing untrained model
2024-02-17 00:39:12,650:INFO:Declaring custom model
2024-02-17 00:39:12,650:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:39:12,650:INFO:Cross validation set to False
2024-02-17 00:39:12,650:INFO:Fitting Model
2024-02-17 00:39:17,393:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1ADC700>
2024-02-17 00:39:17,393:INFO:create_model() successfully completed......................................
2024-02-17 00:39:17,512:INFO:Initializing create_model()
2024-02-17 00:39:17,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:39:17,526:INFO:Checking exceptions
2024-02-17 00:39:17,528:INFO:Importing libraries
2024-02-17 00:39:17,528:INFO:Copying training dataset
2024-02-17 00:39:17,531:INFO:Defining folds
2024-02-17 00:39:17,531:INFO:Declaring metric variables
2024-02-17 00:39:17,531:INFO:Importing untrained model
2024-02-17 00:39:17,531:INFO:Declaring custom model
2024-02-17 00:39:17,531:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:39:17,531:INFO:Cross validation set to False
2024-02-17 00:39:17,531:INFO:Fitting Model
2024-02-17 00:39:17,653:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:39:17,653:INFO:create_model() successfully completed......................................
2024-02-17 00:39:17,791:INFO:Initializing create_model()
2024-02-17 00:39:17,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:39:17,791:INFO:Checking exceptions
2024-02-17 00:39:17,794:INFO:Importing libraries
2024-02-17 00:39:17,794:INFO:Copying training dataset
2024-02-17 00:39:17,797:INFO:Defining folds
2024-02-17 00:39:17,797:INFO:Declaring metric variables
2024-02-17 00:39:17,797:INFO:Importing untrained model
2024-02-17 00:39:17,797:INFO:Declaring custom model
2024-02-17 00:39:17,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:39:17,797:INFO:Cross validation set to False
2024-02-17 00:39:17,797:INFO:Fitting Model
2024-02-17 00:39:17,814:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:39:17,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2024-02-17 00:39:17,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:39:17,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:39:17,814:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:39:17,814:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:39:17,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:39:17,925:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:39:17,935:INFO:create_model() successfully completed......................................
2024-02-17 00:39:18,095:INFO:_master_model_container: 85
2024-02-17 00:39:18,095:INFO:_display_container: 16
2024-02-17 00:39:18,095:INFO:[<catboost.core.CatBoostClassifier object at 0x0000028DC1ADC700>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2024-02-17 00:39:18,095:INFO:compare_models() successfully completed......................................
2024-02-17 00:40:44,105:INFO:Initializing tune_model()
2024-02-17 00:40:44,108:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1ADC700>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:40:44,108:INFO:Checking exceptions
2024-02-17 00:40:44,122:INFO:Copying training dataset
2024-02-17 00:40:44,122:INFO:Checking base model
2024-02-17 00:40:44,122:INFO:Base model : CatBoost Classifier
2024-02-17 00:40:44,133:INFO:Declaring metric variables
2024-02-17 00:40:44,133:INFO:Defining Hyperparameters
2024-02-17 00:40:44,260:INFO:Tuning with n_jobs=-1
2024-02-17 00:40:44,260:INFO:Initializing RandomizedSearchCV
2024-02-17 00:41:49,481:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2303, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2230, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6105, in _catboost._check_train_params
  File "_catboost.pyx", line 6124, in _catboost._check_train_params
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-02-17 00:41:49,481:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84742268 0.80574374        nan 0.90029455 0.8353461  0.90795287
 0.92076583 0.82268041 0.86023564 0.88468336]
  warnings.warn(

2024-02-17 00:41:49,481:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2024-02-17 00:41:49,481:INFO:Hyperparameter search completed
2024-02-17 00:41:49,481:INFO:SubProcess create_model() called ==================================
2024-02-17 00:41:49,481:INFO:Initializing create_model()
2024-02-17 00:41:49,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1BC7670>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18388B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 250, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 8})
2024-02-17 00:41:49,481:INFO:Checking exceptions
2024-02-17 00:41:49,481:INFO:Importing libraries
2024-02-17 00:41:49,481:INFO:Copying training dataset
2024-02-17 00:41:49,492:INFO:Defining folds
2024-02-17 00:41:49,492:INFO:Declaring metric variables
2024-02-17 00:41:49,492:INFO:Importing untrained model
2024-02-17 00:41:49,492:INFO:Declaring custom model
2024-02-17 00:41:49,492:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:41:49,505:INFO:Starting cross validation
2024-02-17 00:41:49,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:41:57,803:INFO:Calculating mean and std
2024-02-17 00:41:57,805:INFO:Creating metrics dataframe
2024-02-17 00:41:57,810:INFO:Finalizing model
2024-02-17 00:41:59,311:INFO:Uploading results into container
2024-02-17 00:41:59,313:INFO:Uploading model into container now
2024-02-17 00:41:59,313:INFO:_master_model_container: 86
2024-02-17 00:41:59,313:INFO:_display_container: 17
2024-02-17 00:41:59,313:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B20BB0>
2024-02-17 00:41:59,313:INFO:create_model() successfully completed......................................
2024-02-17 00:41:59,435:INFO:SubProcess create_model() end ==================================
2024-02-17 00:41:59,435:INFO:choose_better activated
2024-02-17 00:41:59,435:INFO:SubProcess create_model() called ==================================
2024-02-17 00:41:59,435:INFO:Initializing create_model()
2024-02-17 00:41:59,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1ADC700>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:41:59,435:INFO:Checking exceptions
2024-02-17 00:41:59,435:INFO:Importing libraries
2024-02-17 00:41:59,435:INFO:Copying training dataset
2024-02-17 00:41:59,451:INFO:Defining folds
2024-02-17 00:41:59,451:INFO:Declaring metric variables
2024-02-17 00:41:59,451:INFO:Importing untrained model
2024-02-17 00:41:59,451:INFO:Declaring custom model
2024-02-17 00:41:59,451:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:41:59,451:INFO:Starting cross validation
2024-02-17 00:41:59,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:42:17,031:INFO:Calculating mean and std
2024-02-17 00:42:17,031:INFO:Creating metrics dataframe
2024-02-17 00:42:17,031:INFO:Finalizing model
2024-02-17 00:42:21,324:INFO:Uploading results into container
2024-02-17 00:42:21,324:INFO:Uploading model into container now
2024-02-17 00:42:21,324:INFO:_master_model_container: 87
2024-02-17 00:42:21,324:INFO:_display_container: 18
2024-02-17 00:42:21,324:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20>
2024-02-17 00:42:21,324:INFO:create_model() successfully completed......................................
2024-02-17 00:42:21,455:INFO:SubProcess create_model() end ==================================
2024-02-17 00:42:21,455:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20> result for Accuracy is 0.9227
2024-02-17 00:42:21,455:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B20BB0> result for Accuracy is 0.9208
2024-02-17 00:42:21,455:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20> is best model
2024-02-17 00:42:21,455:INFO:choose_better completed
2024-02-17 00:42:21,455:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:42:21,473:INFO:_master_model_container: 87
2024-02-17 00:42:21,473:INFO:_display_container: 17
2024-02-17 00:42:21,473:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20>
2024-02-17 00:42:21,473:INFO:tune_model() successfully completed......................................
2024-02-17 00:42:21,605:INFO:Initializing tune_model()
2024-02-17 00:42:21,605:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:42:21,605:INFO:Checking exceptions
2024-02-17 00:42:21,640:INFO:Copying training dataset
2024-02-17 00:42:21,648:INFO:Checking base model
2024-02-17 00:42:21,648:INFO:Base model : Extreme Gradient Boosting
2024-02-17 00:42:21,656:INFO:Declaring metric variables
2024-02-17 00:42:21,659:INFO:Defining Hyperparameters
2024-02-17 00:42:21,805:INFO:Tuning with n_jobs=-1
2024-02-17 00:42:21,805:INFO:Initializing RandomizedSearchCV
2024-02-17 00:42:30,681:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 13.4, 'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__colsample_bytree': 0.7}
2024-02-17 00:42:30,681:INFO:Hyperparameter search completed
2024-02-17 00:42:30,681:INFO:SubProcess create_model() called ==================================
2024-02-17 00:42:30,681:INFO:Initializing create_model()
2024-02-17 00:42:30,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBED86320>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 13.4, 'reg_lambda': 0.005, 'reg_alpha': 0.005, 'n_estimators': 150, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.15, 'colsample_bytree': 0.7})
2024-02-17 00:42:30,681:INFO:Checking exceptions
2024-02-17 00:42:30,681:INFO:Importing libraries
2024-02-17 00:42:30,681:INFO:Copying training dataset
2024-02-17 00:42:30,692:INFO:Defining folds
2024-02-17 00:42:30,692:INFO:Declaring metric variables
2024-02-17 00:42:30,692:INFO:Importing untrained model
2024-02-17 00:42:30,692:INFO:Declaring custom model
2024-02-17 00:42:30,710:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:42:30,721:INFO:Starting cross validation
2024-02-17 00:42:30,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:42:31,985:INFO:Calculating mean and std
2024-02-17 00:42:31,985:INFO:Creating metrics dataframe
2024-02-17 00:42:31,985:INFO:Finalizing model
2024-02-17 00:42:32,254:INFO:Uploading results into container
2024-02-17 00:42:32,255:INFO:Uploading model into container now
2024-02-17 00:42:32,256:INFO:_master_model_container: 88
2024-02-17 00:42:32,256:INFO:_display_container: 18
2024-02-17 00:42:32,256:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:42:32,256:INFO:create_model() successfully completed......................................
2024-02-17 00:42:32,382:INFO:SubProcess create_model() end ==================================
2024-02-17 00:42:32,382:INFO:choose_better activated
2024-02-17 00:42:32,382:INFO:SubProcess create_model() called ==================================
2024-02-17 00:42:32,382:INFO:Initializing create_model()
2024-02-17 00:42:32,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:42:32,382:INFO:Checking exceptions
2024-02-17 00:42:32,382:INFO:Importing libraries
2024-02-17 00:42:32,382:INFO:Copying training dataset
2024-02-17 00:42:32,394:INFO:Defining folds
2024-02-17 00:42:32,394:INFO:Declaring metric variables
2024-02-17 00:42:32,394:INFO:Importing untrained model
2024-02-17 00:42:32,394:INFO:Declaring custom model
2024-02-17 00:42:32,394:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:42:32,394:INFO:Starting cross validation
2024-02-17 00:42:32,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:42:32,920:INFO:Calculating mean and std
2024-02-17 00:42:32,920:INFO:Creating metrics dataframe
2024-02-17 00:42:32,920:INFO:Finalizing model
2024-02-17 00:42:33,015:INFO:Uploading results into container
2024-02-17 00:42:33,015:INFO:Uploading model into container now
2024-02-17 00:42:33,015:INFO:_master_model_container: 89
2024-02-17 00:42:33,015:INFO:_display_container: 19
2024-02-17 00:42:33,015:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:42:33,015:INFO:create_model() successfully completed......................................
2024-02-17 00:42:33,149:INFO:SubProcess create_model() end ==================================
2024-02-17 00:42:33,149:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9212
2024-02-17 00:42:33,149:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9103
2024-02-17 00:42:33,155:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-02-17 00:42:33,155:INFO:choose_better completed
2024-02-17 00:42:33,155:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:42:33,158:INFO:_master_model_container: 89
2024-02-17 00:42:33,158:INFO:_display_container: 18
2024-02-17 00:42:33,158:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:42:33,158:INFO:tune_model() successfully completed......................................
2024-02-17 00:42:33,286:INFO:Initializing tune_model()
2024-02-17 00:42:33,286:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:42:33,286:INFO:Checking exceptions
2024-02-17 00:42:33,302:INFO:Copying training dataset
2024-02-17 00:42:33,302:INFO:Checking base model
2024-02-17 00:42:33,302:INFO:Base model : Light Gradient Boosting Machine
2024-02-17 00:42:33,302:INFO:Declaring metric variables
2024-02-17 00:42:33,318:INFO:Defining Hyperparameters
2024-02-17 00:42:33,438:INFO:Tuning with n_jobs=-1
2024-02-17 00:42:33,438:INFO:Initializing RandomizedSearchCV
2024-02-17 00:42:49,962:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2024-02-17 00:42:49,962:INFO:Hyperparameter search completed
2024-02-17 00:42:49,962:INFO:SubProcess create_model() called ==================================
2024-02-17 00:42:49,962:INFO:Initializing create_model()
2024-02-17 00:42:49,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18388B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.15, 'num_leaves': 8, 'n_estimators': 150, 'min_split_gain': 0.1, 'min_child_samples': 41, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2024-02-17 00:42:49,962:INFO:Checking exceptions
2024-02-17 00:42:49,962:INFO:Importing libraries
2024-02-17 00:42:49,962:INFO:Copying training dataset
2024-02-17 00:42:49,975:INFO:Defining folds
2024-02-17 00:42:49,975:INFO:Declaring metric variables
2024-02-17 00:42:49,975:INFO:Importing untrained model
2024-02-17 00:42:49,975:INFO:Declaring custom model
2024-02-17 00:42:49,983:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:42:49,991:INFO:Starting cross validation
2024-02-17 00:42:49,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:42:50,738:INFO:Calculating mean and std
2024-02-17 00:42:50,740:INFO:Creating metrics dataframe
2024-02-17 00:42:50,740:INFO:Finalizing model
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:42:50,758:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:42:50,758:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:42:50,758:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000908 seconds.
2024-02-17 00:42:50,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 00:42:50,758:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:42:50,758:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:42:50,758:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:42:50,884:INFO:Uploading results into container
2024-02-17 00:42:50,885:INFO:Uploading model into container now
2024-02-17 00:42:50,885:INFO:_master_model_container: 90
2024-02-17 00:42:50,885:INFO:_display_container: 19
2024-02-17 00:42:50,885:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:42:50,885:INFO:create_model() successfully completed......................................
2024-02-17 00:42:51,023:INFO:SubProcess create_model() end ==================================
2024-02-17 00:42:51,023:INFO:choose_better activated
2024-02-17 00:42:51,023:INFO:SubProcess create_model() called ==================================
2024-02-17 00:42:51,023:INFO:Initializing create_model()
2024-02-17 00:42:51,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:42:51,028:INFO:Checking exceptions
2024-02-17 00:42:51,028:INFO:Importing libraries
2024-02-17 00:42:51,028:INFO:Copying training dataset
2024-02-17 00:42:51,028:INFO:Defining folds
2024-02-17 00:42:51,028:INFO:Declaring metric variables
2024-02-17 00:42:51,028:INFO:Importing untrained model
2024-02-17 00:42:51,028:INFO:Declaring custom model
2024-02-17 00:42:51,028:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:42:51,028:INFO:Starting cross validation
2024-02-17 00:42:51,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:42:52,384:INFO:Calculating mean and std
2024-02-17 00:42:52,384:INFO:Creating metrics dataframe
2024-02-17 00:42:52,384:INFO:Finalizing model
2024-02-17 00:42:52,406:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:42:52,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.
2024-02-17 00:42:52,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:42:52,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:42:52,417:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:42:52,417:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:42:52,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:42:52,561:INFO:Uploading results into container
2024-02-17 00:42:52,561:INFO:Uploading model into container now
2024-02-17 00:42:52,573:INFO:_master_model_container: 91
2024-02-17 00:42:52,573:INFO:_display_container: 20
2024-02-17 00:42:52,573:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:42:52,573:INFO:create_model() successfully completed......................................
2024-02-17 00:42:52,722:INFO:SubProcess create_model() end ==================================
2024-02-17 00:42:52,723:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9205
2024-02-17 00:42:52,723:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2024-02-17 00:42:52,723:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-17 00:42:52,723:INFO:choose_better completed
2024-02-17 00:42:52,723:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:42:52,730:INFO:_master_model_container: 91
2024-02-17 00:42:52,738:INFO:_display_container: 19
2024-02-17 00:42:52,738:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:42:52,738:INFO:tune_model() successfully completed......................................
2024-02-17 00:43:24,398:INFO:Initializing blend_models()
2024-02-17 00:43:24,398:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-17 00:43:24,398:INFO:Checking exceptions
2024-02-17 00:43:24,416:INFO:Importing libraries
2024-02-17 00:43:24,416:INFO:Copying training dataset
2024-02-17 00:43:24,416:INFO:Getting model names
2024-02-17 00:43:24,426:INFO:SubProcess create_model() called ==================================
2024-02-17 00:43:24,427:INFO:Initializing create_model()
2024-02-17 00:43:24,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1B23E20>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=3957, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1B4FC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:43:24,427:INFO:Checking exceptions
2024-02-17 00:43:24,427:INFO:Importing libraries
2024-02-17 00:43:24,427:INFO:Copying training dataset
2024-02-17 00:43:24,427:INFO:Defining folds
2024-02-17 00:43:24,427:INFO:Declaring metric variables
2024-02-17 00:43:24,440:INFO:Importing untrained model
2024-02-17 00:43:24,440:INFO:Declaring custom model
2024-02-17 00:43:24,441:INFO:Voting Classifier Imported successfully
2024-02-17 00:43:24,458:INFO:Starting cross validation
2024-02-17 00:43:24,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:43:41,039:INFO:Calculating mean and std
2024-02-17 00:43:41,039:INFO:Creating metrics dataframe
2024-02-17 00:43:41,046:INFO:Finalizing model
2024-02-17 00:43:44,293:INFO:Uploading results into container
2024-02-17 00:43:44,296:INFO:Uploading model into container now
2024-02-17 00:43:44,296:INFO:_master_model_container: 92
2024-02-17 00:43:44,296:INFO:_display_container: 20
2024-02-17 00:43:44,296:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1B36A40>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=3957, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:43:44,296:INFO:create_model() successfully completed......................................
2024-02-17 00:43:44,426:INFO:SubProcess create_model() end ==================================
2024-02-17 00:43:44,443:INFO:_master_model_container: 92
2024-02-17 00:43:44,443:INFO:_display_container: 20
2024-02-17 00:43:44,443:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1B36A40>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=3957, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:43:44,443:INFO:blend_models() successfully completed......................................
2024-02-17 00:44:57,472:INFO:Initializing compare_models()
2024-02-17 00:44:57,472:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 00:44:57,472:INFO:Checking exceptions
2024-02-17 00:44:57,477:INFO:Preparing display monitor
2024-02-17 00:44:57,502:INFO:Initializing Logistic Regression
2024-02-17 00:44:57,502:INFO:Total runtime is 0.0 minutes
2024-02-17 00:44:57,511:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:57,513:INFO:Initializing create_model()
2024-02-17 00:44:57,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:57,513:INFO:Checking exceptions
2024-02-17 00:44:57,513:INFO:Importing libraries
2024-02-17 00:44:57,513:INFO:Copying training dataset
2024-02-17 00:44:57,517:INFO:Defining folds
2024-02-17 00:44:57,517:INFO:Declaring metric variables
2024-02-17 00:44:57,551:INFO:Importing untrained model
2024-02-17 00:44:57,554:INFO:Logistic Regression Imported successfully
2024-02-17 00:44:57,563:INFO:Starting cross validation
2024-02-17 00:44:57,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:44:58,466:INFO:Calculating mean and std
2024-02-17 00:44:58,467:INFO:Creating metrics dataframe
2024-02-17 00:44:58,467:INFO:Uploading results into container
2024-02-17 00:44:58,467:INFO:Uploading model into container now
2024-02-17 00:44:58,467:INFO:_master_model_container: 93
2024-02-17 00:44:58,467:INFO:_display_container: 21
2024-02-17 00:44:58,467:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3957, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 00:44:58,467:INFO:create_model() successfully completed......................................
2024-02-17 00:44:58,580:INFO:SubProcess create_model() end ==================================
2024-02-17 00:44:58,580:INFO:Creating metrics dataframe
2024-02-17 00:44:58,595:INFO:Initializing K Neighbors Classifier
2024-02-17 00:44:58,595:INFO:Total runtime is 0.018214305241902668 minutes
2024-02-17 00:44:58,597:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:58,597:INFO:Initializing create_model()
2024-02-17 00:44:58,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:58,597:INFO:Checking exceptions
2024-02-17 00:44:58,597:INFO:Importing libraries
2024-02-17 00:44:58,597:INFO:Copying training dataset
2024-02-17 00:44:58,597:INFO:Defining folds
2024-02-17 00:44:58,597:INFO:Declaring metric variables
2024-02-17 00:44:58,597:INFO:Importing untrained model
2024-02-17 00:44:58,614:INFO:K Neighbors Classifier Imported successfully
2024-02-17 00:44:58,616:INFO:Starting cross validation
2024-02-17 00:44:58,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:44:58,830:INFO:Calculating mean and std
2024-02-17 00:44:58,833:INFO:Creating metrics dataframe
2024-02-17 00:44:58,839:INFO:Uploading results into container
2024-02-17 00:44:58,840:INFO:Uploading model into container now
2024-02-17 00:44:58,841:INFO:_master_model_container: 94
2024-02-17 00:44:58,841:INFO:_display_container: 21
2024-02-17 00:44:58,842:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 00:44:58,842:INFO:create_model() successfully completed......................................
2024-02-17 00:44:58,957:INFO:SubProcess create_model() end ==================================
2024-02-17 00:44:58,960:INFO:Creating metrics dataframe
2024-02-17 00:44:58,966:INFO:Initializing Naive Bayes
2024-02-17 00:44:58,966:INFO:Total runtime is 0.024396344025929766 minutes
2024-02-17 00:44:58,974:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:58,974:INFO:Initializing create_model()
2024-02-17 00:44:58,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:58,974:INFO:Checking exceptions
2024-02-17 00:44:58,974:INFO:Importing libraries
2024-02-17 00:44:58,974:INFO:Copying training dataset
2024-02-17 00:44:58,980:INFO:Defining folds
2024-02-17 00:44:58,980:INFO:Declaring metric variables
2024-02-17 00:44:58,980:INFO:Importing untrained model
2024-02-17 00:44:58,980:INFO:Naive Bayes Imported successfully
2024-02-17 00:44:58,991:INFO:Starting cross validation
2024-02-17 00:44:58,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:44:59,078:INFO:Calculating mean and std
2024-02-17 00:44:59,078:INFO:Creating metrics dataframe
2024-02-17 00:44:59,080:INFO:Uploading results into container
2024-02-17 00:44:59,080:INFO:Uploading model into container now
2024-02-17 00:44:59,080:INFO:_master_model_container: 95
2024-02-17 00:44:59,080:INFO:_display_container: 21
2024-02-17 00:44:59,080:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 00:44:59,080:INFO:create_model() successfully completed......................................
2024-02-17 00:44:59,184:INFO:SubProcess create_model() end ==================================
2024-02-17 00:44:59,184:INFO:Creating metrics dataframe
2024-02-17 00:44:59,198:INFO:Initializing Decision Tree Classifier
2024-02-17 00:44:59,198:INFO:Total runtime is 0.028255645434061682 minutes
2024-02-17 00:44:59,199:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:59,199:INFO:Initializing create_model()
2024-02-17 00:44:59,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:59,199:INFO:Checking exceptions
2024-02-17 00:44:59,199:INFO:Importing libraries
2024-02-17 00:44:59,199:INFO:Copying training dataset
2024-02-17 00:44:59,199:INFO:Defining folds
2024-02-17 00:44:59,199:INFO:Declaring metric variables
2024-02-17 00:44:59,212:INFO:Importing untrained model
2024-02-17 00:44:59,242:INFO:Decision Tree Classifier Imported successfully
2024-02-17 00:44:59,246:INFO:Starting cross validation
2024-02-17 00:44:59,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:44:59,390:INFO:Calculating mean and std
2024-02-17 00:44:59,390:INFO:Creating metrics dataframe
2024-02-17 00:44:59,395:INFO:Uploading results into container
2024-02-17 00:44:59,396:INFO:Uploading model into container now
2024-02-17 00:44:59,396:INFO:_master_model_container: 96
2024-02-17 00:44:59,396:INFO:_display_container: 21
2024-02-17 00:44:59,398:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3957, splitter='best')
2024-02-17 00:44:59,398:INFO:create_model() successfully completed......................................
2024-02-17 00:44:59,501:INFO:SubProcess create_model() end ==================================
2024-02-17 00:44:59,501:INFO:Creating metrics dataframe
2024-02-17 00:44:59,516:INFO:Initializing SVM - Linear Kernel
2024-02-17 00:44:59,516:INFO:Total runtime is 0.033568950494130445 minutes
2024-02-17 00:44:59,516:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:59,516:INFO:Initializing create_model()
2024-02-17 00:44:59,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:59,516:INFO:Checking exceptions
2024-02-17 00:44:59,516:INFO:Importing libraries
2024-02-17 00:44:59,516:INFO:Copying training dataset
2024-02-17 00:44:59,516:INFO:Defining folds
2024-02-17 00:44:59,516:INFO:Declaring metric variables
2024-02-17 00:44:59,516:INFO:Importing untrained model
2024-02-17 00:44:59,534:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 00:44:59,534:INFO:Starting cross validation
2024-02-17 00:44:59,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:44:59,688:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,704:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,704:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,704:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,716:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,716:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,729:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,729:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,776:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,808:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:44:59,824:INFO:Calculating mean and std
2024-02-17 00:44:59,824:INFO:Creating metrics dataframe
2024-02-17 00:44:59,830:INFO:Uploading results into container
2024-02-17 00:44:59,830:INFO:Uploading model into container now
2024-02-17 00:44:59,830:INFO:_master_model_container: 97
2024-02-17 00:44:59,830:INFO:_display_container: 21
2024-02-17 00:44:59,830:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3957, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 00:44:59,830:INFO:create_model() successfully completed......................................
2024-02-17 00:44:59,943:INFO:SubProcess create_model() end ==================================
2024-02-17 00:44:59,943:INFO:Creating metrics dataframe
2024-02-17 00:44:59,943:INFO:Initializing Ridge Classifier
2024-02-17 00:44:59,943:INFO:Total runtime is 0.04068748156229654 minutes
2024-02-17 00:44:59,943:INFO:SubProcess create_model() called ==================================
2024-02-17 00:44:59,943:INFO:Initializing create_model()
2024-02-17 00:44:59,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:44:59,943:INFO:Checking exceptions
2024-02-17 00:44:59,943:INFO:Importing libraries
2024-02-17 00:44:59,943:INFO:Copying training dataset
2024-02-17 00:44:59,959:INFO:Defining folds
2024-02-17 00:44:59,959:INFO:Declaring metric variables
2024-02-17 00:44:59,959:INFO:Importing untrained model
2024-02-17 00:44:59,969:INFO:Ridge Classifier Imported successfully
2024-02-17 00:44:59,969:INFO:Starting cross validation
2024-02-17 00:44:59,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:00,020:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,020:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,020:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,030:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,030:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,030:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,037:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,045:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,046:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,046:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 00:45:00,076:INFO:Calculating mean and std
2024-02-17 00:45:00,076:INFO:Creating metrics dataframe
2024-02-17 00:45:00,076:INFO:Uploading results into container
2024-02-17 00:45:00,076:INFO:Uploading model into container now
2024-02-17 00:45:00,076:INFO:_master_model_container: 98
2024-02-17 00:45:00,076:INFO:_display_container: 21
2024-02-17 00:45:00,082:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3957, solver='auto',
                tol=0.0001)
2024-02-17 00:45:00,082:INFO:create_model() successfully completed......................................
2024-02-17 00:45:00,176:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:00,176:INFO:Creating metrics dataframe
2024-02-17 00:45:00,199:INFO:Initializing Random Forest Classifier
2024-02-17 00:45:00,199:INFO:Total runtime is 0.044940439860026035 minutes
2024-02-17 00:45:00,199:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:00,199:INFO:Initializing create_model()
2024-02-17 00:45:00,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:00,199:INFO:Checking exceptions
2024-02-17 00:45:00,199:INFO:Importing libraries
2024-02-17 00:45:00,199:INFO:Copying training dataset
2024-02-17 00:45:00,208:INFO:Defining folds
2024-02-17 00:45:00,208:INFO:Declaring metric variables
2024-02-17 00:45:00,214:INFO:Importing untrained model
2024-02-17 00:45:00,217:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:45:00,217:INFO:Starting cross validation
2024-02-17 00:45:00,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:01,888:INFO:Calculating mean and std
2024-02-17 00:45:01,888:INFO:Creating metrics dataframe
2024-02-17 00:45:01,888:INFO:Uploading results into container
2024-02-17 00:45:01,888:INFO:Uploading model into container now
2024-02-17 00:45:01,888:INFO:_master_model_container: 99
2024-02-17 00:45:01,888:INFO:_display_container: 21
2024-02-17 00:45:01,897:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:45:01,897:INFO:create_model() successfully completed......................................
2024-02-17 00:45:02,000:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:02,000:INFO:Creating metrics dataframe
2024-02-17 00:45:02,016:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 00:45:02,016:INFO:Total runtime is 0.07522604862848917 minutes
2024-02-17 00:45:02,016:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:02,016:INFO:Initializing create_model()
2024-02-17 00:45:02,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:02,016:INFO:Checking exceptions
2024-02-17 00:45:02,016:INFO:Importing libraries
2024-02-17 00:45:02,016:INFO:Copying training dataset
2024-02-17 00:45:02,024:INFO:Defining folds
2024-02-17 00:45:02,024:INFO:Declaring metric variables
2024-02-17 00:45:02,024:INFO:Importing untrained model
2024-02-17 00:45:02,034:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 00:45:02,034:INFO:Starting cross validation
2024-02-17 00:45:02,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:02,142:INFO:Calculating mean and std
2024-02-17 00:45:02,142:INFO:Creating metrics dataframe
2024-02-17 00:45:02,148:INFO:Uploading results into container
2024-02-17 00:45:02,149:INFO:Uploading model into container now
2024-02-17 00:45:02,150:INFO:_master_model_container: 100
2024-02-17 00:45:02,150:INFO:_display_container: 21
2024-02-17 00:45:02,150:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 00:45:02,151:INFO:create_model() successfully completed......................................
2024-02-17 00:45:02,260:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:02,260:INFO:Creating metrics dataframe
2024-02-17 00:45:02,263:INFO:Initializing Ada Boost Classifier
2024-02-17 00:45:02,263:INFO:Total runtime is 0.07934804757436116 minutes
2024-02-17 00:45:02,276:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:02,276:INFO:Initializing create_model()
2024-02-17 00:45:02,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:02,276:INFO:Checking exceptions
2024-02-17 00:45:02,276:INFO:Importing libraries
2024-02-17 00:45:02,276:INFO:Copying training dataset
2024-02-17 00:45:02,276:INFO:Defining folds
2024-02-17 00:45:02,276:INFO:Declaring metric variables
2024-02-17 00:45:02,276:INFO:Importing untrained model
2024-02-17 00:45:02,289:INFO:Ada Boost Classifier Imported successfully
2024-02-17 00:45:02,301:INFO:Starting cross validation
2024-02-17 00:45:02,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:03,127:INFO:Calculating mean and std
2024-02-17 00:45:03,127:INFO:Creating metrics dataframe
2024-02-17 00:45:03,133:INFO:Uploading results into container
2024-02-17 00:45:03,133:INFO:Uploading model into container now
2024-02-17 00:45:03,133:INFO:_master_model_container: 101
2024-02-17 00:45:03,133:INFO:_display_container: 21
2024-02-17 00:45:03,133:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3957)
2024-02-17 00:45:03,133:INFO:create_model() successfully completed......................................
2024-02-17 00:45:03,243:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:03,243:INFO:Creating metrics dataframe
2024-02-17 00:45:03,243:INFO:Initializing Gradient Boosting Classifier
2024-02-17 00:45:03,243:INFO:Total runtime is 0.09567445119222004 minutes
2024-02-17 00:45:03,259:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:03,259:INFO:Initializing create_model()
2024-02-17 00:45:03,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:03,259:INFO:Checking exceptions
2024-02-17 00:45:03,259:INFO:Importing libraries
2024-02-17 00:45:03,259:INFO:Copying training dataset
2024-02-17 00:45:03,266:INFO:Defining folds
2024-02-17 00:45:03,266:INFO:Declaring metric variables
2024-02-17 00:45:03,266:INFO:Importing untrained model
2024-02-17 00:45:03,273:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 00:45:03,285:INFO:Starting cross validation
2024-02-17 00:45:03,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:05,597:INFO:Calculating mean and std
2024-02-17 00:45:05,598:INFO:Creating metrics dataframe
2024-02-17 00:45:05,599:INFO:Uploading results into container
2024-02-17 00:45:05,599:INFO:Uploading model into container now
2024-02-17 00:45:05,599:INFO:_master_model_container: 102
2024-02-17 00:45:05,599:INFO:_display_container: 21
2024-02-17 00:45:05,605:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3957, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 00:45:05,605:INFO:create_model() successfully completed......................................
2024-02-17 00:45:05,712:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:05,712:INFO:Creating metrics dataframe
2024-02-17 00:45:05,728:INFO:Initializing Linear Discriminant Analysis
2024-02-17 00:45:05,728:INFO:Total runtime is 0.13709137042363484 minutes
2024-02-17 00:45:05,728:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:05,728:INFO:Initializing create_model()
2024-02-17 00:45:05,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:05,728:INFO:Checking exceptions
2024-02-17 00:45:05,728:INFO:Importing libraries
2024-02-17 00:45:05,728:INFO:Copying training dataset
2024-02-17 00:45:05,728:INFO:Defining folds
2024-02-17 00:45:05,728:INFO:Declaring metric variables
2024-02-17 00:45:05,728:INFO:Importing untrained model
2024-02-17 00:45:05,748:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 00:45:05,748:INFO:Starting cross validation
2024-02-17 00:45:05,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:05,849:INFO:Calculating mean and std
2024-02-17 00:45:05,849:INFO:Creating metrics dataframe
2024-02-17 00:45:05,849:INFO:Uploading results into container
2024-02-17 00:45:05,849:INFO:Uploading model into container now
2024-02-17 00:45:05,849:INFO:_master_model_container: 103
2024-02-17 00:45:05,849:INFO:_display_container: 21
2024-02-17 00:45:05,849:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 00:45:05,849:INFO:create_model() successfully completed......................................
2024-02-17 00:45:05,986:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:05,986:INFO:Creating metrics dataframe
2024-02-17 00:45:05,997:INFO:Initializing Extra Trees Classifier
2024-02-17 00:45:05,997:INFO:Total runtime is 0.14158684015274048 minutes
2024-02-17 00:45:06,006:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:06,006:INFO:Initializing create_model()
2024-02-17 00:45:06,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:06,006:INFO:Checking exceptions
2024-02-17 00:45:06,006:INFO:Importing libraries
2024-02-17 00:45:06,006:INFO:Copying training dataset
2024-02-17 00:45:06,006:INFO:Defining folds
2024-02-17 00:45:06,006:INFO:Declaring metric variables
2024-02-17 00:45:06,015:INFO:Importing untrained model
2024-02-17 00:45:06,015:INFO:Extra Trees Classifier Imported successfully
2024-02-17 00:45:06,015:INFO:Starting cross validation
2024-02-17 00:45:06,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:07,786:INFO:Calculating mean and std
2024-02-17 00:45:07,786:INFO:Creating metrics dataframe
2024-02-17 00:45:07,794:INFO:Uploading results into container
2024-02-17 00:45:07,794:INFO:Uploading model into container now
2024-02-17 00:45:07,796:INFO:_master_model_container: 104
2024-02-17 00:45:07,796:INFO:_display_container: 21
2024-02-17 00:45:07,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:45:07,796:INFO:create_model() successfully completed......................................
2024-02-17 00:45:07,926:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:07,926:INFO:Creating metrics dataframe
2024-02-17 00:45:07,943:INFO:Initializing Extreme Gradient Boosting
2024-02-17 00:45:07,943:INFO:Total runtime is 0.1740070382754008 minutes
2024-02-17 00:45:07,947:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:07,947:INFO:Initializing create_model()
2024-02-17 00:45:07,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:07,947:INFO:Checking exceptions
2024-02-17 00:45:07,947:INFO:Importing libraries
2024-02-17 00:45:07,947:INFO:Copying training dataset
2024-02-17 00:45:07,947:INFO:Defining folds
2024-02-17 00:45:07,947:INFO:Declaring metric variables
2024-02-17 00:45:07,963:INFO:Importing untrained model
2024-02-17 00:45:07,966:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:45:07,980:INFO:Starting cross validation
2024-02-17 00:45:07,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:08,729:INFO:Calculating mean and std
2024-02-17 00:45:08,730:INFO:Creating metrics dataframe
2024-02-17 00:45:08,730:INFO:Uploading results into container
2024-02-17 00:45:08,730:INFO:Uploading model into container now
2024-02-17 00:45:08,730:INFO:_master_model_container: 105
2024-02-17 00:45:08,730:INFO:_display_container: 21
2024-02-17 00:45:08,730:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:45:08,730:INFO:create_model() successfully completed......................................
2024-02-17 00:45:08,870:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:08,870:INFO:Creating metrics dataframe
2024-02-17 00:45:08,898:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 00:45:08,898:INFO:Total runtime is 0.18993174235026042 minutes
2024-02-17 00:45:08,900:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:08,900:INFO:Initializing create_model()
2024-02-17 00:45:08,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:08,900:INFO:Checking exceptions
2024-02-17 00:45:08,900:INFO:Importing libraries
2024-02-17 00:45:08,900:INFO:Copying training dataset
2024-02-17 00:45:08,913:INFO:Defining folds
2024-02-17 00:45:08,913:INFO:Declaring metric variables
2024-02-17 00:45:08,920:INFO:Importing untrained model
2024-02-17 00:45:08,923:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:45:08,933:INFO:Starting cross validation
2024-02-17 00:45:08,933:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:10,943:INFO:Calculating mean and std
2024-02-17 00:45:10,943:INFO:Creating metrics dataframe
2024-02-17 00:45:10,947:INFO:Uploading results into container
2024-02-17 00:45:10,947:INFO:Uploading model into container now
2024-02-17 00:45:10,947:INFO:_master_model_container: 106
2024-02-17 00:45:10,947:INFO:_display_container: 21
2024-02-17 00:45:10,959:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:45:10,959:INFO:create_model() successfully completed......................................
2024-02-17 00:45:11,078:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:11,078:INFO:Creating metrics dataframe
2024-02-17 00:45:11,094:INFO:Initializing CatBoost Classifier
2024-02-17 00:45:11,094:INFO:Total runtime is 0.22652732531229655 minutes
2024-02-17 00:45:11,094:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:11,094:INFO:Initializing create_model()
2024-02-17 00:45:11,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:11,094:INFO:Checking exceptions
2024-02-17 00:45:11,094:INFO:Importing libraries
2024-02-17 00:45:11,094:INFO:Copying training dataset
2024-02-17 00:45:11,113:INFO:Defining folds
2024-02-17 00:45:11,113:INFO:Declaring metric variables
2024-02-17 00:45:11,117:INFO:Importing untrained model
2024-02-17 00:45:11,117:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:45:11,130:INFO:Starting cross validation
2024-02-17 00:45:11,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:33,043:INFO:Calculating mean and std
2024-02-17 00:45:33,043:INFO:Creating metrics dataframe
2024-02-17 00:45:33,056:INFO:Uploading results into container
2024-02-17 00:45:33,056:INFO:Uploading model into container now
2024-02-17 00:45:33,056:INFO:_master_model_container: 107
2024-02-17 00:45:33,056:INFO:_display_container: 21
2024-02-17 00:45:33,056:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B37CA0>
2024-02-17 00:45:33,056:INFO:create_model() successfully completed......................................
2024-02-17 00:45:33,315:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:33,315:INFO:Creating metrics dataframe
2024-02-17 00:45:33,360:INFO:Initializing Dummy Classifier
2024-02-17 00:45:33,360:INFO:Total runtime is 0.5976339062054952 minutes
2024-02-17 00:45:33,370:INFO:SubProcess create_model() called ==================================
2024-02-17 00:45:33,370:INFO:Initializing create_model()
2024-02-17 00:45:33,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC18BAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:33,370:INFO:Checking exceptions
2024-02-17 00:45:33,370:INFO:Importing libraries
2024-02-17 00:45:33,370:INFO:Copying training dataset
2024-02-17 00:45:33,399:INFO:Defining folds
2024-02-17 00:45:33,399:INFO:Declaring metric variables
2024-02-17 00:45:33,415:INFO:Importing untrained model
2024-02-17 00:45:33,420:INFO:Dummy Classifier Imported successfully
2024-02-17 00:45:33,446:INFO:Starting cross validation
2024-02-17 00:45:33,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:45:33,601:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:45:33,615:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:45:33,616:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:45:33,644:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:45:33,649:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:45:33,676:INFO:Calculating mean and std
2024-02-17 00:45:33,676:INFO:Creating metrics dataframe
2024-02-17 00:45:33,683:INFO:Uploading results into container
2024-02-17 00:45:33,692:INFO:Uploading model into container now
2024-02-17 00:45:33,692:INFO:_master_model_container: 108
2024-02-17 00:45:33,692:INFO:_display_container: 21
2024-02-17 00:45:33,696:INFO:DummyClassifier(constant=None, random_state=3957, strategy='prior')
2024-02-17 00:45:33,696:INFO:create_model() successfully completed......................................
2024-02-17 00:45:33,933:INFO:SubProcess create_model() end ==================================
2024-02-17 00:45:33,933:INFO:Creating metrics dataframe
2024-02-17 00:45:34,018:INFO:Initializing create_model()
2024-02-17 00:45:34,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1B37CA0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:34,018:INFO:Checking exceptions
2024-02-17 00:45:34,099:INFO:Importing libraries
2024-02-17 00:45:34,099:INFO:Copying training dataset
2024-02-17 00:45:34,115:INFO:Defining folds
2024-02-17 00:45:34,115:INFO:Declaring metric variables
2024-02-17 00:45:34,115:INFO:Importing untrained model
2024-02-17 00:45:34,115:INFO:Declaring custom model
2024-02-17 00:45:34,115:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:45:34,115:INFO:Cross validation set to False
2024-02-17 00:45:34,115:INFO:Fitting Model
2024-02-17 00:45:45,984:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC19ABA00>
2024-02-17 00:45:45,984:INFO:create_model() successfully completed......................................
2024-02-17 00:45:46,267:INFO:Initializing create_model()
2024-02-17 00:45:46,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:46,267:INFO:Checking exceptions
2024-02-17 00:45:46,272:INFO:Importing libraries
2024-02-17 00:45:46,272:INFO:Copying training dataset
2024-02-17 00:45:46,286:INFO:Defining folds
2024-02-17 00:45:46,286:INFO:Declaring metric variables
2024-02-17 00:45:46,286:INFO:Importing untrained model
2024-02-17 00:45:46,286:INFO:Declaring custom model
2024-02-17 00:45:46,297:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:45:46,299:INFO:Cross validation set to False
2024-02-17 00:45:46,299:INFO:Fitting Model
2024-02-17 00:45:46,666:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:45:46,666:INFO:create_model() successfully completed......................................
2024-02-17 00:45:46,963:INFO:Initializing create_model()
2024-02-17 00:45:46,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:46,966:INFO:Checking exceptions
2024-02-17 00:45:46,966:INFO:Importing libraries
2024-02-17 00:45:46,966:INFO:Copying training dataset
2024-02-17 00:45:46,970:INFO:Defining folds
2024-02-17 00:45:46,970:INFO:Declaring metric variables
2024-02-17 00:45:46,970:INFO:Importing untrained model
2024-02-17 00:45:46,970:INFO:Declaring custom model
2024-02-17 00:45:46,970:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:45:46,979:INFO:Cross validation set to False
2024-02-17 00:45:46,979:INFO:Fitting Model
2024-02-17 00:45:47,003:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:45:47,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001188 seconds.
2024-02-17 00:45:47,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:45:47,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:45:47,012:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:45:47,012:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:45:47,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:45:47,296:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:45:47,299:INFO:create_model() successfully completed......................................
2024-02-17 00:45:47,593:INFO:Initializing create_model()
2024-02-17 00:45:47,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:45:47,593:INFO:Checking exceptions
2024-02-17 00:45:47,601:INFO:Importing libraries
2024-02-17 00:45:47,601:INFO:Copying training dataset
2024-02-17 00:45:47,616:INFO:Defining folds
2024-02-17 00:45:47,616:INFO:Declaring metric variables
2024-02-17 00:45:47,616:INFO:Importing untrained model
2024-02-17 00:45:47,616:INFO:Declaring custom model
2024-02-17 00:45:47,616:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:45:47,616:INFO:Cross validation set to False
2024-02-17 00:45:47,624:INFO:Fitting Model
2024-02-17 00:45:48,609:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:45:48,609:INFO:create_model() successfully completed......................................
2024-02-17 00:45:48,992:INFO:_master_model_container: 108
2024-02-17 00:45:48,992:INFO:_display_container: 21
2024-02-17 00:45:49,000:INFO:[<catboost.core.CatBoostClassifier object at 0x0000028DC19ABA00>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)]
2024-02-17 00:45:49,000:INFO:compare_models() successfully completed......................................
2024-02-17 00:46:15,252:INFO:Initializing tune_model()
2024-02-17 00:46:15,252:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC19ABA00>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:46:15,252:INFO:Checking exceptions
2024-02-17 00:46:15,328:INFO:Copying training dataset
2024-02-17 00:46:15,335:INFO:Checking base model
2024-02-17 00:46:15,335:INFO:Base model : CatBoost Classifier
2024-02-17 00:46:15,348:INFO:Declaring metric variables
2024-02-17 00:46:15,367:INFO:Defining Hyperparameters
2024-02-17 00:46:15,663:INFO:Tuning with n_jobs=-1
2024-02-17 00:46:15,663:INFO:Initializing RandomizedSearchCV
2024-02-17 00:47:25,133:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 5100, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2303, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\catboost\core.py", line 2230, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6105, in _catboost._check_train_params
  File "_catboost.pyx", line 6124, in _catboost._check_train_params
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-02-17 00:47:25,134:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84742268 0.80574374        nan 0.90029455 0.8353461  0.90795287
 0.92076583 0.82268041 0.86023564 0.88468336]
  warnings.warn(

2024-02-17 00:47:25,134:INFO:best_params: {'actual_estimator__random_strength': 0.5, 'actual_estimator__n_estimators': 250, 'actual_estimator__l2_leaf_reg': 6, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 8}
2024-02-17 00:47:25,134:INFO:Hyperparameter search completed
2024-02-17 00:47:25,134:INFO:SubProcess create_model() called ==================================
2024-02-17 00:47:25,137:INFO:Initializing create_model()
2024-02-17 00:47:25,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1BC6650>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBEB15A80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.5, 'n_estimators': 250, 'l2_leaf_reg': 6, 'eta': 0.1, 'depth': 8})
2024-02-17 00:47:25,137:INFO:Checking exceptions
2024-02-17 00:47:25,137:INFO:Importing libraries
2024-02-17 00:47:25,138:INFO:Copying training dataset
2024-02-17 00:47:25,143:INFO:Defining folds
2024-02-17 00:47:25,143:INFO:Declaring metric variables
2024-02-17 00:47:25,143:INFO:Importing untrained model
2024-02-17 00:47:25,143:INFO:Declaring custom model
2024-02-17 00:47:25,157:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:47:25,157:INFO:Starting cross validation
2024-02-17 00:47:25,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:47:33,486:INFO:Calculating mean and std
2024-02-17 00:47:33,488:INFO:Creating metrics dataframe
2024-02-17 00:47:33,488:INFO:Finalizing model
2024-02-17 00:47:35,198:INFO:Uploading results into container
2024-02-17 00:47:35,198:INFO:Uploading model into container now
2024-02-17 00:47:35,198:INFO:_master_model_container: 109
2024-02-17 00:47:35,198:INFO:_display_container: 22
2024-02-17 00:47:35,198:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1BC7340>
2024-02-17 00:47:35,198:INFO:create_model() successfully completed......................................
2024-02-17 00:47:35,340:INFO:SubProcess create_model() end ==================================
2024-02-17 00:47:35,340:INFO:choose_better activated
2024-02-17 00:47:35,340:INFO:SubProcess create_model() called ==================================
2024-02-17 00:47:35,340:INFO:Initializing create_model()
2024-02-17 00:47:35,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC19ABA00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:47:35,340:INFO:Checking exceptions
2024-02-17 00:47:35,340:INFO:Importing libraries
2024-02-17 00:47:35,340:INFO:Copying training dataset
2024-02-17 00:47:35,349:INFO:Defining folds
2024-02-17 00:47:35,349:INFO:Declaring metric variables
2024-02-17 00:47:35,349:INFO:Importing untrained model
2024-02-17 00:47:35,349:INFO:Declaring custom model
2024-02-17 00:47:35,349:INFO:CatBoost Classifier Imported successfully
2024-02-17 00:47:35,349:INFO:Starting cross validation
2024-02-17 00:47:35,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:47:53,333:INFO:Calculating mean and std
2024-02-17 00:47:53,333:INFO:Creating metrics dataframe
2024-02-17 00:47:53,333:INFO:Finalizing model
2024-02-17 00:47:57,639:INFO:Uploading results into container
2024-02-17 00:47:57,639:INFO:Uploading model into container now
2024-02-17 00:47:57,639:INFO:_master_model_container: 110
2024-02-17 00:47:57,639:INFO:_display_container: 23
2024-02-17 00:47:57,639:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC19A9780>
2024-02-17 00:47:57,639:INFO:create_model() successfully completed......................................
2024-02-17 00:47:57,772:INFO:SubProcess create_model() end ==================================
2024-02-17 00:47:57,772:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC19A9780> result for Accuracy is 0.9227
2024-02-17 00:47:57,772:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1BC7340> result for Accuracy is 0.9208
2024-02-17 00:47:57,772:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC19A9780> is best model
2024-02-17 00:47:57,772:INFO:choose_better completed
2024-02-17 00:47:57,772:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:47:57,787:INFO:_master_model_container: 110
2024-02-17 00:47:57,787:INFO:_display_container: 22
2024-02-17 00:47:57,789:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC19A9780>
2024-02-17 00:47:57,789:INFO:tune_model() successfully completed......................................
2024-02-17 00:47:57,920:INFO:Initializing tune_model()
2024-02-17 00:47:57,920:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:47:57,920:INFO:Checking exceptions
2024-02-17 00:47:57,939:INFO:Copying training dataset
2024-02-17 00:47:57,951:INFO:Checking base model
2024-02-17 00:47:57,951:INFO:Base model : Extreme Gradient Boosting
2024-02-17 00:47:57,955:INFO:Declaring metric variables
2024-02-17 00:47:57,959:INFO:Defining Hyperparameters
2024-02-17 00:47:58,113:INFO:Tuning with n_jobs=-1
2024-02-17 00:47:58,113:INFO:Initializing RandomizedSearchCV
2024-02-17 00:48:06,668:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 13.4, 'actual_estimator__reg_lambda': 0.005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_child_weight': 3, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__colsample_bytree': 0.7}
2024-02-17 00:48:06,668:INFO:Hyperparameter search completed
2024-02-17 00:48:06,668:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:06,668:INFO:Initializing create_model()
2024-02-17 00:48:06,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE2C0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 13.4, 'reg_lambda': 0.005, 'reg_alpha': 0.005, 'n_estimators': 150, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.15, 'colsample_bytree': 0.7})
2024-02-17 00:48:06,668:INFO:Checking exceptions
2024-02-17 00:48:06,668:INFO:Importing libraries
2024-02-17 00:48:06,668:INFO:Copying training dataset
2024-02-17 00:48:06,678:INFO:Defining folds
2024-02-17 00:48:06,678:INFO:Declaring metric variables
2024-02-17 00:48:06,689:INFO:Importing untrained model
2024-02-17 00:48:06,689:INFO:Declaring custom model
2024-02-17 00:48:06,693:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:48:06,706:INFO:Starting cross validation
2024-02-17 00:48:06,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:08,126:INFO:Calculating mean and std
2024-02-17 00:48:08,126:INFO:Creating metrics dataframe
2024-02-17 00:48:08,126:INFO:Finalizing model
2024-02-17 00:48:08,390:INFO:Uploading results into container
2024-02-17 00:48:08,391:INFO:Uploading model into container now
2024-02-17 00:48:08,391:INFO:_master_model_container: 111
2024-02-17 00:48:08,392:INFO:_display_container: 23
2024-02-17 00:48:08,393:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:48:08,393:INFO:create_model() successfully completed......................................
2024-02-17 00:48:08,520:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:08,520:INFO:choose_better activated
2024-02-17 00:48:08,520:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:08,520:INFO:Initializing create_model()
2024-02-17 00:48:08,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:48:08,520:INFO:Checking exceptions
2024-02-17 00:48:08,520:INFO:Importing libraries
2024-02-17 00:48:08,520:INFO:Copying training dataset
2024-02-17 00:48:08,535:INFO:Defining folds
2024-02-17 00:48:08,535:INFO:Declaring metric variables
2024-02-17 00:48:08,535:INFO:Importing untrained model
2024-02-17 00:48:08,535:INFO:Declaring custom model
2024-02-17 00:48:08,535:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 00:48:08,535:INFO:Starting cross validation
2024-02-17 00:48:08,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:09,049:INFO:Calculating mean and std
2024-02-17 00:48:09,050:INFO:Creating metrics dataframe
2024-02-17 00:48:09,050:INFO:Finalizing model
2024-02-17 00:48:09,156:INFO:Uploading results into container
2024-02-17 00:48:09,156:INFO:Uploading model into container now
2024-02-17 00:48:09,156:INFO:_master_model_container: 112
2024-02-17 00:48:09,156:INFO:_display_container: 24
2024-02-17 00:48:09,156:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:48:09,156:INFO:create_model() successfully completed......................................
2024-02-17 00:48:09,292:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:09,292:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9212
2024-02-17 00:48:09,292:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.7, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.15, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=3, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=150, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9103
2024-02-17 00:48:09,292:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-02-17 00:48:09,292:INFO:choose_better completed
2024-02-17 00:48:09,292:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:48:09,326:INFO:_master_model_container: 112
2024-02-17 00:48:09,326:INFO:_display_container: 23
2024-02-17 00:48:09,327:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 00:48:09,327:INFO:tune_model() successfully completed......................................
2024-02-17 00:48:09,457:INFO:Initializing tune_model()
2024-02-17 00:48:09,457:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:48:09,457:INFO:Checking exceptions
2024-02-17 00:48:09,470:INFO:Copying training dataset
2024-02-17 00:48:09,475:INFO:Checking base model
2024-02-17 00:48:09,475:INFO:Base model : Light Gradient Boosting Machine
2024-02-17 00:48:09,475:INFO:Declaring metric variables
2024-02-17 00:48:09,484:INFO:Defining Hyperparameters
2024-02-17 00:48:09,592:INFO:Tuning with n_jobs=-1
2024-02-17 00:48:09,592:INFO:Initializing RandomizedSearchCV
2024-02-17 00:48:26,836:INFO:best_params: {'actual_estimator__reg_lambda': 0.0001, 'actual_estimator__reg_alpha': 0.15, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2024-02-17 00:48:26,836:INFO:Hyperparameter search completed
2024-02-17 00:48:26,836:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:26,840:INFO:Initializing create_model()
2024-02-17 00:48:26,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE8C0E80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.0001, 'reg_alpha': 0.15, 'num_leaves': 8, 'n_estimators': 150, 'min_split_gain': 0.1, 'min_child_samples': 41, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2024-02-17 00:48:26,840:INFO:Checking exceptions
2024-02-17 00:48:26,841:INFO:Importing libraries
2024-02-17 00:48:26,841:INFO:Copying training dataset
2024-02-17 00:48:26,844:INFO:Defining folds
2024-02-17 00:48:26,844:INFO:Declaring metric variables
2024-02-17 00:48:26,844:INFO:Importing untrained model
2024-02-17 00:48:26,844:INFO:Declaring custom model
2024-02-17 00:48:26,857:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:48:26,859:INFO:Starting cross validation
2024-02-17 00:48:26,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:27,652:INFO:Calculating mean and std
2024-02-17 00:48:27,652:INFO:Creating metrics dataframe
2024-02-17 00:48:27,657:INFO:Finalizing model
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-02-17 00:48:27,677:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2024-02-17 00:48:27,677:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:48:27,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.
2024-02-17 00:48:27,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 00:48:27,677:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:48:27,677:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:48:27,689:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:48:27,807:INFO:Uploading results into container
2024-02-17 00:48:27,809:INFO:Uploading model into container now
2024-02-17 00:48:27,809:INFO:_master_model_container: 113
2024-02-17 00:48:27,809:INFO:_display_container: 24
2024-02-17 00:48:27,809:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:48:27,809:INFO:create_model() successfully completed......................................
2024-02-17 00:48:27,954:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:27,954:INFO:choose_better activated
2024-02-17 00:48:27,954:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:27,954:INFO:Initializing create_model()
2024-02-17 00:48:27,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:48:27,954:INFO:Checking exceptions
2024-02-17 00:48:27,954:INFO:Importing libraries
2024-02-17 00:48:27,954:INFO:Copying training dataset
2024-02-17 00:48:27,969:INFO:Defining folds
2024-02-17 00:48:27,970:INFO:Declaring metric variables
2024-02-17 00:48:27,970:INFO:Importing untrained model
2024-02-17 00:48:27,970:INFO:Declaring custom model
2024-02-17 00:48:27,970:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 00:48:27,970:INFO:Starting cross validation
2024-02-17 00:48:27,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:29,437:INFO:Calculating mean and std
2024-02-17 00:48:29,437:INFO:Creating metrics dataframe
2024-02-17 00:48:29,437:INFO:Finalizing model
2024-02-17 00:48:29,452:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 00:48:29,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.
2024-02-17 00:48:29,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 00:48:29,469:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 00:48:29,469:INFO:[LightGBM] [Info] Total Bins 1316
2024-02-17 00:48:29,469:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 00:48:29,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 00:48:29,699:INFO:Uploading results into container
2024-02-17 00:48:29,699:INFO:Uploading model into container now
2024-02-17 00:48:29,699:INFO:_master_model_container: 114
2024-02-17 00:48:29,699:INFO:_display_container: 25
2024-02-17 00:48:29,699:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:48:29,699:INFO:create_model() successfully completed......................................
2024-02-17 00:48:29,853:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:29,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9205
2024-02-17 00:48:29,853:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=8, objective=None,
               random_state=3957, reg_alpha=0.15, reg_lambda=0.0001,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2024-02-17 00:48:29,853:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-17 00:48:29,853:INFO:choose_better completed
2024-02-17 00:48:29,853:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:48:29,870:INFO:_master_model_container: 114
2024-02-17 00:48:29,870:INFO:_display_container: 24
2024-02-17 00:48:29,870:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 00:48:29,870:INFO:tune_model() successfully completed......................................
2024-02-17 00:48:30,003:INFO:Initializing tune_model()
2024-02-17 00:48:30,003:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>)
2024-02-17 00:48:30,003:INFO:Checking exceptions
2024-02-17 00:48:30,034:INFO:Copying training dataset
2024-02-17 00:48:30,041:INFO:Checking base model
2024-02-17 00:48:30,041:INFO:Base model : Random Forest Classifier
2024-02-17 00:48:30,048:INFO:Declaring metric variables
2024-02-17 00:48:30,057:INFO:Defining Hyperparameters
2024-02-17 00:48:30,191:INFO:Tuning with n_jobs=-1
2024-02-17 00:48:30,191:INFO:Initializing RandomizedSearchCV
2024-02-17 00:48:42,875:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2024-02-17 00:48:42,877:INFO:Hyperparameter search completed
2024-02-17 00:48:42,877:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:42,877:INFO:Initializing create_model()
2024-02-17 00:48:42,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBE2C0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0005, 'max_features': 'log2', 'max_depth': 5, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2024-02-17 00:48:42,877:INFO:Checking exceptions
2024-02-17 00:48:42,877:INFO:Importing libraries
2024-02-17 00:48:42,877:INFO:Copying training dataset
2024-02-17 00:48:42,890:INFO:Defining folds
2024-02-17 00:48:42,890:INFO:Declaring metric variables
2024-02-17 00:48:42,894:INFO:Importing untrained model
2024-02-17 00:48:42,894:INFO:Declaring custom model
2024-02-17 00:48:42,894:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:48:42,906:INFO:Starting cross validation
2024-02-17 00:48:42,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:44,052:INFO:Calculating mean and std
2024-02-17 00:48:44,052:INFO:Creating metrics dataframe
2024-02-17 00:48:44,062:INFO:Finalizing model
2024-02-17 00:48:44,330:INFO:Uploading results into container
2024-02-17 00:48:44,332:INFO:Uploading model into container now
2024-02-17 00:48:44,332:INFO:_master_model_container: 115
2024-02-17 00:48:44,332:INFO:_display_container: 25
2024-02-17 00:48:44,332:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:48:44,332:INFO:create_model() successfully completed......................................
2024-02-17 00:48:44,438:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:44,438:INFO:choose_better activated
2024-02-17 00:48:44,438:INFO:SubProcess create_model() called ==================================
2024-02-17 00:48:44,438:INFO:Initializing create_model()
2024-02-17 00:48:44,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:48:44,438:INFO:Checking exceptions
2024-02-17 00:48:44,438:INFO:Importing libraries
2024-02-17 00:48:44,438:INFO:Copying training dataset
2024-02-17 00:48:44,454:INFO:Defining folds
2024-02-17 00:48:44,454:INFO:Declaring metric variables
2024-02-17 00:48:44,454:INFO:Importing untrained model
2024-02-17 00:48:44,454:INFO:Declaring custom model
2024-02-17 00:48:44,454:INFO:Random Forest Classifier Imported successfully
2024-02-17 00:48:44,454:INFO:Starting cross validation
2024-02-17 00:48:44,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:48:46,536:INFO:Calculating mean and std
2024-02-17 00:48:46,536:INFO:Creating metrics dataframe
2024-02-17 00:48:46,539:INFO:Finalizing model
2024-02-17 00:48:46,982:INFO:Uploading results into container
2024-02-17 00:48:46,982:INFO:Uploading model into container now
2024-02-17 00:48:46,982:INFO:_master_model_container: 116
2024-02-17 00:48:46,982:INFO:_display_container: 26
2024-02-17 00:48:46,982:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:48:46,982:INFO:create_model() successfully completed......................................
2024-02-17 00:48:47,111:INFO:SubProcess create_model() end ==================================
2024-02-17 00:48:47,111:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.9162
2024-02-17 00:48:47,111:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=5, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) result for Accuracy is 0.8414
2024-02-17 00:48:47,111:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False) is best model
2024-02-17 00:48:47,111:INFO:choose_better completed
2024-02-17 00:48:47,111:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 00:48:47,127:INFO:_master_model_container: 116
2024-02-17 00:48:47,127:INFO:_display_container: 25
2024-02-17 00:48:47,127:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)
2024-02-17 00:48:47,127:INFO:tune_model() successfully completed......................................
2024-02-17 00:51:55,012:INFO:Initializing blend_models()
2024-02-17 00:51:55,012:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x0000028DC19A9780>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3957, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3957, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-17 00:51:55,012:INFO:Checking exceptions
2024-02-17 00:51:55,028:INFO:Importing libraries
2024-02-17 00:51:55,028:INFO:Copying training dataset
2024-02-17 00:51:55,036:INFO:Getting model names
2024-02-17 00:51:55,045:INFO:SubProcess create_model() called ==================================
2024-02-17 00:51:55,050:INFO:Initializing create_model()
2024-02-17 00:51:55,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC19A9780>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC1B23280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:51:55,050:INFO:Checking exceptions
2024-02-17 00:51:55,050:INFO:Importing libraries
2024-02-17 00:51:55,050:INFO:Copying training dataset
2024-02-17 00:51:55,056:INFO:Defining folds
2024-02-17 00:51:55,056:INFO:Declaring metric variables
2024-02-17 00:51:55,060:INFO:Importing untrained model
2024-02-17 00:51:55,060:INFO:Declaring custom model
2024-02-17 00:51:55,095:INFO:Voting Classifier Imported successfully
2024-02-17 00:51:55,101:INFO:Starting cross validation
2024-02-17 00:51:55,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 00:52:13,186:INFO:Calculating mean and std
2024-02-17 00:52:13,186:INFO:Creating metrics dataframe
2024-02-17 00:52:13,194:INFO:Finalizing model
2024-02-17 00:52:16,614:INFO:Uploading results into container
2024-02-17 00:52:16,617:INFO:Uploading model into container now
2024-02-17 00:52:16,617:INFO:_master_model_container: 117
2024-02-17 00:52:16,617:INFO:_display_container: 26
2024-02-17 00:52:16,626:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:52:16,626:INFO:create_model() successfully completed......................................
2024-02-17 00:52:16,758:INFO:SubProcess create_model() end ==================================
2024-02-17 00:52:16,771:INFO:_master_model_container: 117
2024-02-17 00:52:16,771:INFO:_display_container: 26
2024-02-17 00:52:16,771:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:52:16,771:INFO:blend_models() successfully completed......................................
2024-02-17 00:54:08,661:INFO:Initializing finalize_model()
2024-02-17 00:54:08,661:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 00:54:08,664:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 00:54:08,680:INFO:Initializing create_model()
2024-02-17 00:54:08,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 00:54:08,680:INFO:Checking exceptions
2024-02-17 00:54:08,688:INFO:Importing libraries
2024-02-17 00:54:08,688:INFO:Copying training dataset
2024-02-17 00:54:08,688:INFO:Defining folds
2024-02-17 00:54:08,688:INFO:Declaring metric variables
2024-02-17 00:54:08,688:INFO:Importing untrained model
2024-02-17 00:54:08,688:INFO:Declaring custom model
2024-02-17 00:54:08,692:INFO:Voting Classifier Imported successfully
2024-02-17 00:54:08,692:INFO:Cross validation set to False
2024-02-17 00:54:08,692:INFO:Fitting Model
2024-02-17 00:54:13,892:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 00:54:13,892:INFO:create_model() successfully completed......................................
2024-02-17 00:54:14,009:INFO:_master_model_container: 117
2024-02-17 00:54:14,009:INFO:_display_container: 26
2024-02-17 00:54:14,017:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 00:54:14,017:INFO:finalize_model() successfully completed......................................
2024-02-17 00:55:53,692:INFO:Initializing predict_model()
2024-02-17 00:55:53,692:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC1A2BD90>)
2024-02-17 00:55:53,692:INFO:Checking exceptions
2024-02-17 00:55:53,692:INFO:Preloading libraries
2024-02-17 00:55:53,692:INFO:Set up data.
2024-02-17 00:55:53,711:INFO:Set up index.
2024-02-17 00:55:53,850:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\utils\generic.py:586: UserWarning: Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\utils\generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2024-02-17 00:55:53,854:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 00:57:02,377:INFO:Initializing predict_model()
2024-02-17 00:57:02,377:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DBEA79C60>)
2024-02-17 00:57:02,377:INFO:Checking exceptions
2024-02-17 00:57:02,377:INFO:Preloading libraries
2024-02-17 00:57:02,383:INFO:Set up data.
2024-02-17 00:57:02,395:INFO:Set up index.
2024-02-17 00:57:26,151:INFO:Initializing predict_model()
2024-02-17 00:57:26,151:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC19CD900>)
2024-02-17 00:57:26,151:INFO:Checking exceptions
2024-02-17 00:57:26,151:INFO:Preloading libraries
2024-02-17 00:57:26,155:INFO:Set up data.
2024-02-17 00:57:26,163:INFO:Set up index.
2024-02-17 00:59:34,888:INFO:Initializing predict_model()
2024-02-17 00:59:34,889:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC19CEC20>)
2024-02-17 00:59:34,889:INFO:Checking exceptions
2024-02-17 00:59:34,889:INFO:Preloading libraries
2024-02-17 00:59:34,894:INFO:Set up data.
2024-02-17 00:59:34,956:INFO:Set up index.
2024-02-17 01:01:41,419:INFO:Initializing finalize_model()
2024-02-17 01:01:41,419:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:01:41,420:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:01:41,431:INFO:Initializing create_model()
2024-02-17 01:01:41,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:01:41,431:INFO:Checking exceptions
2024-02-17 01:01:41,431:INFO:Importing libraries
2024-02-17 01:01:41,431:INFO:Copying training dataset
2024-02-17 01:01:41,431:INFO:Defining folds
2024-02-17 01:01:41,431:INFO:Declaring metric variables
2024-02-17 01:01:41,431:INFO:Importing untrained model
2024-02-17 01:01:41,431:INFO:Declaring custom model
2024-02-17 01:01:41,431:INFO:Voting Classifier Imported successfully
2024-02-17 01:01:41,439:INFO:Cross validation set to False
2024-02-17 01:01:41,439:INFO:Fitting Model
2024-02-17 01:02:00,266:INFO:Initializing finalize_model()
2024-02-17 01:02:00,266:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:02:00,276:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:02:00,289:INFO:Initializing create_model()
2024-02-17 01:02:00,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:02:00,289:INFO:Checking exceptions
2024-02-17 01:02:00,289:INFO:Importing libraries
2024-02-17 01:02:00,292:INFO:Copying training dataset
2024-02-17 01:02:00,292:INFO:Defining folds
2024-02-17 01:02:00,292:INFO:Declaring metric variables
2024-02-17 01:02:00,292:INFO:Importing untrained model
2024-02-17 01:02:00,292:INFO:Declaring custom model
2024-02-17 01:02:00,292:INFO:Voting Classifier Imported successfully
2024-02-17 01:02:00,292:INFO:Cross validation set to False
2024-02-17 01:02:00,292:INFO:Fitting Model
2024-02-17 01:02:07,183:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:07,183:INFO:create_model() successfully completed......................................
2024-02-17 01:02:07,309:INFO:_master_model_container: 117
2024-02-17 01:02:07,309:INFO:_display_container: 30
2024-02-17 01:02:07,327:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:07,327:INFO:finalize_model() successfully completed......................................
2024-02-17 01:02:07,470:INFO:Initializing predict_model()
2024-02-17 01:02:07,470:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC2380700>)
2024-02-17 01:02:07,470:INFO:Checking exceptions
2024-02-17 01:02:07,470:INFO:Preloading libraries
2024-02-17 01:02:07,484:INFO:Set up data.
2024-02-17 01:02:07,484:INFO:Set up index.
2024-02-17 01:02:19,555:INFO:Initializing finalize_model()
2024-02-17 01:02:19,555:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:02:19,559:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:02:19,570:INFO:Initializing create_model()
2024-02-17 01:02:19,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:02:19,570:INFO:Checking exceptions
2024-02-17 01:02:19,577:INFO:Importing libraries
2024-02-17 01:02:19,577:INFO:Copying training dataset
2024-02-17 01:02:19,577:INFO:Defining folds
2024-02-17 01:02:19,577:INFO:Declaring metric variables
2024-02-17 01:02:19,577:INFO:Importing untrained model
2024-02-17 01:02:19,577:INFO:Declaring custom model
2024-02-17 01:02:19,581:INFO:Voting Classifier Imported successfully
2024-02-17 01:02:19,581:INFO:Cross validation set to False
2024-02-17 01:02:19,581:INFO:Fitting Model
2024-02-17 01:02:25,850:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:25,851:INFO:create_model() successfully completed......................................
2024-02-17 01:02:25,985:INFO:_master_model_container: 117
2024-02-17 01:02:25,985:INFO:_display_container: 31
2024-02-17 01:02:26,002:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:26,002:INFO:finalize_model() successfully completed......................................
2024-02-17 01:02:26,152:INFO:Initializing predict_model()
2024-02-17 01:02:26,152:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC2380940>)
2024-02-17 01:02:26,152:INFO:Checking exceptions
2024-02-17 01:02:26,152:INFO:Preloading libraries
2024-02-17 01:02:26,152:INFO:Set up data.
2024-02-17 01:02:26,152:INFO:Set up index.
2024-02-17 01:02:35,123:INFO:Initializing finalize_model()
2024-02-17 01:02:35,123:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:02:35,128:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:02:35,143:INFO:Initializing create_model()
2024-02-17 01:02:35,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:02:35,145:INFO:Checking exceptions
2024-02-17 01:02:35,145:INFO:Importing libraries
2024-02-17 01:02:35,145:INFO:Copying training dataset
2024-02-17 01:02:35,145:INFO:Defining folds
2024-02-17 01:02:35,145:INFO:Declaring metric variables
2024-02-17 01:02:35,145:INFO:Importing untrained model
2024-02-17 01:02:35,149:INFO:Declaring custom model
2024-02-17 01:02:35,152:INFO:Voting Classifier Imported successfully
2024-02-17 01:02:35,152:INFO:Cross validation set to False
2024-02-17 01:02:35,152:INFO:Fitting Model
2024-02-17 01:02:41,265:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:41,265:INFO:create_model() successfully completed......................................
2024-02-17 01:02:41,402:INFO:_master_model_container: 117
2024-02-17 01:02:41,403:INFO:_display_container: 32
2024-02-17 01:02:41,415:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:02:41,415:INFO:finalize_model() successfully completed......................................
2024-02-17 01:02:41,553:INFO:Initializing predict_model()
2024-02-17 01:02:41,553:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC5395F30>)
2024-02-17 01:02:41,553:INFO:Checking exceptions
2024-02-17 01:02:41,553:INFO:Preloading libraries
2024-02-17 01:02:41,566:INFO:Set up data.
2024-02-17 01:02:41,573:INFO:Set up index.
2024-02-17 01:03:21,624:INFO:Initializing finalize_model()
2024-02-17 01:03:21,624:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:03:21,642:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:03:21,651:INFO:Initializing create_model()
2024-02-17 01:03:21,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:03:21,651:INFO:Checking exceptions
2024-02-17 01:03:21,651:INFO:Importing libraries
2024-02-17 01:03:21,651:INFO:Copying training dataset
2024-02-17 01:03:21,651:INFO:Defining folds
2024-02-17 01:03:21,651:INFO:Declaring metric variables
2024-02-17 01:03:21,651:INFO:Importing untrained model
2024-02-17 01:03:21,651:INFO:Declaring custom model
2024-02-17 01:03:21,655:INFO:Voting Classifier Imported successfully
2024-02-17 01:03:21,655:INFO:Cross validation set to False
2024-02-17 01:03:21,655:INFO:Fitting Model
2024-02-17 01:03:27,840:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:03:27,840:INFO:create_model() successfully completed......................................
2024-02-17 01:03:27,970:INFO:_master_model_container: 117
2024-02-17 01:03:27,970:INFO:_display_container: 33
2024-02-17 01:03:27,989:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:03:27,989:INFO:finalize_model() successfully completed......................................
2024-02-17 01:04:36,220:INFO:Initializing finalize_model()
2024-02-17 01:04:36,220:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:04:36,225:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:04:36,235:INFO:Initializing create_model()
2024-02-17 01:04:36,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000028DC1A0B400>),
                             ('Extreme Gradient Boosting',
                              XGBClassifier(base_score=None, booster='gbtree',
                                            callbacks=None,
                                            colsample_bylevel=None,
                                            colsample_bynode=None,
                                            colsample_bytree=None, device='cpu',
                                            early_stopping_rounds=None,
                                            enable_categorical=False,
                                            eval_metric=None...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=3957,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:04:36,235:INFO:Checking exceptions
2024-02-17 01:04:36,235:INFO:Importing libraries
2024-02-17 01:04:36,235:INFO:Copying training dataset
2024-02-17 01:04:36,235:INFO:Defining folds
2024-02-17 01:04:36,235:INFO:Declaring metric variables
2024-02-17 01:04:36,235:INFO:Importing untrained model
2024-02-17 01:04:36,235:INFO:Declaring custom model
2024-02-17 01:04:36,235:INFO:Voting Classifier Imported successfully
2024-02-17 01:04:36,235:INFO:Cross validation set to False
2024-02-17 01:04:36,235:INFO:Fitting Model
2024-02-17 01:04:42,322:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:04:42,322:INFO:create_model() successfully completed......................................
2024-02-17 01:04:42,457:INFO:_master_model_container: 117
2024-02-17 01:04:42,457:INFO:_display_container: 33
2024-02-17 01:04:42,473:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:04:42,473:INFO:finalize_model() successfully completed......................................
2024-02-17 01:04:42,608:INFO:Initializing predict_model()
2024-02-17 01:04:42,608:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DBEB03DC0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=3957,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028DC19CE5F0>)
2024-02-17 01:04:42,608:INFO:Checking exceptions
2024-02-17 01:04:42,608:INFO:Preloading libraries
2024-02-17 01:04:42,624:INFO:Set up data.
2024-02-17 01:04:42,628:INFO:Set up index.
2024-02-17 01:07:34,766:INFO:PyCaret ClassificationExperiment
2024-02-17 01:07:34,766:INFO:Logging name: clf-default-name
2024-02-17 01:07:34,766:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-02-17 01:07:34,766:INFO:version 3.2.0
2024-02-17 01:07:34,766:INFO:Initializing setup()
2024-02-17 01:07:34,766:INFO:self.USI: ba2b
2024-02-17 01:07:34,766:INFO:self._variable_keys: {'y_test', 'fold_groups_param', 'X', 'pipeline', 'logging_param', 'idx', 'exp_id', 'gpu_n_jobs_param', 'fold_shuffle_param', 'n_jobs_param', 'gpu_param', 'memory', 'y', 'seed', 'X_test', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'data', 'X_train', 'target_param', 'html_param', 'y_train', 'fix_imbalance', 'fold_generator', '_available_plots', '_ml_usecase', 'USI'}
2024-02-17 01:07:34,766:INFO:Checking environment
2024-02-17 01:07:34,766:INFO:python_version: 3.10.2
2024-02-17 01:07:34,766:INFO:python_build: ('tags/v3.10.2:a58ebcc', 'Jan 17 2022 14:12:15')
2024-02-17 01:07:34,766:INFO:machine: AMD64
2024-02-17 01:07:34,766:INFO:platform: Windows-10-10.0.22621-SP0
2024-02-17 01:07:34,773:INFO:Memory: svmem(total=8247582720, available=1075519488, percent=87.0, used=7172063232, free=1075519488)
2024-02-17 01:07:34,773:INFO:Physical Core: 4
2024-02-17 01:07:34,774:INFO:Logical Core: 8
2024-02-17 01:07:34,774:INFO:Checking libraries
2024-02-17 01:07:34,775:INFO:System:
2024-02-17 01:07:34,775:INFO:    python: 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
2024-02-17 01:07:34,775:INFO:executable: c:\Users\happy\AppData\Local\Programs\Python\Python310\python.exe
2024-02-17 01:07:34,775:INFO:   machine: Windows-10-10.0.22621-SP0
2024-02-17 01:07:34,775:INFO:PyCaret required dependencies:
2024-02-17 01:07:34,775:INFO:                 pip: 24.0
2024-02-17 01:07:34,775:INFO:          setuptools: 58.1.0
2024-02-17 01:07:34,775:INFO:             pycaret: 3.2.0
2024-02-17 01:07:34,775:INFO:             IPython: 8.16.1
2024-02-17 01:07:34,775:INFO:          ipywidgets: 8.1.1
2024-02-17 01:07:34,775:INFO:                tqdm: 4.66.1
2024-02-17 01:07:34,775:INFO:               numpy: 1.25.2
2024-02-17 01:07:34,775:INFO:              pandas: 1.5.3
2024-02-17 01:07:34,775:INFO:              jinja2: 3.1.3
2024-02-17 01:07:34,775:INFO:               scipy: 1.10.1
2024-02-17 01:07:34,775:INFO:              joblib: 1.3.2
2024-02-17 01:07:34,775:INFO:             sklearn: 1.2.2
2024-02-17 01:07:34,775:INFO:                pyod: 1.1.2
2024-02-17 01:07:34,775:INFO:            imblearn: 0.12.0
2024-02-17 01:07:34,775:INFO:   category_encoders: 2.6.3
2024-02-17 01:07:34,775:INFO:            lightgbm: 4.3.0
2024-02-17 01:07:34,775:INFO:               numba: 0.59.0
2024-02-17 01:07:34,775:INFO:            requests: 2.31.0
2024-02-17 01:07:34,775:INFO:          matplotlib: 3.6.0
2024-02-17 01:07:34,775:INFO:          scikitplot: 0.3.7
2024-02-17 01:07:34,775:INFO:         yellowbrick: 1.5
2024-02-17 01:07:34,775:INFO:              plotly: 5.18.0
2024-02-17 01:07:34,775:INFO:    plotly-resampler: Not installed
2024-02-17 01:07:34,775:INFO:             kaleido: 0.2.1
2024-02-17 01:07:34,775:INFO:           schemdraw: 0.15
2024-02-17 01:07:34,775:INFO:         statsmodels: 0.14.1
2024-02-17 01:07:34,775:INFO:              sktime: 0.21.1
2024-02-17 01:07:34,775:INFO:               tbats: 1.1.3
2024-02-17 01:07:34,775:INFO:            pmdarima: 2.0.4
2024-02-17 01:07:34,775:INFO:              psutil: 5.9.6
2024-02-17 01:07:34,775:INFO:          markupsafe: 2.1.4
2024-02-17 01:07:34,775:INFO:             pickle5: Not installed
2024-02-17 01:07:34,775:INFO:         cloudpickle: 3.0.0
2024-02-17 01:07:34,775:INFO:         deprecation: 2.1.0
2024-02-17 01:07:34,775:INFO:              xxhash: 3.4.1
2024-02-17 01:07:34,775:INFO:           wurlitzer: Not installed
2024-02-17 01:07:34,775:INFO:PyCaret optional dependencies:
2024-02-17 01:07:34,775:INFO:                shap: Not installed
2024-02-17 01:07:34,775:INFO:           interpret: Not installed
2024-02-17 01:07:34,775:INFO:                umap: Not installed
2024-02-17 01:07:34,775:INFO:     ydata_profiling: Not installed
2024-02-17 01:07:34,775:INFO:  explainerdashboard: Not installed
2024-02-17 01:07:34,775:INFO:             autoviz: Not installed
2024-02-17 01:07:34,775:INFO:           fairlearn: Not installed
2024-02-17 01:07:34,775:INFO:          deepchecks: Not installed
2024-02-17 01:07:34,775:INFO:             xgboost: 2.0.3
2024-02-17 01:07:34,775:INFO:            catboost: 1.2.2
2024-02-17 01:07:34,775:INFO:              kmodes: Not installed
2024-02-17 01:07:34,775:INFO:             mlxtend: 0.23.1
2024-02-17 01:07:34,775:INFO:       statsforecast: Not installed
2024-02-17 01:07:34,775:INFO:        tune_sklearn: Not installed
2024-02-17 01:07:34,775:INFO:                 ray: Not installed
2024-02-17 01:07:34,775:INFO:            hyperopt: Not installed
2024-02-17 01:07:34,775:INFO:              optuna: Not installed
2024-02-17 01:07:34,775:INFO:               skopt: Not installed
2024-02-17 01:07:34,775:INFO:              mlflow: Not installed
2024-02-17 01:07:34,775:INFO:              gradio: Not installed
2024-02-17 01:07:34,775:INFO:             fastapi: Not installed
2024-02-17 01:07:34,775:INFO:             uvicorn: Not installed
2024-02-17 01:07:34,775:INFO:              m2cgen: Not installed
2024-02-17 01:07:34,775:INFO:           evidently: Not installed
2024-02-17 01:07:34,775:INFO:               fugue: Not installed
2024-02-17 01:07:34,775:INFO:           streamlit: Not installed
2024-02-17 01:07:34,775:INFO:             prophet: Not installed
2024-02-17 01:07:34,775:INFO:None
2024-02-17 01:07:34,775:INFO:Set up data.
2024-02-17 01:07:34,789:INFO:Set up folding strategy.
2024-02-17 01:07:34,789:INFO:Set up train/test split.
2024-02-17 01:07:34,799:INFO:Set up index.
2024-02-17 01:07:34,799:INFO:Assigning column types.
2024-02-17 01:07:34,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-02-17 01:07:34,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-17 01:07:34,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-17 01:07:34,864:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:34,864:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:34,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-02-17 01:07:34,909:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-17 01:07:34,927:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:34,937:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:34,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-02-17 01:07:34,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-17 01:07:34,996:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,009:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-02-17 01:07:35,077:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,077:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,077:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-02-17 01:07:35,149:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,149:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,224:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,226:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,229:INFO:Preparing preprocessing pipeline...
2024-02-17 01:07:35,229:INFO:Set up simple imputation.
2024-02-17 01:07:35,244:INFO:Finished creating preprocessing pipeline.
2024-02-17 01:07:35,244:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\happy\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_cat...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-02-17 01:07:35,244:INFO:Creating final display dataframe.
2024-02-17 01:07:35,327:INFO:Setup _display_container:                     Description             Value
0                    Session id               255
1                        Target      is_converted
2                   Target type            Binary
3           Original data shape        (9700, 20)
4        Transformed data shape        (9700, 20)
5   Transformed train set shape        (6790, 20)
6    Transformed test set shape        (2910, 20)
7               Ignore features                 1
8              Numeric features                19
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              ba2b
2024-02-17 01:07:35,395:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,395:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,473:INFO:Soft dependency imported: xgboost: 2.0.3
2024-02-17 01:07:35,473:INFO:Soft dependency imported: catboost: 1.2.2
2024-02-17 01:07:35,473:INFO:setup() successfully completed in 0.71s...............
2024-02-17 01:07:37,719:INFO:Initializing compare_models()
2024-02-17 01:07:37,719:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 01:07:37,719:INFO:Checking exceptions
2024-02-17 01:07:37,730:INFO:Preparing display monitor
2024-02-17 01:07:37,789:INFO:Initializing Logistic Regression
2024-02-17 01:07:37,789:INFO:Total runtime is 0.0 minutes
2024-02-17 01:07:37,794:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:37,794:INFO:Initializing create_model()
2024-02-17 01:07:37,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:37,794:INFO:Checking exceptions
2024-02-17 01:07:37,794:INFO:Importing libraries
2024-02-17 01:07:37,794:INFO:Copying training dataset
2024-02-17 01:07:37,805:INFO:Defining folds
2024-02-17 01:07:37,805:INFO:Declaring metric variables
2024-02-17 01:07:37,808:INFO:Importing untrained model
2024-02-17 01:07:37,808:INFO:Logistic Regression Imported successfully
2024-02-17 01:07:37,816:INFO:Starting cross validation
2024-02-17 01:07:37,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:39,869:INFO:Calculating mean and std
2024-02-17 01:07:39,869:INFO:Creating metrics dataframe
2024-02-17 01:07:39,869:INFO:Uploading results into container
2024-02-17 01:07:39,869:INFO:Uploading model into container now
2024-02-17 01:07:39,869:INFO:_master_model_container: 1
2024-02-17 01:07:39,875:INFO:_display_container: 2
2024-02-17 01:07:39,875:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=255, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 01:07:39,877:INFO:create_model() successfully completed......................................
2024-02-17 01:07:40,075:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:40,075:INFO:Creating metrics dataframe
2024-02-17 01:07:40,083:INFO:Initializing K Neighbors Classifier
2024-02-17 01:07:40,083:INFO:Total runtime is 0.03823810418446859 minutes
2024-02-17 01:07:40,091:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:40,092:INFO:Initializing create_model()
2024-02-17 01:07:40,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:40,092:INFO:Checking exceptions
2024-02-17 01:07:40,092:INFO:Importing libraries
2024-02-17 01:07:40,094:INFO:Copying training dataset
2024-02-17 01:07:40,097:INFO:Defining folds
2024-02-17 01:07:40,097:INFO:Declaring metric variables
2024-02-17 01:07:40,097:INFO:Importing untrained model
2024-02-17 01:07:40,108:INFO:K Neighbors Classifier Imported successfully
2024-02-17 01:07:40,111:INFO:Starting cross validation
2024-02-17 01:07:40,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:40,440:INFO:Calculating mean and std
2024-02-17 01:07:40,441:INFO:Creating metrics dataframe
2024-02-17 01:07:40,444:INFO:Uploading results into container
2024-02-17 01:07:40,444:INFO:Uploading model into container now
2024-02-17 01:07:40,444:INFO:_master_model_container: 2
2024-02-17 01:07:40,444:INFO:_display_container: 2
2024-02-17 01:07:40,444:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 01:07:40,444:INFO:create_model() successfully completed......................................
2024-02-17 01:07:40,593:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:40,593:INFO:Creating metrics dataframe
2024-02-17 01:07:40,599:INFO:Initializing Naive Bayes
2024-02-17 01:07:40,599:INFO:Total runtime is 0.04684245586395264 minutes
2024-02-17 01:07:40,610:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:40,611:INFO:Initializing create_model()
2024-02-17 01:07:40,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:40,611:INFO:Checking exceptions
2024-02-17 01:07:40,611:INFO:Importing libraries
2024-02-17 01:07:40,611:INFO:Copying training dataset
2024-02-17 01:07:40,611:INFO:Defining folds
2024-02-17 01:07:40,611:INFO:Declaring metric variables
2024-02-17 01:07:40,611:INFO:Importing untrained model
2024-02-17 01:07:40,624:INFO:Naive Bayes Imported successfully
2024-02-17 01:07:40,628:INFO:Starting cross validation
2024-02-17 01:07:40,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:40,728:INFO:Calculating mean and std
2024-02-17 01:07:40,730:INFO:Creating metrics dataframe
2024-02-17 01:07:40,730:INFO:Uploading results into container
2024-02-17 01:07:40,730:INFO:Uploading model into container now
2024-02-17 01:07:40,730:INFO:_master_model_container: 3
2024-02-17 01:07:40,730:INFO:_display_container: 2
2024-02-17 01:07:40,730:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 01:07:40,730:INFO:create_model() successfully completed......................................
2024-02-17 01:07:40,862:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:40,862:INFO:Creating metrics dataframe
2024-02-17 01:07:40,876:INFO:Initializing Decision Tree Classifier
2024-02-17 01:07:40,876:INFO:Total runtime is 0.05145585139592489 minutes
2024-02-17 01:07:40,876:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:40,876:INFO:Initializing create_model()
2024-02-17 01:07:40,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:40,876:INFO:Checking exceptions
2024-02-17 01:07:40,876:INFO:Importing libraries
2024-02-17 01:07:40,876:INFO:Copying training dataset
2024-02-17 01:07:40,884:INFO:Defining folds
2024-02-17 01:07:40,884:INFO:Declaring metric variables
2024-02-17 01:07:40,884:INFO:Importing untrained model
2024-02-17 01:07:40,898:INFO:Decision Tree Classifier Imported successfully
2024-02-17 01:07:40,898:INFO:Starting cross validation
2024-02-17 01:07:40,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:41,067:INFO:Calculating mean and std
2024-02-17 01:07:41,067:INFO:Creating metrics dataframe
2024-02-17 01:07:41,067:INFO:Uploading results into container
2024-02-17 01:07:41,067:INFO:Uploading model into container now
2024-02-17 01:07:41,067:INFO:_master_model_container: 4
2024-02-17 01:07:41,067:INFO:_display_container: 2
2024-02-17 01:07:41,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=255, splitter='best')
2024-02-17 01:07:41,067:INFO:create_model() successfully completed......................................
2024-02-17 01:07:41,232:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:41,232:INFO:Creating metrics dataframe
2024-02-17 01:07:41,241:INFO:Initializing SVM - Linear Kernel
2024-02-17 01:07:41,242:INFO:Total runtime is 0.05756041208902995 minutes
2024-02-17 01:07:41,246:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:41,246:INFO:Initializing create_model()
2024-02-17 01:07:41,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:41,246:INFO:Checking exceptions
2024-02-17 01:07:41,246:INFO:Importing libraries
2024-02-17 01:07:41,246:INFO:Copying training dataset
2024-02-17 01:07:41,246:INFO:Defining folds
2024-02-17 01:07:41,246:INFO:Declaring metric variables
2024-02-17 01:07:41,246:INFO:Importing untrained model
2024-02-17 01:07:41,262:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 01:07:41,262:INFO:Starting cross validation
2024-02-17 01:07:41,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:41,404:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,425:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 01:07:41,442:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,452:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 01:07:41,452:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,459:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,459:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,484:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 01:07:41,542:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-02-17 01:07:41,560:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,587:INFO:Calculating mean and std
2024-02-17 01:07:41,587:INFO:Creating metrics dataframe
2024-02-17 01:07:41,595:INFO:Uploading results into container
2024-02-17 01:07:41,595:INFO:Uploading model into container now
2024-02-17 01:07:41,595:INFO:_master_model_container: 5
2024-02-17 01:07:41,595:INFO:_display_container: 2
2024-02-17 01:07:41,595:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=255, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 01:07:41,595:INFO:create_model() successfully completed......................................
2024-02-17 01:07:41,725:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:41,725:INFO:Creating metrics dataframe
2024-02-17 01:07:41,745:INFO:Initializing Ridge Classifier
2024-02-17 01:07:41,745:INFO:Total runtime is 0.06593417723973592 minutes
2024-02-17 01:07:41,745:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:41,745:INFO:Initializing create_model()
2024-02-17 01:07:41,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:41,745:INFO:Checking exceptions
2024-02-17 01:07:41,745:INFO:Importing libraries
2024-02-17 01:07:41,745:INFO:Copying training dataset
2024-02-17 01:07:41,745:INFO:Defining folds
2024-02-17 01:07:41,745:INFO:Declaring metric variables
2024-02-17 01:07:41,763:INFO:Importing untrained model
2024-02-17 01:07:41,763:INFO:Ridge Classifier Imported successfully
2024-02-17 01:07:41,774:INFO:Starting cross validation
2024-02-17 01:07:41,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:41,809:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,809:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 01:07:41,825:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,825:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,835:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 01:07:41,835:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 01:07:41,835:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,843:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,850:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-02-17 01:07:41,859:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:07:41,873:INFO:Calculating mean and std
2024-02-17 01:07:41,875:INFO:Creating metrics dataframe
2024-02-17 01:07:41,879:INFO:Uploading results into container
2024-02-17 01:07:41,880:INFO:Uploading model into container now
2024-02-17 01:07:41,880:INFO:_master_model_container: 6
2024-02-17 01:07:41,880:INFO:_display_container: 2
2024-02-17 01:07:41,880:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=255, solver='auto',
                tol=0.0001)
2024-02-17 01:07:41,880:INFO:create_model() successfully completed......................................
2024-02-17 01:07:42,012:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:42,012:INFO:Creating metrics dataframe
2024-02-17 01:07:42,021:INFO:Initializing Random Forest Classifier
2024-02-17 01:07:42,023:INFO:Total runtime is 0.07057271401087443 minutes
2024-02-17 01:07:42,026:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:42,026:INFO:Initializing create_model()
2024-02-17 01:07:42,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:42,026:INFO:Checking exceptions
2024-02-17 01:07:42,026:INFO:Importing libraries
2024-02-17 01:07:42,026:INFO:Copying training dataset
2024-02-17 01:07:42,026:INFO:Defining folds
2024-02-17 01:07:42,026:INFO:Declaring metric variables
2024-02-17 01:07:42,037:INFO:Importing untrained model
2024-02-17 01:07:42,043:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:07:42,045:INFO:Starting cross validation
2024-02-17 01:07:42,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:44,438:INFO:Calculating mean and std
2024-02-17 01:07:44,438:INFO:Creating metrics dataframe
2024-02-17 01:07:44,442:INFO:Uploading results into container
2024-02-17 01:07:44,442:INFO:Uploading model into container now
2024-02-17 01:07:44,442:INFO:_master_model_container: 7
2024-02-17 01:07:44,442:INFO:_display_container: 2
2024-02-17 01:07:44,442:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:07:44,442:INFO:create_model() successfully completed......................................
2024-02-17 01:07:44,603:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:44,603:INFO:Creating metrics dataframe
2024-02-17 01:07:44,626:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 01:07:44,626:INFO:Total runtime is 0.11396320660909018 minutes
2024-02-17 01:07:44,630:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:44,630:INFO:Initializing create_model()
2024-02-17 01:07:44,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:44,630:INFO:Checking exceptions
2024-02-17 01:07:44,630:INFO:Importing libraries
2024-02-17 01:07:44,630:INFO:Copying training dataset
2024-02-17 01:07:44,642:INFO:Defining folds
2024-02-17 01:07:44,642:INFO:Declaring metric variables
2024-02-17 01:07:44,645:INFO:Importing untrained model
2024-02-17 01:07:44,645:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 01:07:44,662:INFO:Starting cross validation
2024-02-17 01:07:44,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:44,820:INFO:Calculating mean and std
2024-02-17 01:07:44,820:INFO:Creating metrics dataframe
2024-02-17 01:07:44,820:INFO:Uploading results into container
2024-02-17 01:07:44,820:INFO:Uploading model into container now
2024-02-17 01:07:44,820:INFO:_master_model_container: 8
2024-02-17 01:07:44,820:INFO:_display_container: 2
2024-02-17 01:07:44,820:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 01:07:44,820:INFO:create_model() successfully completed......................................
2024-02-17 01:07:44,977:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:44,978:INFO:Creating metrics dataframe
2024-02-17 01:07:44,993:INFO:Initializing Ada Boost Classifier
2024-02-17 01:07:44,993:INFO:Total runtime is 0.12007012764612834 minutes
2024-02-17 01:07:45,003:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:45,003:INFO:Initializing create_model()
2024-02-17 01:07:45,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:45,003:INFO:Checking exceptions
2024-02-17 01:07:45,003:INFO:Importing libraries
2024-02-17 01:07:45,003:INFO:Copying training dataset
2024-02-17 01:07:45,012:INFO:Defining folds
2024-02-17 01:07:45,012:INFO:Declaring metric variables
2024-02-17 01:07:45,012:INFO:Importing untrained model
2024-02-17 01:07:45,025:INFO:Ada Boost Classifier Imported successfully
2024-02-17 01:07:45,031:INFO:Starting cross validation
2024-02-17 01:07:45,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:46,291:INFO:Calculating mean and std
2024-02-17 01:07:46,292:INFO:Creating metrics dataframe
2024-02-17 01:07:46,292:INFO:Uploading results into container
2024-02-17 01:07:46,292:INFO:Uploading model into container now
2024-02-17 01:07:46,292:INFO:_master_model_container: 9
2024-02-17 01:07:46,292:INFO:_display_container: 2
2024-02-17 01:07:46,292:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=255)
2024-02-17 01:07:46,292:INFO:create_model() successfully completed......................................
2024-02-17 01:07:46,442:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:46,442:INFO:Creating metrics dataframe
2024-02-17 01:07:46,462:INFO:Initializing Gradient Boosting Classifier
2024-02-17 01:07:46,462:INFO:Total runtime is 0.14456350803375245 minutes
2024-02-17 01:07:46,462:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:46,462:INFO:Initializing create_model()
2024-02-17 01:07:46,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:46,462:INFO:Checking exceptions
2024-02-17 01:07:46,462:INFO:Importing libraries
2024-02-17 01:07:46,462:INFO:Copying training dataset
2024-02-17 01:07:46,479:INFO:Defining folds
2024-02-17 01:07:46,479:INFO:Declaring metric variables
2024-02-17 01:07:46,479:INFO:Importing untrained model
2024-02-17 01:07:46,492:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 01:07:46,543:INFO:Starting cross validation
2024-02-17 01:07:46,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:49,085:INFO:Calculating mean and std
2024-02-17 01:07:49,085:INFO:Creating metrics dataframe
2024-02-17 01:07:49,085:INFO:Uploading results into container
2024-02-17 01:07:49,085:INFO:Uploading model into container now
2024-02-17 01:07:49,085:INFO:_master_model_container: 10
2024-02-17 01:07:49,085:INFO:_display_container: 2
2024-02-17 01:07:49,085:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=255, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 01:07:49,085:INFO:create_model() successfully completed......................................
2024-02-17 01:07:49,221:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:49,221:INFO:Creating metrics dataframe
2024-02-17 01:07:49,229:INFO:Initializing Linear Discriminant Analysis
2024-02-17 01:07:49,229:INFO:Total runtime is 0.1906672477722168 minutes
2024-02-17 01:07:49,237:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:49,237:INFO:Initializing create_model()
2024-02-17 01:07:49,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:49,237:INFO:Checking exceptions
2024-02-17 01:07:49,237:INFO:Importing libraries
2024-02-17 01:07:49,237:INFO:Copying training dataset
2024-02-17 01:07:49,245:INFO:Defining folds
2024-02-17 01:07:49,245:INFO:Declaring metric variables
2024-02-17 01:07:49,245:INFO:Importing untrained model
2024-02-17 01:07:49,245:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 01:07:49,261:INFO:Starting cross validation
2024-02-17 01:07:49,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:49,376:INFO:Calculating mean and std
2024-02-17 01:07:49,376:INFO:Creating metrics dataframe
2024-02-17 01:07:49,376:INFO:Uploading results into container
2024-02-17 01:07:49,376:INFO:Uploading model into container now
2024-02-17 01:07:49,376:INFO:_master_model_container: 11
2024-02-17 01:07:49,376:INFO:_display_container: 2
2024-02-17 01:07:49,376:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 01:07:49,376:INFO:create_model() successfully completed......................................
2024-02-17 01:07:49,511:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:49,511:INFO:Creating metrics dataframe
2024-02-17 01:07:49,531:INFO:Initializing Extra Trees Classifier
2024-02-17 01:07:49,531:INFO:Total runtime is 0.1957001248995463 minutes
2024-02-17 01:07:49,533:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:49,533:INFO:Initializing create_model()
2024-02-17 01:07:49,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:49,533:INFO:Checking exceptions
2024-02-17 01:07:49,533:INFO:Importing libraries
2024-02-17 01:07:49,533:INFO:Copying training dataset
2024-02-17 01:07:49,533:INFO:Defining folds
2024-02-17 01:07:49,533:INFO:Declaring metric variables
2024-02-17 01:07:49,546:INFO:Importing untrained model
2024-02-17 01:07:49,546:INFO:Extra Trees Classifier Imported successfully
2024-02-17 01:07:49,546:INFO:Starting cross validation
2024-02-17 01:07:49,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:51,054:INFO:Calculating mean and std
2024-02-17 01:07:51,054:INFO:Creating metrics dataframe
2024-02-17 01:07:51,054:INFO:Uploading results into container
2024-02-17 01:07:51,054:INFO:Uploading model into container now
2024-02-17 01:07:51,060:INFO:_master_model_container: 12
2024-02-17 01:07:51,060:INFO:_display_container: 2
2024-02-17 01:07:51,060:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=255, verbose=0, warm_start=False)
2024-02-17 01:07:51,061:INFO:create_model() successfully completed......................................
2024-02-17 01:07:51,193:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:51,193:INFO:Creating metrics dataframe
2024-02-17 01:07:51,209:INFO:Initializing Extreme Gradient Boosting
2024-02-17 01:07:51,210:INFO:Total runtime is 0.22368119955062865 minutes
2024-02-17 01:07:51,214:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:51,214:INFO:Initializing create_model()
2024-02-17 01:07:51,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:51,214:INFO:Checking exceptions
2024-02-17 01:07:51,214:INFO:Importing libraries
2024-02-17 01:07:51,214:INFO:Copying training dataset
2024-02-17 01:07:51,221:INFO:Defining folds
2024-02-17 01:07:51,222:INFO:Declaring metric variables
2024-02-17 01:07:51,227:INFO:Importing untrained model
2024-02-17 01:07:51,229:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:07:51,239:INFO:Starting cross validation
2024-02-17 01:07:51,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:51,789:INFO:Calculating mean and std
2024-02-17 01:07:51,789:INFO:Creating metrics dataframe
2024-02-17 01:07:51,797:INFO:Uploading results into container
2024-02-17 01:07:51,797:INFO:Uploading model into container now
2024-02-17 01:07:51,798:INFO:_master_model_container: 13
2024-02-17 01:07:51,798:INFO:_display_container: 2
2024-02-17 01:07:51,798:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:07:51,798:INFO:create_model() successfully completed......................................
2024-02-17 01:07:51,926:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:51,926:INFO:Creating metrics dataframe
2024-02-17 01:07:51,926:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 01:07:51,940:INFO:Total runtime is 0.23586283524831134 minutes
2024-02-17 01:07:51,944:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:51,944:INFO:Initializing create_model()
2024-02-17 01:07:51,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:51,944:INFO:Checking exceptions
2024-02-17 01:07:51,944:INFO:Importing libraries
2024-02-17 01:07:51,944:INFO:Copying training dataset
2024-02-17 01:07:51,956:INFO:Defining folds
2024-02-17 01:07:51,956:INFO:Declaring metric variables
2024-02-17 01:07:51,962:INFO:Importing untrained model
2024-02-17 01:07:51,967:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:07:51,973:INFO:Starting cross validation
2024-02-17 01:07:51,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:07:53,304:INFO:Calculating mean and std
2024-02-17 01:07:53,304:INFO:Creating metrics dataframe
2024-02-17 01:07:53,313:INFO:Uploading results into container
2024-02-17 01:07:53,313:INFO:Uploading model into container now
2024-02-17 01:07:53,313:INFO:_master_model_container: 14
2024-02-17 01:07:53,313:INFO:_display_container: 2
2024-02-17 01:07:53,313:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:07:53,313:INFO:create_model() successfully completed......................................
2024-02-17 01:07:53,460:INFO:SubProcess create_model() end ==================================
2024-02-17 01:07:53,460:INFO:Creating metrics dataframe
2024-02-17 01:07:53,460:INFO:Initializing CatBoost Classifier
2024-02-17 01:07:53,472:INFO:Total runtime is 0.2611824075380961 minutes
2024-02-17 01:07:53,476:INFO:SubProcess create_model() called ==================================
2024-02-17 01:07:53,476:INFO:Initializing create_model()
2024-02-17 01:07:53,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:07:53,476:INFO:Checking exceptions
2024-02-17 01:07:53,476:INFO:Importing libraries
2024-02-17 01:07:53,476:INFO:Copying training dataset
2024-02-17 01:07:53,476:INFO:Defining folds
2024-02-17 01:07:53,476:INFO:Declaring metric variables
2024-02-17 01:07:53,476:INFO:Importing untrained model
2024-02-17 01:07:53,491:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:07:53,498:INFO:Starting cross validation
2024-02-17 01:07:53,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:12,210:INFO:Calculating mean and std
2024-02-17 01:08:12,211:INFO:Creating metrics dataframe
2024-02-17 01:08:12,211:INFO:Uploading results into container
2024-02-17 01:08:12,211:INFO:Uploading model into container now
2024-02-17 01:08:12,211:INFO:_master_model_container: 15
2024-02-17 01:08:12,211:INFO:_display_container: 2
2024-02-17 01:08:12,211:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBF697670>
2024-02-17 01:08:12,211:INFO:create_model() successfully completed......................................
2024-02-17 01:08:12,394:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:12,394:INFO:Creating metrics dataframe
2024-02-17 01:08:12,398:INFO:Initializing Dummy Classifier
2024-02-17 01:08:12,398:INFO:Total runtime is 0.5768260359764099 minutes
2024-02-17 01:08:12,412:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:12,412:INFO:Initializing create_model()
2024-02-17 01:08:12,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EC47EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:12,412:INFO:Checking exceptions
2024-02-17 01:08:12,412:INFO:Importing libraries
2024-02-17 01:08:12,412:INFO:Copying training dataset
2024-02-17 01:08:12,412:INFO:Defining folds
2024-02-17 01:08:12,412:INFO:Declaring metric variables
2024-02-17 01:08:12,430:INFO:Importing untrained model
2024-02-17 01:08:12,430:INFO:Dummy Classifier Imported successfully
2024-02-17 01:08:12,445:INFO:Starting cross validation
2024-02-17 01:08:12,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:12,511:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:08:12,511:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:08:12,518:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:08:12,518:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:08:12,528:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:08:12,573:INFO:Calculating mean and std
2024-02-17 01:08:12,573:INFO:Creating metrics dataframe
2024-02-17 01:08:12,582:INFO:Uploading results into container
2024-02-17 01:08:12,582:INFO:Uploading model into container now
2024-02-17 01:08:12,582:INFO:_master_model_container: 16
2024-02-17 01:08:12,582:INFO:_display_container: 2
2024-02-17 01:08:12,582:INFO:DummyClassifier(constant=None, random_state=255, strategy='prior')
2024-02-17 01:08:12,582:INFO:create_model() successfully completed......................................
2024-02-17 01:08:12,744:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:12,744:INFO:Creating metrics dataframe
2024-02-17 01:08:12,772:INFO:Initializing create_model()
2024-02-17 01:08:12,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:12,772:INFO:Checking exceptions
2024-02-17 01:08:12,772:INFO:Importing libraries
2024-02-17 01:08:12,772:INFO:Copying training dataset
2024-02-17 01:08:12,780:INFO:Defining folds
2024-02-17 01:08:12,780:INFO:Declaring metric variables
2024-02-17 01:08:12,780:INFO:Importing untrained model
2024-02-17 01:08:12,780:INFO:Declaring custom model
2024-02-17 01:08:12,780:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:08:12,780:INFO:Cross validation set to False
2024-02-17 01:08:12,780:INFO:Fitting Model
2024-02-17 01:08:12,804:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 01:08:12,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.
2024-02-17 01:08:12,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 01:08:12,804:INFO:[LightGBM] [Info] Total Bins 1328
2024-02-17 01:08:12,804:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 01:08:12,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 01:08:12,896:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:08:12,896:INFO:create_model() successfully completed......................................
2024-02-17 01:08:13,050:INFO:Initializing create_model()
2024-02-17 01:08:13,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:13,050:INFO:Checking exceptions
2024-02-17 01:08:13,052:INFO:Importing libraries
2024-02-17 01:08:13,052:INFO:Copying training dataset
2024-02-17 01:08:13,052:INFO:Defining folds
2024-02-17 01:08:13,052:INFO:Declaring metric variables
2024-02-17 01:08:13,052:INFO:Importing untrained model
2024-02-17 01:08:13,052:INFO:Declaring custom model
2024-02-17 01:08:13,052:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:08:13,061:INFO:Cross validation set to False
2024-02-17 01:08:13,062:INFO:Fitting Model
2024-02-17 01:08:13,259:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:08:13,259:INFO:create_model() successfully completed......................................
2024-02-17 01:08:13,419:INFO:Initializing create_model()
2024-02-17 01:08:13,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DBF697670>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:13,429:INFO:Checking exceptions
2024-02-17 01:08:13,434:INFO:Importing libraries
2024-02-17 01:08:13,434:INFO:Copying training dataset
2024-02-17 01:08:13,449:INFO:Defining folds
2024-02-17 01:08:13,449:INFO:Declaring metric variables
2024-02-17 01:08:13,449:INFO:Importing untrained model
2024-02-17 01:08:13,449:INFO:Declaring custom model
2024-02-17 01:08:13,449:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:08:13,452:INFO:Cross validation set to False
2024-02-17 01:08:13,452:INFO:Fitting Model
2024-02-17 01:08:17,362:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DBF6973A0>
2024-02-17 01:08:17,362:INFO:create_model() successfully completed......................................
2024-02-17 01:08:17,542:INFO:Initializing create_model()
2024-02-17 01:08:17,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:17,542:INFO:Checking exceptions
2024-02-17 01:08:17,546:INFO:Importing libraries
2024-02-17 01:08:17,548:INFO:Copying training dataset
2024-02-17 01:08:17,548:INFO:Defining folds
2024-02-17 01:08:17,548:INFO:Declaring metric variables
2024-02-17 01:08:17,548:INFO:Importing untrained model
2024-02-17 01:08:17,548:INFO:Declaring custom model
2024-02-17 01:08:17,548:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:08:17,548:INFO:Cross validation set to False
2024-02-17 01:08:17,548:INFO:Fitting Model
2024-02-17 01:08:18,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:08:18,012:INFO:create_model() successfully completed......................................
2024-02-17 01:08:18,196:INFO:_master_model_container: 16
2024-02-17 01:08:18,196:INFO:_display_container: 2
2024-02-17 01:08:18,196:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), <catboost.core.CatBoostClassifier object at 0x0000028DBF6973A0>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)]
2024-02-17 01:08:18,196:INFO:compare_models() successfully completed......................................
2024-02-17 01:08:48,152:INFO:Initializing compare_models()
2024-02-17 01:08:48,152:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-02-17 01:08:48,152:INFO:Checking exceptions
2024-02-17 01:08:48,152:INFO:Preparing display monitor
2024-02-17 01:08:48,190:INFO:Initializing Logistic Regression
2024-02-17 01:08:48,190:INFO:Total runtime is 0.0 minutes
2024-02-17 01:08:48,194:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:48,195:INFO:Initializing create_model()
2024-02-17 01:08:48,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:48,195:INFO:Checking exceptions
2024-02-17 01:08:48,195:INFO:Importing libraries
2024-02-17 01:08:48,195:INFO:Copying training dataset
2024-02-17 01:08:48,199:INFO:Defining folds
2024-02-17 01:08:48,199:INFO:Declaring metric variables
2024-02-17 01:08:48,205:INFO:Importing untrained model
2024-02-17 01:08:48,205:INFO:Logistic Regression Imported successfully
2024-02-17 01:08:48,214:INFO:Starting cross validation
2024-02-17 01:08:48,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:49,195:INFO:Calculating mean and std
2024-02-17 01:08:49,198:INFO:Creating metrics dataframe
2024-02-17 01:08:49,203:INFO:Uploading results into container
2024-02-17 01:08:49,203:INFO:Uploading model into container now
2024-02-17 01:08:49,203:INFO:_master_model_container: 17
2024-02-17 01:08:49,203:INFO:_display_container: 3
2024-02-17 01:08:49,203:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=255, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-02-17 01:08:49,203:INFO:create_model() successfully completed......................................
2024-02-17 01:08:49,337:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:49,337:INFO:Creating metrics dataframe
2024-02-17 01:08:49,345:INFO:Initializing K Neighbors Classifier
2024-02-17 01:08:49,345:INFO:Total runtime is 0.019236846764882406 minutes
2024-02-17 01:08:49,350:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:49,350:INFO:Initializing create_model()
2024-02-17 01:08:49,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:49,350:INFO:Checking exceptions
2024-02-17 01:08:49,350:INFO:Importing libraries
2024-02-17 01:08:49,350:INFO:Copying training dataset
2024-02-17 01:08:49,350:INFO:Defining folds
2024-02-17 01:08:49,350:INFO:Declaring metric variables
2024-02-17 01:08:49,360:INFO:Importing untrained model
2024-02-17 01:08:49,366:INFO:K Neighbors Classifier Imported successfully
2024-02-17 01:08:49,366:INFO:Starting cross validation
2024-02-17 01:08:49,366:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:49,599:INFO:Calculating mean and std
2024-02-17 01:08:49,599:INFO:Creating metrics dataframe
2024-02-17 01:08:49,605:INFO:Uploading results into container
2024-02-17 01:08:49,605:INFO:Uploading model into container now
2024-02-17 01:08:49,605:INFO:_master_model_container: 18
2024-02-17 01:08:49,605:INFO:_display_container: 3
2024-02-17 01:08:49,605:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-02-17 01:08:49,605:INFO:create_model() successfully completed......................................
2024-02-17 01:08:49,751:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:49,751:INFO:Creating metrics dataframe
2024-02-17 01:08:49,759:INFO:Initializing Naive Bayes
2024-02-17 01:08:49,763:INFO:Total runtime is 0.02620579799016317 minutes
2024-02-17 01:08:49,763:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:49,763:INFO:Initializing create_model()
2024-02-17 01:08:49,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:49,763:INFO:Checking exceptions
2024-02-17 01:08:49,763:INFO:Importing libraries
2024-02-17 01:08:49,763:INFO:Copying training dataset
2024-02-17 01:08:49,773:INFO:Defining folds
2024-02-17 01:08:49,773:INFO:Declaring metric variables
2024-02-17 01:08:49,781:INFO:Importing untrained model
2024-02-17 01:08:49,781:INFO:Naive Bayes Imported successfully
2024-02-17 01:08:49,792:INFO:Starting cross validation
2024-02-17 01:08:49,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:49,899:INFO:Calculating mean and std
2024-02-17 01:08:49,899:INFO:Creating metrics dataframe
2024-02-17 01:08:49,899:INFO:Uploading results into container
2024-02-17 01:08:49,899:INFO:Uploading model into container now
2024-02-17 01:08:49,899:INFO:_master_model_container: 19
2024-02-17 01:08:49,899:INFO:_display_container: 3
2024-02-17 01:08:49,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-02-17 01:08:49,899:INFO:create_model() successfully completed......................................
2024-02-17 01:08:50,037:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:50,037:INFO:Creating metrics dataframe
2024-02-17 01:08:50,048:INFO:Initializing Decision Tree Classifier
2024-02-17 01:08:50,048:INFO:Total runtime is 0.030964191754659018 minutes
2024-02-17 01:08:50,048:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:50,048:INFO:Initializing create_model()
2024-02-17 01:08:50,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:50,048:INFO:Checking exceptions
2024-02-17 01:08:50,048:INFO:Importing libraries
2024-02-17 01:08:50,048:INFO:Copying training dataset
2024-02-17 01:08:50,061:INFO:Defining folds
2024-02-17 01:08:50,061:INFO:Declaring metric variables
2024-02-17 01:08:50,066:INFO:Importing untrained model
2024-02-17 01:08:50,073:INFO:Decision Tree Classifier Imported successfully
2024-02-17 01:08:50,080:INFO:Starting cross validation
2024-02-17 01:08:50,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:50,236:INFO:Calculating mean and std
2024-02-17 01:08:50,237:INFO:Creating metrics dataframe
2024-02-17 01:08:50,237:INFO:Uploading results into container
2024-02-17 01:08:50,237:INFO:Uploading model into container now
2024-02-17 01:08:50,237:INFO:_master_model_container: 20
2024-02-17 01:08:50,237:INFO:_display_container: 3
2024-02-17 01:08:50,237:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=255, splitter='best')
2024-02-17 01:08:50,237:INFO:create_model() successfully completed......................................
2024-02-17 01:08:50,371:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:50,371:INFO:Creating metrics dataframe
2024-02-17 01:08:50,387:INFO:Initializing SVM - Linear Kernel
2024-02-17 01:08:50,387:INFO:Total runtime is 0.03661082983016968 minutes
2024-02-17 01:08:50,387:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:50,387:INFO:Initializing create_model()
2024-02-17 01:08:50,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:50,387:INFO:Checking exceptions
2024-02-17 01:08:50,387:INFO:Importing libraries
2024-02-17 01:08:50,387:INFO:Copying training dataset
2024-02-17 01:08:50,398:INFO:Defining folds
2024-02-17 01:08:50,398:INFO:Declaring metric variables
2024-02-17 01:08:50,405:INFO:Importing untrained model
2024-02-17 01:08:50,412:INFO:SVM - Linear Kernel Imported successfully
2024-02-17 01:08:50,420:INFO:Starting cross validation
2024-02-17 01:08:50,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:50,552:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,585:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,585:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,590:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,605:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,613:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,620:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,642:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,691:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,707:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,731:INFO:Calculating mean and std
2024-02-17 01:08:50,731:INFO:Creating metrics dataframe
2024-02-17 01:08:50,731:INFO:Uploading results into container
2024-02-17 01:08:50,731:INFO:Uploading model into container now
2024-02-17 01:08:50,731:INFO:_master_model_container: 21
2024-02-17 01:08:50,731:INFO:_display_container: 3
2024-02-17 01:08:50,731:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=255, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-02-17 01:08:50,731:INFO:create_model() successfully completed......................................
2024-02-17 01:08:50,886:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:50,886:INFO:Creating metrics dataframe
2024-02-17 01:08:50,901:INFO:Initializing Ridge Classifier
2024-02-17 01:08:50,902:INFO:Total runtime is 0.045200077692667644 minutes
2024-02-17 01:08:50,904:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:50,904:INFO:Initializing create_model()
2024-02-17 01:08:50,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:50,904:INFO:Checking exceptions
2024-02-17 01:08:50,904:INFO:Importing libraries
2024-02-17 01:08:50,904:INFO:Copying training dataset
2024-02-17 01:08:50,913:INFO:Defining folds
2024-02-17 01:08:50,913:INFO:Declaring metric variables
2024-02-17 01:08:50,918:INFO:Importing untrained model
2024-02-17 01:08:50,920:INFO:Ridge Classifier Imported successfully
2024-02-17 01:08:50,930:INFO:Starting cross validation
2024-02-17 01:08:50,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:50,980:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,982:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,988:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,988:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,988:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,988:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:50,997:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:51,004:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:51,020:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:51,020:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'. Did you mean: 'predict_log_proba'?

  warnings.warn(

2024-02-17 01:08:51,031:INFO:Calculating mean and std
2024-02-17 01:08:51,032:INFO:Creating metrics dataframe
2024-02-17 01:08:51,033:INFO:Uploading results into container
2024-02-17 01:08:51,033:INFO:Uploading model into container now
2024-02-17 01:08:51,033:INFO:_master_model_container: 22
2024-02-17 01:08:51,033:INFO:_display_container: 3
2024-02-17 01:08:51,033:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=255, solver='auto',
                tol=0.0001)
2024-02-17 01:08:51,033:INFO:create_model() successfully completed......................................
2024-02-17 01:08:51,167:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:51,167:INFO:Creating metrics dataframe
2024-02-17 01:08:51,176:INFO:Initializing Random Forest Classifier
2024-02-17 01:08:51,176:INFO:Total runtime is 0.0497626264890035 minutes
2024-02-17 01:08:51,181:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:51,181:INFO:Initializing create_model()
2024-02-17 01:08:51,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:51,182:INFO:Checking exceptions
2024-02-17 01:08:51,182:INFO:Importing libraries
2024-02-17 01:08:51,182:INFO:Copying training dataset
2024-02-17 01:08:51,190:INFO:Defining folds
2024-02-17 01:08:51,190:INFO:Declaring metric variables
2024-02-17 01:08:51,190:INFO:Importing untrained model
2024-02-17 01:08:51,197:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:08:51,209:INFO:Starting cross validation
2024-02-17 01:08:51,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:53,112:INFO:Calculating mean and std
2024-02-17 01:08:53,112:INFO:Creating metrics dataframe
2024-02-17 01:08:53,117:INFO:Uploading results into container
2024-02-17 01:08:53,117:INFO:Uploading model into container now
2024-02-17 01:08:53,117:INFO:_master_model_container: 23
2024-02-17 01:08:53,117:INFO:_display_container: 3
2024-02-17 01:08:53,117:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:08:53,117:INFO:create_model() successfully completed......................................
2024-02-17 01:08:53,280:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:53,283:INFO:Creating metrics dataframe
2024-02-17 01:08:53,295:INFO:Initializing Quadratic Discriminant Analysis
2024-02-17 01:08:53,295:INFO:Total runtime is 0.0850690762201945 minutes
2024-02-17 01:08:53,297:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:53,297:INFO:Initializing create_model()
2024-02-17 01:08:53,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:53,297:INFO:Checking exceptions
2024-02-17 01:08:53,297:INFO:Importing libraries
2024-02-17 01:08:53,297:INFO:Copying training dataset
2024-02-17 01:08:53,303:INFO:Defining folds
2024-02-17 01:08:53,303:INFO:Declaring metric variables
2024-02-17 01:08:53,303:INFO:Importing untrained model
2024-02-17 01:08:53,317:INFO:Quadratic Discriminant Analysis Imported successfully
2024-02-17 01:08:53,317:INFO:Starting cross validation
2024-02-17 01:08:53,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:53,429:INFO:Calculating mean and std
2024-02-17 01:08:53,431:INFO:Creating metrics dataframe
2024-02-17 01:08:53,431:INFO:Uploading results into container
2024-02-17 01:08:53,431:INFO:Uploading model into container now
2024-02-17 01:08:53,431:INFO:_master_model_container: 24
2024-02-17 01:08:53,431:INFO:_display_container: 3
2024-02-17 01:08:53,437:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-02-17 01:08:53,437:INFO:create_model() successfully completed......................................
2024-02-17 01:08:53,570:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:53,570:INFO:Creating metrics dataframe
2024-02-17 01:08:53,575:INFO:Initializing Ada Boost Classifier
2024-02-17 01:08:53,575:INFO:Total runtime is 0.08974390029907227 minutes
2024-02-17 01:08:53,584:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:53,584:INFO:Initializing create_model()
2024-02-17 01:08:53,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:53,584:INFO:Checking exceptions
2024-02-17 01:08:53,584:INFO:Importing libraries
2024-02-17 01:08:53,584:INFO:Copying training dataset
2024-02-17 01:08:53,591:INFO:Defining folds
2024-02-17 01:08:53,591:INFO:Declaring metric variables
2024-02-17 01:08:53,591:INFO:Importing untrained model
2024-02-17 01:08:53,600:INFO:Ada Boost Classifier Imported successfully
2024-02-17 01:08:53,607:INFO:Starting cross validation
2024-02-17 01:08:53,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:54,443:INFO:Calculating mean and std
2024-02-17 01:08:54,443:INFO:Creating metrics dataframe
2024-02-17 01:08:54,443:INFO:Uploading results into container
2024-02-17 01:08:54,443:INFO:Uploading model into container now
2024-02-17 01:08:54,443:INFO:_master_model_container: 25
2024-02-17 01:08:54,451:INFO:_display_container: 3
2024-02-17 01:08:54,451:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=255)
2024-02-17 01:08:54,451:INFO:create_model() successfully completed......................................
2024-02-17 01:08:54,578:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:54,578:INFO:Creating metrics dataframe
2024-02-17 01:08:54,584:INFO:Initializing Gradient Boosting Classifier
2024-02-17 01:08:54,584:INFO:Total runtime is 0.10656590461730958 minutes
2024-02-17 01:08:54,594:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:54,594:INFO:Initializing create_model()
2024-02-17 01:08:54,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:54,594:INFO:Checking exceptions
2024-02-17 01:08:54,594:INFO:Importing libraries
2024-02-17 01:08:54,594:INFO:Copying training dataset
2024-02-17 01:08:54,594:INFO:Defining folds
2024-02-17 01:08:54,594:INFO:Declaring metric variables
2024-02-17 01:08:54,594:INFO:Importing untrained model
2024-02-17 01:08:54,609:INFO:Gradient Boosting Classifier Imported successfully
2024-02-17 01:08:54,620:INFO:Starting cross validation
2024-02-17 01:08:54,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:57,063:INFO:Calculating mean and std
2024-02-17 01:08:57,065:INFO:Creating metrics dataframe
2024-02-17 01:08:57,069:INFO:Uploading results into container
2024-02-17 01:08:57,070:INFO:Uploading model into container now
2024-02-17 01:08:57,070:INFO:_master_model_container: 26
2024-02-17 01:08:57,070:INFO:_display_container: 3
2024-02-17 01:08:57,070:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=255, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-02-17 01:08:57,070:INFO:create_model() successfully completed......................................
2024-02-17 01:08:57,200:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:57,200:INFO:Creating metrics dataframe
2024-02-17 01:08:57,204:INFO:Initializing Linear Discriminant Analysis
2024-02-17 01:08:57,204:INFO:Total runtime is 0.15022147099177044 minutes
2024-02-17 01:08:57,204:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:57,214:INFO:Initializing create_model()
2024-02-17 01:08:57,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:57,215:INFO:Checking exceptions
2024-02-17 01:08:57,215:INFO:Importing libraries
2024-02-17 01:08:57,215:INFO:Copying training dataset
2024-02-17 01:08:57,215:INFO:Defining folds
2024-02-17 01:08:57,215:INFO:Declaring metric variables
2024-02-17 01:08:57,224:INFO:Importing untrained model
2024-02-17 01:08:57,231:INFO:Linear Discriminant Analysis Imported successfully
2024-02-17 01:08:57,241:INFO:Starting cross validation
2024-02-17 01:08:57,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:57,347:INFO:Calculating mean and std
2024-02-17 01:08:57,347:INFO:Creating metrics dataframe
2024-02-17 01:08:57,352:INFO:Uploading results into container
2024-02-17 01:08:57,353:INFO:Uploading model into container now
2024-02-17 01:08:57,353:INFO:_master_model_container: 27
2024-02-17 01:08:57,353:INFO:_display_container: 3
2024-02-17 01:08:57,353:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-02-17 01:08:57,353:INFO:create_model() successfully completed......................................
2024-02-17 01:08:57,483:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:57,483:INFO:Creating metrics dataframe
2024-02-17 01:08:57,498:INFO:Initializing Extra Trees Classifier
2024-02-17 01:08:57,498:INFO:Total runtime is 0.15512516895929973 minutes
2024-02-17 01:08:57,498:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:57,498:INFO:Initializing create_model()
2024-02-17 01:08:57,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:57,498:INFO:Checking exceptions
2024-02-17 01:08:57,498:INFO:Importing libraries
2024-02-17 01:08:57,498:INFO:Copying training dataset
2024-02-17 01:08:57,498:INFO:Defining folds
2024-02-17 01:08:57,498:INFO:Declaring metric variables
2024-02-17 01:08:57,515:INFO:Importing untrained model
2024-02-17 01:08:57,519:INFO:Extra Trees Classifier Imported successfully
2024-02-17 01:08:57,527:INFO:Starting cross validation
2024-02-17 01:08:57,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:08:59,228:INFO:Calculating mean and std
2024-02-17 01:08:59,228:INFO:Creating metrics dataframe
2024-02-17 01:08:59,237:INFO:Uploading results into container
2024-02-17 01:08:59,237:INFO:Uploading model into container now
2024-02-17 01:08:59,237:INFO:_master_model_container: 28
2024-02-17 01:08:59,237:INFO:_display_container: 3
2024-02-17 01:08:59,237:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=255, verbose=0, warm_start=False)
2024-02-17 01:08:59,237:INFO:create_model() successfully completed......................................
2024-02-17 01:08:59,399:INFO:SubProcess create_model() end ==================================
2024-02-17 01:08:59,399:INFO:Creating metrics dataframe
2024-02-17 01:08:59,418:INFO:Initializing Extreme Gradient Boosting
2024-02-17 01:08:59,418:INFO:Total runtime is 0.18713097572326662 minutes
2024-02-17 01:08:59,418:INFO:SubProcess create_model() called ==================================
2024-02-17 01:08:59,418:INFO:Initializing create_model()
2024-02-17 01:08:59,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:08:59,418:INFO:Checking exceptions
2024-02-17 01:08:59,418:INFO:Importing libraries
2024-02-17 01:08:59,418:INFO:Copying training dataset
2024-02-17 01:08:59,432:INFO:Defining folds
2024-02-17 01:08:59,432:INFO:Declaring metric variables
2024-02-17 01:08:59,439:INFO:Importing untrained model
2024-02-17 01:08:59,439:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:08:59,458:INFO:Starting cross validation
2024-02-17 01:08:59,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:09:00,262:INFO:Calculating mean and std
2024-02-17 01:09:00,264:INFO:Creating metrics dataframe
2024-02-17 01:09:00,270:INFO:Uploading results into container
2024-02-17 01:09:00,271:INFO:Uploading model into container now
2024-02-17 01:09:00,271:INFO:_master_model_container: 29
2024-02-17 01:09:00,271:INFO:_display_container: 3
2024-02-17 01:09:00,271:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:09:00,271:INFO:create_model() successfully completed......................................
2024-02-17 01:09:00,417:INFO:SubProcess create_model() end ==================================
2024-02-17 01:09:00,417:INFO:Creating metrics dataframe
2024-02-17 01:09:00,432:INFO:Initializing Light Gradient Boosting Machine
2024-02-17 01:09:00,432:INFO:Total runtime is 0.20402957995732626 minutes
2024-02-17 01:09:00,432:INFO:SubProcess create_model() called ==================================
2024-02-17 01:09:00,432:INFO:Initializing create_model()
2024-02-17 01:09:00,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:00,432:INFO:Checking exceptions
2024-02-17 01:09:00,432:INFO:Importing libraries
2024-02-17 01:09:00,432:INFO:Copying training dataset
2024-02-17 01:09:00,449:INFO:Defining folds
2024-02-17 01:09:00,449:INFO:Declaring metric variables
2024-02-17 01:09:00,458:INFO:Importing untrained model
2024-02-17 01:09:00,467:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:09:00,486:INFO:Starting cross validation
2024-02-17 01:09:00,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:09:02,513:INFO:Calculating mean and std
2024-02-17 01:09:02,513:INFO:Creating metrics dataframe
2024-02-17 01:09:02,522:INFO:Uploading results into container
2024-02-17 01:09:02,522:INFO:Uploading model into container now
2024-02-17 01:09:02,522:INFO:_master_model_container: 30
2024-02-17 01:09:02,522:INFO:_display_container: 3
2024-02-17 01:09:02,522:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:09:02,522:INFO:create_model() successfully completed......................................
2024-02-17 01:09:02,706:INFO:SubProcess create_model() end ==================================
2024-02-17 01:09:02,706:INFO:Creating metrics dataframe
2024-02-17 01:09:02,715:INFO:Initializing CatBoost Classifier
2024-02-17 01:09:02,715:INFO:Total runtime is 0.24208347002665204 minutes
2024-02-17 01:09:02,715:INFO:SubProcess create_model() called ==================================
2024-02-17 01:09:02,729:INFO:Initializing create_model()
2024-02-17 01:09:02,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:02,729:INFO:Checking exceptions
2024-02-17 01:09:02,729:INFO:Importing libraries
2024-02-17 01:09:02,729:INFO:Copying training dataset
2024-02-17 01:09:02,732:INFO:Defining folds
2024-02-17 01:09:02,732:INFO:Declaring metric variables
2024-02-17 01:09:02,732:INFO:Importing untrained model
2024-02-17 01:09:02,749:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:09:02,760:INFO:Starting cross validation
2024-02-17 01:09:02,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:09:21,144:INFO:Calculating mean and std
2024-02-17 01:09:21,144:INFO:Creating metrics dataframe
2024-02-17 01:09:21,149:INFO:Uploading results into container
2024-02-17 01:09:21,153:INFO:Uploading model into container now
2024-02-17 01:09:21,153:INFO:_master_model_container: 31
2024-02-17 01:09:21,153:INFO:_display_container: 3
2024-02-17 01:09:21,153:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1B4F940>
2024-02-17 01:09:21,153:INFO:create_model() successfully completed......................................
2024-02-17 01:09:21,287:INFO:SubProcess create_model() end ==================================
2024-02-17 01:09:21,287:INFO:Creating metrics dataframe
2024-02-17 01:09:21,304:INFO:Initializing Dummy Classifier
2024-02-17 01:09:21,304:INFO:Total runtime is 0.5518910845120748 minutes
2024-02-17 01:09:21,304:INFO:SubProcess create_model() called ==================================
2024-02-17 01:09:21,304:INFO:Initializing create_model()
2024-02-17 01:09:21,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028D9EE0FE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:21,304:INFO:Checking exceptions
2024-02-17 01:09:21,304:INFO:Importing libraries
2024-02-17 01:09:21,304:INFO:Copying training dataset
2024-02-17 01:09:21,318:INFO:Defining folds
2024-02-17 01:09:21,318:INFO:Declaring metric variables
2024-02-17 01:09:21,318:INFO:Importing untrained model
2024-02-17 01:09:21,318:INFO:Dummy Classifier Imported successfully
2024-02-17 01:09:21,333:INFO:Starting cross validation
2024-02-17 01:09:21,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:09:21,374:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:09:21,374:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:09:21,374:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:09:21,382:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:09:21,382:WARNING:c:\Users\happy\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-02-17 01:09:21,415:INFO:Calculating mean and std
2024-02-17 01:09:21,415:INFO:Creating metrics dataframe
2024-02-17 01:09:21,417:INFO:Uploading results into container
2024-02-17 01:09:21,417:INFO:Uploading model into container now
2024-02-17 01:09:21,417:INFO:_master_model_container: 32
2024-02-17 01:09:21,417:INFO:_display_container: 3
2024-02-17 01:09:21,417:INFO:DummyClassifier(constant=None, random_state=255, strategy='prior')
2024-02-17 01:09:21,417:INFO:create_model() successfully completed......................................
2024-02-17 01:09:21,542:INFO:SubProcess create_model() end ==================================
2024-02-17 01:09:21,542:INFO:Creating metrics dataframe
2024-02-17 01:09:21,567:INFO:Initializing create_model()
2024-02-17 01:09:21,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:21,567:INFO:Checking exceptions
2024-02-17 01:09:21,567:INFO:Importing libraries
2024-02-17 01:09:21,567:INFO:Copying training dataset
2024-02-17 01:09:21,567:INFO:Defining folds
2024-02-17 01:09:21,567:INFO:Declaring metric variables
2024-02-17 01:09:21,567:INFO:Importing untrained model
2024-02-17 01:09:21,567:INFO:Declaring custom model
2024-02-17 01:09:21,567:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:09:21,567:INFO:Cross validation set to False
2024-02-17 01:09:21,567:INFO:Fitting Model
2024-02-17 01:09:21,586:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 01:09:21,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000997 seconds.
2024-02-17 01:09:21,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 01:09:21,608:INFO:[LightGBM] [Info] Total Bins 1328
2024-02-17 01:09:21,608:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 01:09:21,608:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 01:09:21,683:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:09:21,683:INFO:create_model() successfully completed......................................
2024-02-17 01:09:21,833:INFO:Initializing create_model()
2024-02-17 01:09:21,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:21,844:INFO:Checking exceptions
2024-02-17 01:09:21,846:INFO:Importing libraries
2024-02-17 01:09:21,846:INFO:Copying training dataset
2024-02-17 01:09:21,853:INFO:Defining folds
2024-02-17 01:09:21,853:INFO:Declaring metric variables
2024-02-17 01:09:21,853:INFO:Importing untrained model
2024-02-17 01:09:21,853:INFO:Declaring custom model
2024-02-17 01:09:21,853:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:09:21,853:INFO:Cross validation set to False
2024-02-17 01:09:21,853:INFO:Fitting Model
2024-02-17 01:09:21,987:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:09:21,987:INFO:create_model() successfully completed......................................
2024-02-17 01:09:22,140:INFO:Initializing create_model()
2024-02-17 01:09:22,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC1B4F940>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:22,140:INFO:Checking exceptions
2024-02-17 01:09:22,140:INFO:Importing libraries
2024-02-17 01:09:22,140:INFO:Copying training dataset
2024-02-17 01:09:22,148:INFO:Defining folds
2024-02-17 01:09:22,148:INFO:Declaring metric variables
2024-02-17 01:09:22,148:INFO:Importing untrained model
2024-02-17 01:09:22,148:INFO:Declaring custom model
2024-02-17 01:09:22,150:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:09:22,150:INFO:Cross validation set to False
2024-02-17 01:09:22,150:INFO:Fitting Model
2024-02-17 01:09:26,821:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC190A980>
2024-02-17 01:09:26,821:INFO:create_model() successfully completed......................................
2024-02-17 01:09:26,987:INFO:Initializing create_model()
2024-02-17 01:09:26,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:09:26,987:INFO:Checking exceptions
2024-02-17 01:09:26,987:INFO:Importing libraries
2024-02-17 01:09:26,987:INFO:Copying training dataset
2024-02-17 01:09:26,996:INFO:Defining folds
2024-02-17 01:09:26,996:INFO:Declaring metric variables
2024-02-17 01:09:26,996:INFO:Importing untrained model
2024-02-17 01:09:27,000:INFO:Declaring custom model
2024-02-17 01:09:27,000:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:09:27,003:INFO:Cross validation set to False
2024-02-17 01:09:27,003:INFO:Fitting Model
2024-02-17 01:09:27,467:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:09:27,467:INFO:create_model() successfully completed......................................
2024-02-17 01:09:27,655:INFO:_master_model_container: 32
2024-02-17 01:09:27,655:INFO:_display_container: 3
2024-02-17 01:09:27,655:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), <catboost.core.CatBoostClassifier object at 0x0000028DC190A980>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)]
2024-02-17 01:09:27,655:INFO:compare_models() successfully completed......................................
2024-02-17 01:09:48,637:INFO:Initializing tune_model()
2024-02-17 01:09:48,637:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>)
2024-02-17 01:09:48,637:INFO:Checking exceptions
2024-02-17 01:09:48,669:INFO:Copying training dataset
2024-02-17 01:09:48,669:INFO:Checking base model
2024-02-17 01:09:48,669:INFO:Base model : Light Gradient Boosting Machine
2024-02-17 01:09:48,669:INFO:Declaring metric variables
2024-02-17 01:09:48,685:INFO:Defining Hyperparameters
2024-02-17 01:09:48,822:INFO:Tuning with n_jobs=-1
2024-02-17 01:09:48,822:INFO:Initializing RandomizedSearchCV
2024-02-17 01:10:18,638:INFO:best_params: {'actual_estimator__reg_lambda': 0.5, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 81, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.9}
2024-02-17 01:10:18,643:INFO:Hyperparameter search completed
2024-02-17 01:10:18,643:INFO:SubProcess create_model() called ==================================
2024-02-17 01:10:18,643:INFO:Initializing create_model()
2024-02-17 01:10:18,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC5880760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.5, 'reg_alpha': 0.05, 'num_leaves': 70, 'n_estimators': 150, 'min_split_gain': 0.2, 'min_child_samples': 81, 'learning_rate': 0.4, 'feature_fraction': 0.8, 'bagging_freq': 6, 'bagging_fraction': 0.9})
2024-02-17 01:10:18,646:INFO:Checking exceptions
2024-02-17 01:10:18,646:INFO:Importing libraries
2024-02-17 01:10:18,646:INFO:Copying training dataset
2024-02-17 01:10:18,661:INFO:Defining folds
2024-02-17 01:10:18,662:INFO:Declaring metric variables
2024-02-17 01:10:18,669:INFO:Importing untrained model
2024-02-17 01:10:18,669:INFO:Declaring custom model
2024-02-17 01:10:18,681:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:10:18,695:INFO:Starting cross validation
2024-02-17 01:10:18,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:10:20,700:INFO:Calculating mean and std
2024-02-17 01:10:20,700:INFO:Creating metrics dataframe
2024-02-17 01:10:20,711:INFO:Finalizing model
2024-02-17 01:10:20,740:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-02-17 01:10:20,740:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-17 01:10:20,740:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-17 01:10:20,747:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2024-02-17 01:10:20,747:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2024-02-17 01:10:20,747:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-02-17 01:10:20,747:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 01:10:20,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001944 seconds.
2024-02-17 01:10:20,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-02-17 01:10:20,755:INFO:[LightGBM] [Info] Total Bins 1328
2024-02-17 01:10:20,755:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 01:10:20,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 01:10:20,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,938:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,950:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,953:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,955:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,971:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,972:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,973:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,984:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:20,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,000:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-02-17 01:10:21,005:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-02-17 01:10:21,025:INFO:Uploading results into container
2024-02-17 01:10:21,027:INFO:Uploading model into container now
2024-02-17 01:10:21,027:INFO:_master_model_container: 33
2024-02-17 01:10:21,027:INFO:_display_container: 4
2024-02-17 01:10:21,027:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=70, objective=None,
               random_state=255, reg_alpha=0.05, reg_lambda=0.5, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:10:21,027:INFO:create_model() successfully completed......................................
2024-02-17 01:10:21,221:INFO:SubProcess create_model() end ==================================
2024-02-17 01:10:21,221:INFO:choose_better activated
2024-02-17 01:10:21,221:INFO:SubProcess create_model() called ==================================
2024-02-17 01:10:21,221:INFO:Initializing create_model()
2024-02-17 01:10:21,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:10:21,221:INFO:Checking exceptions
2024-02-17 01:10:21,221:INFO:Importing libraries
2024-02-17 01:10:21,221:INFO:Copying training dataset
2024-02-17 01:10:21,238:INFO:Defining folds
2024-02-17 01:10:21,238:INFO:Declaring metric variables
2024-02-17 01:10:21,238:INFO:Importing untrained model
2024-02-17 01:10:21,238:INFO:Declaring custom model
2024-02-17 01:10:21,241:INFO:Light Gradient Boosting Machine Imported successfully
2024-02-17 01:10:21,241:INFO:Starting cross validation
2024-02-17 01:10:21,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:10:23,131:INFO:Calculating mean and std
2024-02-17 01:10:23,132:INFO:Creating metrics dataframe
2024-02-17 01:10:23,132:INFO:Finalizing model
2024-02-17 01:10:23,165:INFO:[LightGBM] [Info] Number of positive: 3395, number of negative: 3395
2024-02-17 01:10:23,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.
2024-02-17 01:10:23,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-02-17 01:10:23,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-02-17 01:10:23,165:INFO:[LightGBM] [Info] Total Bins 1328
2024-02-17 01:10:23,165:INFO:[LightGBM] [Info] Number of data points in the train set: 6790, number of used features: 19
2024-02-17 01:10:23,169:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-02-17 01:10:23,297:INFO:Uploading results into container
2024-02-17 01:10:23,297:INFO:Uploading model into container now
2024-02-17 01:10:23,304:INFO:_master_model_container: 34
2024-02-17 01:10:23,304:INFO:_display_container: 5
2024-02-17 01:10:23,305:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:10:23,305:INFO:create_model() successfully completed......................................
2024-02-17 01:10:23,438:INFO:SubProcess create_model() end ==================================
2024-02-17 01:10:23,448:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9206
2024-02-17 01:10:23,448:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=81, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=70, objective=None,
               random_state=255, reg_alpha=0.05, reg_lambda=0.5, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2024-02-17 01:10:23,448:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-02-17 01:10:23,448:INFO:choose_better completed
2024-02-17 01:10:23,448:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 01:10:23,456:INFO:_master_model_container: 34
2024-02-17 01:10:23,456:INFO:_display_container: 4
2024-02-17 01:10:23,456:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-02-17 01:10:23,456:INFO:tune_model() successfully completed......................................
2024-02-17 01:10:23,588:INFO:Initializing tune_model()
2024-02-17 01:10:23,588:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>)
2024-02-17 01:10:23,588:INFO:Checking exceptions
2024-02-17 01:10:23,605:INFO:Copying training dataset
2024-02-17 01:10:23,616:INFO:Checking base model
2024-02-17 01:10:23,616:INFO:Base model : Extreme Gradient Boosting
2024-02-17 01:10:23,616:INFO:Declaring metric variables
2024-02-17 01:10:23,624:INFO:Defining Hyperparameters
2024-02-17 01:10:23,758:INFO:Tuning with n_jobs=-1
2024-02-17 01:10:23,758:INFO:Initializing RandomizedSearchCV
2024-02-17 01:10:31,288:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 45.6, 'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 5, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 2, 'actual_estimator__max_depth': 8, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__colsample_bytree': 1}
2024-02-17 01:10:31,288:INFO:Hyperparameter search completed
2024-02-17 01:10:31,288:INFO:SubProcess create_model() called ==================================
2024-02-17 01:10:31,288:INFO:Initializing create_model()
2024-02-17 01:10:31,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DC5880760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 45.6, 'reg_lambda': 5, 'reg_alpha': 5, 'n_estimators': 60, 'min_child_weight': 2, 'max_depth': 8, 'learning_rate': 0.2, 'colsample_bytree': 1})
2024-02-17 01:10:31,288:INFO:Checking exceptions
2024-02-17 01:10:31,288:INFO:Importing libraries
2024-02-17 01:10:31,288:INFO:Copying training dataset
2024-02-17 01:10:31,297:INFO:Defining folds
2024-02-17 01:10:31,297:INFO:Declaring metric variables
2024-02-17 01:10:31,308:INFO:Importing untrained model
2024-02-17 01:10:31,308:INFO:Declaring custom model
2024-02-17 01:10:31,308:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:10:31,322:INFO:Starting cross validation
2024-02-17 01:10:31,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:10:32,006:INFO:Calculating mean and std
2024-02-17 01:10:32,006:INFO:Creating metrics dataframe
2024-02-17 01:10:32,013:INFO:Finalizing model
2024-02-17 01:10:32,173:INFO:Uploading results into container
2024-02-17 01:10:32,173:INFO:Uploading model into container now
2024-02-17 01:10:32,173:INFO:_master_model_container: 35
2024-02-17 01:10:32,173:INFO:_display_container: 5
2024-02-17 01:10:32,173:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.2, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:10:32,173:INFO:create_model() successfully completed......................................
2024-02-17 01:10:32,323:INFO:SubProcess create_model() end ==================================
2024-02-17 01:10:32,323:INFO:choose_better activated
2024-02-17 01:10:32,323:INFO:SubProcess create_model() called ==================================
2024-02-17 01:10:32,323:INFO:Initializing create_model()
2024-02-17 01:10:32,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:10:32,323:INFO:Checking exceptions
2024-02-17 01:10:32,323:INFO:Importing libraries
2024-02-17 01:10:32,323:INFO:Copying training dataset
2024-02-17 01:10:32,333:INFO:Defining folds
2024-02-17 01:10:32,333:INFO:Declaring metric variables
2024-02-17 01:10:32,333:INFO:Importing untrained model
2024-02-17 01:10:32,333:INFO:Declaring custom model
2024-02-17 01:10:32,333:INFO:Extreme Gradient Boosting Imported successfully
2024-02-17 01:10:32,333:INFO:Starting cross validation
2024-02-17 01:10:32,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:10:32,888:INFO:Calculating mean and std
2024-02-17 01:10:32,890:INFO:Creating metrics dataframe
2024-02-17 01:10:32,890:INFO:Finalizing model
2024-02-17 01:10:33,007:INFO:Uploading results into container
2024-02-17 01:10:33,007:INFO:Uploading model into container now
2024-02-17 01:10:33,007:INFO:_master_model_container: 36
2024-02-17 01:10:33,007:INFO:_display_container: 6
2024-02-17 01:10:33,007:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:10:33,007:INFO:create_model() successfully completed......................................
2024-02-17 01:10:33,156:INFO:SubProcess create_model() end ==================================
2024-02-17 01:10:33,156:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.9156
2024-02-17 01:10:33,164:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,
              device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.2, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=8, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) result for Accuracy is 0.8688
2024-02-17 01:10:33,164:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...) is best model
2024-02-17 01:10:33,164:INFO:choose_better completed
2024-02-17 01:10:33,164:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 01:10:33,172:INFO:_master_model_container: 36
2024-02-17 01:10:33,172:INFO:_display_container: 5
2024-02-17 01:10:33,183:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-02-17 01:10:33,183:INFO:tune_model() successfully completed......................................
2024-02-17 01:10:33,308:INFO:Initializing tune_model()
2024-02-17 01:10:33,308:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC190A980>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>)
2024-02-17 01:10:33,308:INFO:Checking exceptions
2024-02-17 01:10:33,323:INFO:Copying training dataset
2024-02-17 01:10:33,323:INFO:Checking base model
2024-02-17 01:10:33,337:INFO:Base model : CatBoost Classifier
2024-02-17 01:10:33,339:INFO:Declaring metric variables
2024-02-17 01:10:33,345:INFO:Defining Hyperparameters
2024-02-17 01:10:33,475:INFO:Tuning with n_jobs=-1
2024-02-17 01:10:33,475:INFO:Initializing RandomizedSearchCV
2024-02-17 01:12:00,854:INFO:best_params: {'actual_estimator__random_strength': 0.7, 'actual_estimator__n_estimators': 150, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 9}
2024-02-17 01:12:00,854:INFO:Hyperparameter search completed
2024-02-17 01:12:00,854:INFO:SubProcess create_model() called ==================================
2024-02-17 01:12:00,854:INFO:Initializing create_model()
2024-02-17 01:12:00,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DBCE04E50>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DFB5758D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.7, 'n_estimators': 150, 'l2_leaf_reg': 7, 'eta': 0.1, 'depth': 9})
2024-02-17 01:12:00,854:INFO:Checking exceptions
2024-02-17 01:12:00,854:INFO:Importing libraries
2024-02-17 01:12:00,854:INFO:Copying training dataset
2024-02-17 01:12:00,865:INFO:Defining folds
2024-02-17 01:12:00,865:INFO:Declaring metric variables
2024-02-17 01:12:00,870:INFO:Importing untrained model
2024-02-17 01:12:00,870:INFO:Declaring custom model
2024-02-17 01:12:00,881:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:12:00,882:INFO:Starting cross validation
2024-02-17 01:12:00,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:12:09,209:INFO:Calculating mean and std
2024-02-17 01:12:09,211:INFO:Creating metrics dataframe
2024-02-17 01:12:09,212:INFO:Finalizing model
2024-02-17 01:12:11,023:INFO:Uploading results into container
2024-02-17 01:12:11,023:INFO:Uploading model into container now
2024-02-17 01:12:11,023:INFO:_master_model_container: 37
2024-02-17 01:12:11,023:INFO:_display_container: 6
2024-02-17 01:12:11,023:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873910>
2024-02-17 01:12:11,023:INFO:create_model() successfully completed......................................
2024-02-17 01:12:11,197:INFO:SubProcess create_model() end ==================================
2024-02-17 01:12:11,197:INFO:choose_better activated
2024-02-17 01:12:11,197:INFO:SubProcess create_model() called ==================================
2024-02-17 01:12:11,197:INFO:Initializing create_model()
2024-02-17 01:12:11,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=<catboost.core.CatBoostClassifier object at 0x0000028DC190A980>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:12:11,197:INFO:Checking exceptions
2024-02-17 01:12:11,197:INFO:Importing libraries
2024-02-17 01:12:11,197:INFO:Copying training dataset
2024-02-17 01:12:11,212:INFO:Defining folds
2024-02-17 01:12:11,212:INFO:Declaring metric variables
2024-02-17 01:12:11,212:INFO:Importing untrained model
2024-02-17 01:12:11,213:INFO:Declaring custom model
2024-02-17 01:12:11,213:INFO:CatBoost Classifier Imported successfully
2024-02-17 01:12:11,213:INFO:Starting cross validation
2024-02-17 01:12:11,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:12:30,392:INFO:Calculating mean and std
2024-02-17 01:12:30,392:INFO:Creating metrics dataframe
2024-02-17 01:12:30,392:INFO:Finalizing model
2024-02-17 01:12:34,259:INFO:Uploading results into container
2024-02-17 01:12:34,259:INFO:Uploading model into container now
2024-02-17 01:12:34,259:INFO:_master_model_container: 38
2024-02-17 01:12:34,259:INFO:_display_container: 7
2024-02-17 01:12:34,259:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFD60>
2024-02-17 01:12:34,259:INFO:create_model() successfully completed......................................
2024-02-17 01:12:34,414:INFO:SubProcess create_model() end ==================================
2024-02-17 01:12:34,414:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFD60> result for Accuracy is 0.9144
2024-02-17 01:12:34,414:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC1873910> result for Accuracy is 0.899
2024-02-17 01:12:34,414:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFD60> is best model
2024-02-17 01:12:34,414:INFO:choose_better completed
2024-02-17 01:12:34,414:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 01:12:34,435:INFO:_master_model_container: 38
2024-02-17 01:12:34,435:INFO:_display_container: 6
2024-02-17 01:12:34,435:INFO:<catboost.core.CatBoostClassifier object at 0x0000028DC15BFD60>
2024-02-17 01:12:34,435:INFO:tune_model() successfully completed......................................
2024-02-17 01:12:34,700:INFO:Initializing tune_model()
2024-02-17 01:12:34,700:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>)
2024-02-17 01:12:34,700:INFO:Checking exceptions
2024-02-17 01:12:34,747:INFO:Copying training dataset
2024-02-17 01:12:34,756:INFO:Checking base model
2024-02-17 01:12:34,756:INFO:Base model : Random Forest Classifier
2024-02-17 01:12:34,763:INFO:Declaring metric variables
2024-02-17 01:12:34,802:INFO:Defining Hyperparameters
2024-02-17 01:12:35,011:INFO:Tuning with n_jobs=-1
2024-02-17 01:12:35,011:INFO:Initializing RandomizedSearchCV
2024-02-17 01:12:55,351:INFO:best_params: {'actual_estimator__n_estimators': 270, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2024-02-17 01:12:55,351:INFO:Hyperparameter search completed
2024-02-17 01:12:55,351:INFO:SubProcess create_model() called ==================================
2024-02-17 01:12:55,351:INFO:Initializing create_model()
2024-02-17 01:12:55,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DBEB16170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 270, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2024-02-17 01:12:55,351:INFO:Checking exceptions
2024-02-17 01:12:55,351:INFO:Importing libraries
2024-02-17 01:12:55,351:INFO:Copying training dataset
2024-02-17 01:12:55,358:INFO:Defining folds
2024-02-17 01:12:55,358:INFO:Declaring metric variables
2024-02-17 01:12:55,358:INFO:Importing untrained model
2024-02-17 01:12:55,358:INFO:Declaring custom model
2024-02-17 01:12:55,366:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:12:55,373:INFO:Starting cross validation
2024-02-17 01:12:55,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:12:59,877:INFO:Calculating mean and std
2024-02-17 01:12:59,877:INFO:Creating metrics dataframe
2024-02-17 01:12:59,885:INFO:Finalizing model
2024-02-17 01:13:01,002:INFO:Uploading results into container
2024-02-17 01:13:01,002:INFO:Uploading model into container now
2024-02-17 01:13:01,002:INFO:_master_model_container: 39
2024-02-17 01:13:01,002:INFO:_display_container: 7
2024-02-17 01:13:01,002:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=270, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:13:01,002:INFO:create_model() successfully completed......................................
2024-02-17 01:13:01,166:INFO:SubProcess create_model() end ==================================
2024-02-17 01:13:01,177:INFO:choose_better activated
2024-02-17 01:13:01,182:INFO:SubProcess create_model() called ==================================
2024-02-17 01:13:01,183:INFO:Initializing create_model()
2024-02-17 01:13:01,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:13:01,185:INFO:Checking exceptions
2024-02-17 01:13:01,188:INFO:Importing libraries
2024-02-17 01:13:01,188:INFO:Copying training dataset
2024-02-17 01:13:01,188:INFO:Defining folds
2024-02-17 01:13:01,188:INFO:Declaring metric variables
2024-02-17 01:13:01,188:INFO:Importing untrained model
2024-02-17 01:13:01,188:INFO:Declaring custom model
2024-02-17 01:13:01,188:INFO:Random Forest Classifier Imported successfully
2024-02-17 01:13:01,188:INFO:Starting cross validation
2024-02-17 01:13:01,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:13:03,479:INFO:Calculating mean and std
2024-02-17 01:13:03,479:INFO:Creating metrics dataframe
2024-02-17 01:13:03,483:INFO:Finalizing model
2024-02-17 01:13:03,828:INFO:Uploading results into container
2024-02-17 01:13:03,828:INFO:Uploading model into container now
2024-02-17 01:13:03,828:INFO:_master_model_container: 40
2024-02-17 01:13:03,828:INFO:_display_container: 8
2024-02-17 01:13:03,832:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:13:03,832:INFO:create_model() successfully completed......................................
2024-02-17 01:13:03,966:INFO:SubProcess create_model() end ==================================
2024-02-17 01:13:03,966:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False) result for Accuracy is 0.9091
2024-02-17 01:13:03,966:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.001, min_samples_leaf=2,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=270, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False) result for Accuracy is 0.8828
2024-02-17 01:13:03,966:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False) is best model
2024-02-17 01:13:03,966:INFO:choose_better completed
2024-02-17 01:13:03,966:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-02-17 01:13:03,978:INFO:_master_model_container: 40
2024-02-17 01:13:03,978:INFO:_display_container: 7
2024-02-17 01:13:03,978:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)
2024-02-17 01:13:03,978:INFO:tune_model() successfully completed......................................
2024-02-17 01:13:10,245:INFO:Initializing blend_models()
2024-02-17 01:13:10,245:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=255, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), <catboost.core.CatBoostClassifier object at 0x0000028DC15BFD60>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=255, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-02-17 01:13:10,245:INFO:Checking exceptions
2024-02-17 01:13:10,266:INFO:Importing libraries
2024-02-17 01:13:10,266:INFO:Copying training dataset
2024-02-17 01:13:10,268:INFO:Getting model names
2024-02-17 01:13:10,275:INFO:SubProcess create_model() called ==================================
2024-02-17 01:13:10,283:INFO:Initializing create_model()
2024-02-17 01:13:10,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028DA1DEB370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:13:10,283:INFO:Checking exceptions
2024-02-17 01:13:10,283:INFO:Importing libraries
2024-02-17 01:13:10,283:INFO:Copying training dataset
2024-02-17 01:13:10,287:INFO:Defining folds
2024-02-17 01:13:10,287:INFO:Declaring metric variables
2024-02-17 01:13:10,287:INFO:Importing untrained model
2024-02-17 01:13:10,287:INFO:Declaring custom model
2024-02-17 01:13:10,322:INFO:Voting Classifier Imported successfully
2024-02-17 01:13:10,336:INFO:Starting cross validation
2024-02-17 01:13:10,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-02-17 01:13:29,731:INFO:Calculating mean and std
2024-02-17 01:13:29,731:INFO:Creating metrics dataframe
2024-02-17 01:13:29,735:INFO:Finalizing model
2024-02-17 01:13:34,541:INFO:Uploading results into container
2024-02-17 01:13:34,542:INFO:Uploading model into container now
2024-02-17 01:13:34,542:INFO:_master_model_container: 41
2024-02-17 01:13:34,542:INFO:_display_container: 8
2024-02-17 01:13:34,542:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:13:34,542:INFO:create_model() successfully completed......................................
2024-02-17 01:13:34,702:INFO:SubProcess create_model() end ==================================
2024-02-17 01:13:34,723:INFO:_master_model_container: 41
2024-02-17 01:13:34,723:INFO:_display_container: 8
2024-02-17 01:13:34,723:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:13:34,723:INFO:blend_models() successfully completed......................................
2024-02-17 01:13:56,261:INFO:Initializing finalize_model()
2024-02-17 01:13:56,261:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-02-17 01:13:56,264:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-02-17 01:13:56,273:INFO:Initializing create_model()
2024-02-17 01:13:56,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=255, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=255,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-02-17 01:13:56,273:INFO:Checking exceptions
2024-02-17 01:13:56,273:INFO:Importing libraries
2024-02-17 01:13:56,273:INFO:Copying training dataset
2024-02-17 01:13:56,273:INFO:Defining folds
2024-02-17 01:13:56,273:INFO:Declaring metric variables
2024-02-17 01:13:56,273:INFO:Importing untrained model
2024-02-17 01:13:56,273:INFO:Declaring custom model
2024-02-17 01:13:56,273:INFO:Voting Classifier Imported successfully
2024-02-17 01:13:56,273:INFO:Cross validation set to False
2024-02-17 01:13:56,273:INFO:Fitting Model
2024-02-17 01:14:01,704:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=255,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:14:01,704:INFO:create_model() successfully completed......................................
2024-02-17 01:14:01,838:INFO:_master_model_container: 41
2024-02-17 01:14:01,838:INFO:_display_container: 8
2024-02-17 01:14:01,853:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=255,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2024-02-17 01:14:01,853:INFO:finalize_model() successfully completed......................................
2024-02-17 01:14:01,999:INFO:Initializing predict_model()
2024-02-17 01:14:01,999:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028DC586C340>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['bant_submit', 'customer_country',
                                             'business_unit',
                                             'com_reg_ver_win_rate',
                                             'customer_idx', 'customer_type',
                                             'enterprise',
                                             'historical_existing_cnt',
                                             'customer_job', 'lead_desc_length',
                                             'inquiry_type', 'product_category',
                                             'customer_position',
                                             'response_cor...
                                                                      criterion='gini',
                                                                      max_depth=None,
                                                                      max_features='sqrt',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.0,
                                                                      min_samples_leaf=1,
                                                                      min_samples_split=2,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=100,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=255,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028D9EC9B490>)
2024-02-17 01:14:01,999:INFO:Checking exceptions
2024-02-17 01:14:01,999:INFO:Preloading libraries
2024-02-17 01:14:02,007:INFO:Set up data.
2024-02-17 01:14:02,007:INFO:Set up index.
